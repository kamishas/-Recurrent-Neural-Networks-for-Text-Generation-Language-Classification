{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olp9NMSaAtil",
        "outputId": "c93e924d-8adf-4cf6-a37f-36996a2fcfde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/CS747_Assignment4/CS747_Assignment4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G--CDybAtfM",
        "outputId": "8ee0a86c-a144-4e5b-bcdb-5edf6b63d0ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS747_Assignment4/CS747_Assignment4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Unidecode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tpRfmroAzjR",
        "outputId": "e67b16c9-5bb6-4f8a-83e8-7a8f281172d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import glob\n",
        "import string\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from rnn.helpers import time_since\n",
        "\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "U1veyjHFASxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "rmaMDfRXASxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language recognition with an RNN\n",
        "\n",
        "If you've ever used an online translator you've probably seen a feature that automatically detects the input language. While this might be easy to do if you input unicode characters that are unique to one or a small group of languages (like \"你好\" or \"γεια σας\"), this problem is more challenging if the input only uses the available ASCII characters. In this case, something like \"těší mě\" would beome \"tesi me\" in the ascii form. This is a more challenging problem in which the language must be recognized purely by the pattern of characters rather than unique unicode characters.\n",
        "\n",
        "We will train an RNN to solve this problem for a small set of languages thta can be converted to romanized ASCII form. For training data it would be ideal to have a large and varied dataset in different language styles. However, it is easy to find copies of the Bible which is a large text translated to different languages but in the same easily parsable format, so we will use 20 different copies of the Bible as training data. Using the same book for all of the different languages will hopefully prevent minor overfitting that might arise if we used different books for each language (fitting to common characteristics of the individual books rather than the language)."
      ],
      "metadata": {
        "id": "OZgIh-UfASxU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from unidecode import unidecode as unicodeToAscii\n",
        "\n",
        "all_characters = string.printable\n",
        "n_letters = len(all_characters)\n",
        "\n",
        "print(unicodeToAscii('těší mě'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tesi me\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpBHuGEHASxV",
        "outputId": "f2d785e1-cfe3-4f80-945f-87d62f57477c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Read a file and split into lines\n",
        "def readFile(filename):\n",
        "    data = open(filename, encoding='utf-8').read().strip()\n",
        "    return unicodeToAscii(data)\n",
        "\n",
        "def get_category_data(data_path):\n",
        "    # Build the category_data dictionary, a list of names per language\n",
        "    category_data = {}\n",
        "    all_categories = []\n",
        "    for filename in glob.glob(data_path):\n",
        "        category = os.path.splitext(os.path.basename(filename))[0].split('_')[0]\n",
        "        all_categories.append(category)\n",
        "        data = readFile(filename)\n",
        "        category_data[category] = data\n",
        "\n",
        "    return category_data, all_categories"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "qr5jxlB6ASxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original text is split into two parts, train and test, so that we can make sure that the model is not simply memorizing the train data."
      ],
      "metadata": {
        "id": "CsNV5RvfASxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "train_data_path = 'language_data/train/*_train.txt'\n",
        "test_data_path = 'language_data/test/*_test.txt'\n",
        "\n",
        "train_category_data, all_categories = get_category_data(train_data_path)\n",
        "test_category_data, test_all_categories = get_category_data(test_data_path)\n",
        "\n",
        "n_languages = len(all_categories)\n",
        "\n",
        "print(len(all_categories))\n",
        "print(all_categories)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "['french', 'english', 'romanian', 'lithuanian', 'vietnamese', 'swedish', 'italian', 'finnish', 'maori', 'xhosa', 'german', 'czech', 'portuguese', 'danish', 'albanian', 'turkish', 'esperanto', 'norwegian', 'hungarian', 'spanish']\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csty2g5aASxV",
        "outputId": "483f05e0-b7a0-40db-93a8-f6e094b23d65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "3_8qYX69ASxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1, dim=1)\n",
        "    category_i = top_i[:, 0]\n",
        "    return category_i\n",
        "\n",
        "# Turn string into long tensor\n",
        "def stringToTensor(string):\n",
        "    tensor = torch.zeros(len(string), requires_grad=True).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "def load_random_batch(text, chunk_len, batch_size, device):\n",
        "    input_data = torch.zeros(batch_size, chunk_len).long().to(device)\n",
        "    target = torch.zeros(batch_size, 1).long().to(device)\n",
        "    input_text = []\n",
        "    for i in range(batch_size):\n",
        "        category = all_categories[random.randint(0, len(all_categories) - 1)]\n",
        "        line_start = random.randint(0, len(text[category]) - chunk_len)\n",
        "        category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long).to(device)\n",
        "        line = text[category][line_start:line_start + chunk_len]\n",
        "        input_text.append(line)\n",
        "        input_data[i] = stringToTensor(line)\n",
        "        target[i] = category_tensor\n",
        "    return input_data, target, input_text\n"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "riwcflvxASxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Model\n",
        "====================\n",
        "\n",
        "For this classification task, we can use the same model we implement for the generation task which is located in `rnn/model.py`. See the `MP4_generation.ipynb` notebook for more instructions. In this case each output vector of our RNN will have the dimension of the number of possible languages (i.e. `n_languages`). We will use this vector to predict a distribution over the languages.\n",
        "\n",
        "In the generation task, we used the output of the RNN at every time step to predict the next letter and our loss included the output from each of these predictions. However, in this task we use the output of the RNN at the end of the sequence to predict the language, so our loss function will use only the predicted output from the last time step.\n",
        "\n"
      ],
      "metadata": {
        "id": "q9rdwyBIASxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train RNN"
      ],
      "metadata": {
        "id": "DC4X5DbdASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from rnn.model import RNN"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "YO3HkIz0ASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "chunk_len = 50\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "n_epochs = 2000\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "learning_rate = 0.01\n",
        "model_type = 'rnn'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "rnn = RNN(n_letters, hidden_size, n_languages, model_type=model_type, n_layers=n_layers).to(device)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "7hTGb_bEASxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:** Fill in the train function. You should initialize a hidden layer representation using your RNN's `init_hidden` function, set the model gradients to zero, and loop over each time step (character) in the input tensor. For each time step compute the output of the of the RNN and the next hidden layer representation. The cross entropy loss should be computed over the last RNN output scores from the end of the sequence and the target classification tensor. Lastly, call backward on the loss and take an optimizer step."
      ],
      "metadata": {
        "id": "aiIJz-gZASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def train(rnn, target_tensor, data_tensor, optimizer, criterion, batch_size=BATCH_SIZE):\n",
        "    \"\"\"\n",
        "    Train the model on a batch of data.\n",
        "\n",
        "    Inputs:\n",
        "    - rnn: model\n",
        "    - target_tensor: target character data tensor of shape (batch_size, 1)\n",
        "    - data_tensor: input character data tensor of shape (batch_size, chunk_len)\n",
        "    - optimizer: rnn model optimizer\n",
        "    - criterion: loss function\n",
        "    - batch_size: data batch size\n",
        "\n",
        "    Returns:\n",
        "    - output: output from RNN from the end of the sequence\n",
        "    - loss: computed loss value as a Python float\n",
        "    \"\"\"\n",
        "    # Initialize hidden state\n",
        "    hidden = rnn.init_hidden(batch_size, device=device)\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    # Loop over each character in the input sequence\n",
        "    for c in range(data_tensor.size(1)):\n",
        "        output, hidden = rnn(data_tensor[:, c], hidden)\n",
        "\n",
        "    # Compute the loss only on the last output\n",
        "    loss = criterion(output, target_tensor.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()\n"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "vGtGTtXQASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "def evaluate(rnn, data_tensor, seq_len=chunk_len, batch_size=BATCH_SIZE):\n",
        "    with torch.no_grad():\n",
        "        data_tensor = data_tensor.to(device)\n",
        "        hidden = rnn.init_hidden(batch_size, device=device)\n",
        "        for i in range(seq_len):\n",
        "            output, hidden = rnn(data_tensor[:,i], hidden)\n",
        "\n",
        "        return output\n",
        "\n",
        "def eval_test(rnn, category_tensor, data_tensor):\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(rnn, data_tensor)\n",
        "        loss = criterion(output, category_tensor.squeeze())\n",
        "        return output, loss.item()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "gHiRU--aASxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Updated Hyperparameters\n",
        "iterations = 2000\n",
        "log_interval = 100\n",
        "plot_interval = 100\n",
        "\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "lr = 0.003  # Slightly reduced learning rate\n",
        "rnn_type = 'lstm'\n",
        "\n",
        "# Initialize the RNN model, loss function, and optimizer\n",
        "rnn = RNN(n_letters, hidden_dim, n_languages, model_type=rnn_type, n_layers=num_layers).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr, weight_decay=1e-6)  # Added small weight decay\n",
        "\n",
        "# Lists to store losses for plotting\n",
        "train_loss_total = 0.0\n",
        "test_loss_total = 0.0\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "start_time = time.time()\n",
        "correct_count = 0\n",
        "\n",
        "print(f\"Training started with model: {rnn_type}, hidden_dim: {hidden_dim}, num_layers: {num_layers}, lr: {lr}\")\n",
        "\n",
        "# Training loop\n",
        "for step in range(1, iterations + 1):\n",
        "    # Fetch a random batch of training data\n",
        "    inputs, targets, text_batch = load_random_batch(train_category_data, chunk_len, BATCH_SIZE, device)\n",
        "\n",
        "    # Training phase\n",
        "    model_output, loss_value = train(rnn, targets, inputs, optimizer, loss_fn)\n",
        "    train_loss_total += loss_value\n",
        "\n",
        "    # Clip gradients to stabilize training\n",
        "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=5.0)\n",
        "\n",
        "    # Debug message for current loss\n",
        "    print(f\"Step {step}: Training Loss = {loss_value:.4f}\")\n",
        "\n",
        "    # Evaluation phase on test set\n",
        "    _, test_loss_value = eval_test(rnn, targets, inputs)\n",
        "    test_loss_total += test_loss_value\n",
        "\n",
        "    # Debug message for test loss\n",
        "    print(f\"Step {step}: Test Loss = {test_loss_value:.4f}\")\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_indices = categoryFromOutput(model_output)\n",
        "    correct_count += (targets.squeeze() == predicted_indices.squeeze()).long().sum().item()\n",
        "\n",
        "    # Logging and printing results\n",
        "    if step % log_interval == 0:\n",
        "        accuracy_score = correct_count / (log_interval * BATCH_SIZE)\n",
        "        sample_text = text_batch[0]\n",
        "        predicted_category = all_categories[predicted_indices[0]]\n",
        "        actual_category = all_categories[int(targets[0])]\n",
        "        correctness = '✓' if predicted_category == actual_category else f'✗ ({actual_category})'\n",
        "\n",
        "        print(f\"{step} {step / iterations * 100:.0f}% ({time_since(start_time)}) \"\n",
        "              f\"Train Loss: {train_loss_total / log_interval:.4f}, \"\n",
        "              f\"Test Loss: {test_loss_total / log_interval:.4f}, \"\n",
        "              f\"Accuracy: {accuracy_score:.4f} - {sample_text} / {predicted_category} {correctness}\")\n",
        "\n",
        "        # Reset counters\n",
        "        train_loss_total = 0.0\n",
        "        test_loss_total = 0.0\n",
        "        correct_count = 0\n",
        "\n",
        "    # Record losses for plotting\n",
        "    if step % plot_interval == 0:\n",
        "        avg_train_loss = train_loss_total / plot_interval\n",
        "        avg_test_loss = test_loss_total / plot_interval\n",
        "        train_losses.append(avg_train_loss)\n",
        "        test_losses.append(avg_test_loss)\n",
        "\n",
        "        # Reset for next interval\n",
        "        train_loss_total = 0.0\n",
        "        test_loss_total = 0.0\n",
        "\n",
        "# Plotting the recorded losses\n",
        "if len(train_losses) > 0 and len(test_losses) > 0:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    steps = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.plot(steps, train_losses, label=\"Training Loss\", color='blue')\n",
        "    plt.plot(steps, test_losses, label=\"Test Loss\", color='red', linestyle='--')\n",
        "    plt.xlabel(\"Iterations (x100)\")\n",
        "    plt.ylabel(\"Loss Value\")\n",
        "    plt.title(\"Loss Curve for Training and Testing\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: No loss values recorded. Check your training loop.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8-CXYvJkpGp4",
        "outputId": "57dbb49a-8b9c-41b4-9e07-d056afdd89c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started with model: lstm, hidden_dim: 256, num_layers: 2, lr: 0.003\n",
            "Step 1: Training Loss = 2.9968\n",
            "Step 1: Test Loss = 2.8824\n",
            "Step 2: Training Loss = 2.9891\n",
            "Step 2: Test Loss = 2.8820\n",
            "Step 3: Training Loss = 2.9572\n",
            "Step 3: Test Loss = 2.8514\n",
            "Step 4: Training Loss = 2.9341\n",
            "Step 4: Test Loss = 2.7826\n",
            "Step 5: Training Loss = 2.9194\n",
            "Step 5: Test Loss = 2.7907\n",
            "Step 6: Training Loss = 2.8252\n",
            "Step 6: Test Loss = 2.6838\n",
            "Step 7: Training Loss = 2.7602\n",
            "Step 7: Test Loss = 2.6314\n",
            "Step 8: Training Loss = 2.6601\n",
            "Step 8: Test Loss = 2.5603\n",
            "Step 9: Training Loss = 2.7172\n",
            "Step 9: Test Loss = 2.5311\n",
            "Step 10: Training Loss = 2.5442\n",
            "Step 10: Test Loss = 2.5483\n",
            "Step 11: Training Loss = 2.7422\n",
            "Step 11: Test Loss = 2.4833\n",
            "Step 12: Training Loss = 2.7036\n",
            "Step 12: Test Loss = 2.6545\n",
            "Step 13: Training Loss = 2.5242\n",
            "Step 13: Test Loss = 2.3439\n",
            "Step 14: Training Loss = 2.5666\n",
            "Step 14: Test Loss = 2.4577\n",
            "Step 15: Training Loss = 2.4948\n",
            "Step 15: Test Loss = 2.3263\n",
            "Step 16: Training Loss = 2.2925\n",
            "Step 16: Test Loss = 2.1592\n",
            "Step 17: Training Loss = 2.3309\n",
            "Step 17: Test Loss = 2.1103\n",
            "Step 18: Training Loss = 2.3132\n",
            "Step 18: Test Loss = 2.0574\n",
            "Step 19: Training Loss = 2.2122\n",
            "Step 19: Test Loss = 2.0302\n",
            "Step 20: Training Loss = 2.1816\n",
            "Step 20: Test Loss = 2.0622\n",
            "Step 21: Training Loss = 2.1903\n",
            "Step 21: Test Loss = 2.0261\n",
            "Step 22: Training Loss = 2.0901\n",
            "Step 22: Test Loss = 1.9439\n",
            "Step 23: Training Loss = 2.0852\n",
            "Step 23: Test Loss = 1.9057\n",
            "Step 24: Training Loss = 1.9731\n",
            "Step 24: Test Loss = 1.7579\n",
            "Step 25: Training Loss = 1.9589\n",
            "Step 25: Test Loss = 1.7972\n",
            "Step 26: Training Loss = 2.0882\n",
            "Step 26: Test Loss = 1.7787\n",
            "Step 27: Training Loss = 1.6848\n",
            "Step 27: Test Loss = 1.5451\n",
            "Step 28: Training Loss = 1.7276\n",
            "Step 28: Test Loss = 1.5515\n",
            "Step 29: Training Loss = 1.6617\n",
            "Step 29: Test Loss = 1.5116\n",
            "Step 30: Training Loss = 1.7285\n",
            "Step 30: Test Loss = 1.6175\n",
            "Step 31: Training Loss = 1.7148\n",
            "Step 31: Test Loss = 1.4608\n",
            "Step 32: Training Loss = 1.7544\n",
            "Step 32: Test Loss = 1.5461\n",
            "Step 33: Training Loss = 1.8386\n",
            "Step 33: Test Loss = 1.6573\n",
            "Step 34: Training Loss = 1.7737\n",
            "Step 34: Test Loss = 1.6576\n",
            "Step 35: Training Loss = 1.5339\n",
            "Step 35: Test Loss = 1.3879\n",
            "Step 36: Training Loss = 1.6274\n",
            "Step 36: Test Loss = 1.4973\n",
            "Step 37: Training Loss = 1.5148\n",
            "Step 37: Test Loss = 1.2899\n",
            "Step 38: Training Loss = 1.5162\n",
            "Step 38: Test Loss = 1.2644\n",
            "Step 39: Training Loss = 1.3500\n",
            "Step 39: Test Loss = 1.1431\n",
            "Step 40: Training Loss = 1.4627\n",
            "Step 40: Test Loss = 1.3236\n",
            "Step 41: Training Loss = 1.2588\n",
            "Step 41: Test Loss = 1.0563\n",
            "Step 42: Training Loss = 1.3869\n",
            "Step 42: Test Loss = 1.2247\n",
            "Step 43: Training Loss = 1.5779\n",
            "Step 43: Test Loss = 1.2969\n",
            "Step 44: Training Loss = 1.4287\n",
            "Step 44: Test Loss = 1.1393\n",
            "Step 45: Training Loss = 1.2623\n",
            "Step 45: Test Loss = 1.1384\n",
            "Step 46: Training Loss = 1.2490\n",
            "Step 46: Test Loss = 1.0596\n",
            "Step 47: Training Loss = 1.2711\n",
            "Step 47: Test Loss = 1.0959\n",
            "Step 48: Training Loss = 1.3031\n",
            "Step 48: Test Loss = 1.2032\n",
            "Step 49: Training Loss = 1.0263\n",
            "Step 49: Test Loss = 0.8615\n",
            "Step 50: Training Loss = 1.2068\n",
            "Step 50: Test Loss = 0.9730\n",
            "Step 51: Training Loss = 1.2055\n",
            "Step 51: Test Loss = 1.1509\n",
            "Step 52: Training Loss = 1.2416\n",
            "Step 52: Test Loss = 1.0472\n",
            "Step 53: Training Loss = 1.2185\n",
            "Step 53: Test Loss = 0.9908\n",
            "Step 54: Training Loss = 1.1091\n",
            "Step 54: Test Loss = 1.0139\n",
            "Step 55: Training Loss = 0.9917\n",
            "Step 55: Test Loss = 0.8685\n",
            "Step 56: Training Loss = 1.1430\n",
            "Step 56: Test Loss = 0.9275\n",
            "Step 57: Training Loss = 1.0381\n",
            "Step 57: Test Loss = 0.9085\n",
            "Step 58: Training Loss = 0.9169\n",
            "Step 58: Test Loss = 0.7858\n",
            "Step 59: Training Loss = 1.0665\n",
            "Step 59: Test Loss = 0.9142\n",
            "Step 60: Training Loss = 0.9320\n",
            "Step 60: Test Loss = 0.7466\n",
            "Step 61: Training Loss = 1.1702\n",
            "Step 61: Test Loss = 0.9687\n",
            "Step 62: Training Loss = 1.1571\n",
            "Step 62: Test Loss = 0.9672\n",
            "Step 63: Training Loss = 0.7442\n",
            "Step 63: Test Loss = 0.6566\n",
            "Step 64: Training Loss = 0.9140\n",
            "Step 64: Test Loss = 0.7445\n",
            "Step 65: Training Loss = 1.1584\n",
            "Step 65: Test Loss = 0.9891\n",
            "Step 66: Training Loss = 1.2021\n",
            "Step 66: Test Loss = 0.9404\n",
            "Step 67: Training Loss = 0.9236\n",
            "Step 67: Test Loss = 0.7903\n",
            "Step 68: Training Loss = 1.0202\n",
            "Step 68: Test Loss = 0.7980\n",
            "Step 69: Training Loss = 0.9598\n",
            "Step 69: Test Loss = 0.8161\n",
            "Step 70: Training Loss = 1.0268\n",
            "Step 70: Test Loss = 0.9071\n",
            "Step 71: Training Loss = 0.9198\n",
            "Step 71: Test Loss = 0.7402\n",
            "Step 72: Training Loss = 1.0702\n",
            "Step 72: Test Loss = 0.8602\n",
            "Step 73: Training Loss = 0.8688\n",
            "Step 73: Test Loss = 0.7248\n",
            "Step 74: Training Loss = 0.9986\n",
            "Step 74: Test Loss = 0.8165\n",
            "Step 75: Training Loss = 0.7799\n",
            "Step 75: Test Loss = 0.6794\n",
            "Step 76: Training Loss = 1.0606\n",
            "Step 76: Test Loss = 0.8937\n",
            "Step 77: Training Loss = 0.9355\n",
            "Step 77: Test Loss = 0.8092\n",
            "Step 78: Training Loss = 1.0072\n",
            "Step 78: Test Loss = 0.7944\n",
            "Step 79: Training Loss = 0.9387\n",
            "Step 79: Test Loss = 0.8143\n",
            "Step 80: Training Loss = 1.0480\n",
            "Step 80: Test Loss = 0.9205\n",
            "Step 81: Training Loss = 0.6849\n",
            "Step 81: Test Loss = 0.5723\n",
            "Step 82: Training Loss = 0.8808\n",
            "Step 82: Test Loss = 0.7335\n",
            "Step 83: Training Loss = 1.0244\n",
            "Step 83: Test Loss = 0.8565\n",
            "Step 84: Training Loss = 1.1726\n",
            "Step 84: Test Loss = 0.9326\n",
            "Step 85: Training Loss = 0.8316\n",
            "Step 85: Test Loss = 0.7191\n",
            "Step 86: Training Loss = 0.7714\n",
            "Step 86: Test Loss = 0.6782\n",
            "Step 87: Training Loss = 0.7999\n",
            "Step 87: Test Loss = 0.6994\n",
            "Step 88: Training Loss = 0.9823\n",
            "Step 88: Test Loss = 0.7952\n",
            "Step 89: Training Loss = 0.8490\n",
            "Step 89: Test Loss = 0.7022\n",
            "Step 90: Training Loss = 0.6522\n",
            "Step 90: Test Loss = 0.5828\n",
            "Step 91: Training Loss = 0.7382\n",
            "Step 91: Test Loss = 0.6484\n",
            "Step 92: Training Loss = 0.8057\n",
            "Step 92: Test Loss = 0.6612\n",
            "Step 93: Training Loss = 0.8358\n",
            "Step 93: Test Loss = 0.6568\n",
            "Step 94: Training Loss = 0.7332\n",
            "Step 94: Test Loss = 0.5830\n",
            "Step 95: Training Loss = 0.7449\n",
            "Step 95: Test Loss = 0.6540\n",
            "Step 96: Training Loss = 0.8237\n",
            "Step 96: Test Loss = 0.6474\n",
            "Step 97: Training Loss = 0.8384\n",
            "Step 97: Test Loss = 0.7248\n",
            "Step 98: Training Loss = 0.6112\n",
            "Step 98: Test Loss = 0.4938\n",
            "Step 99: Training Loss = 0.7351\n",
            "Step 99: Test Loss = 0.5770\n",
            "Step 100: Training Loss = 0.5284\n",
            "Step 100: Test Loss = 0.4637\n",
            "100 5% (0m 11s) Train Loss: 1.4772, Test Loss: 1.3191, Accuracy: 0.5151 - neither I, nor my brethren, nor my servants, nor t / english ✓\n",
            "Step 101: Training Loss = 0.6220\n",
            "Step 101: Test Loss = 0.5451\n",
            "Step 102: Training Loss = 0.5991\n",
            "Step 102: Test Loss = 0.5061\n",
            "Step 103: Training Loss = 0.7324\n",
            "Step 103: Test Loss = 0.5812\n",
            "Step 104: Training Loss = 0.6511\n",
            "Step 104: Test Loss = 0.5713\n",
            "Step 105: Training Loss = 0.6533\n",
            "Step 105: Test Loss = 0.5741\n",
            "Step 106: Training Loss = 0.6066\n",
            "Step 106: Test Loss = 0.5011\n",
            "Step 107: Training Loss = 1.0124\n",
            "Step 107: Test Loss = 0.7652\n",
            "Step 108: Training Loss = 1.0166\n",
            "Step 108: Test Loss = 0.7115\n",
            "Step 109: Training Loss = 0.6257\n",
            "Step 109: Test Loss = 0.4862\n",
            "Step 110: Training Loss = 0.6210\n",
            "Step 110: Test Loss = 0.5716\n",
            "Step 111: Training Loss = 0.8083\n",
            "Step 111: Test Loss = 0.6475\n",
            "Step 112: Training Loss = 0.6668\n",
            "Step 112: Test Loss = 0.5485\n",
            "Step 113: Training Loss = 0.7478\n",
            "Step 113: Test Loss = 0.6421\n",
            "Step 114: Training Loss = 0.6795\n",
            "Step 114: Test Loss = 0.5624\n",
            "Step 115: Training Loss = 0.7627\n",
            "Step 115: Test Loss = 0.5869\n",
            "Step 116: Training Loss = 0.9390\n",
            "Step 116: Test Loss = 0.7297\n",
            "Step 117: Training Loss = 0.7002\n",
            "Step 117: Test Loss = 0.6113\n",
            "Step 118: Training Loss = 0.8645\n",
            "Step 118: Test Loss = 0.7268\n",
            "Step 119: Training Loss = 0.6706\n",
            "Step 119: Test Loss = 0.6042\n",
            "Step 120: Training Loss = 0.8964\n",
            "Step 120: Test Loss = 0.6943\n",
            "Step 121: Training Loss = 0.6630\n",
            "Step 121: Test Loss = 0.5171\n",
            "Step 122: Training Loss = 0.7591\n",
            "Step 122: Test Loss = 0.5921\n",
            "Step 123: Training Loss = 0.7520\n",
            "Step 123: Test Loss = 0.5980\n",
            "Step 124: Training Loss = 0.6384\n",
            "Step 124: Test Loss = 0.5958\n",
            "Step 125: Training Loss = 0.7651\n",
            "Step 125: Test Loss = 0.6050\n",
            "Step 126: Training Loss = 0.7477\n",
            "Step 126: Test Loss = 0.5856\n",
            "Step 127: Training Loss = 0.7082\n",
            "Step 127: Test Loss = 0.5288\n",
            "Step 128: Training Loss = 0.5952\n",
            "Step 128: Test Loss = 0.4815\n",
            "Step 129: Training Loss = 0.6532\n",
            "Step 129: Test Loss = 0.5690\n",
            "Step 130: Training Loss = 0.7221\n",
            "Step 130: Test Loss = 0.5909\n",
            "Step 131: Training Loss = 0.8651\n",
            "Step 131: Test Loss = 0.7607\n",
            "Step 132: Training Loss = 0.5120\n",
            "Step 132: Test Loss = 0.3940\n",
            "Step 133: Training Loss = 0.6202\n",
            "Step 133: Test Loss = 0.4845\n",
            "Step 134: Training Loss = 0.6455\n",
            "Step 134: Test Loss = 0.5341\n",
            "Step 135: Training Loss = 0.5643\n",
            "Step 135: Test Loss = 0.4613\n",
            "Step 136: Training Loss = 0.5856\n",
            "Step 136: Test Loss = 0.4881\n",
            "Step 137: Training Loss = 0.6513\n",
            "Step 137: Test Loss = 0.5603\n",
            "Step 138: Training Loss = 0.7054\n",
            "Step 138: Test Loss = 0.5703\n",
            "Step 139: Training Loss = 0.8101\n",
            "Step 139: Test Loss = 0.6204\n",
            "Step 140: Training Loss = 0.4483\n",
            "Step 140: Test Loss = 0.3777\n",
            "Step 141: Training Loss = 0.5624\n",
            "Step 141: Test Loss = 0.4262\n",
            "Step 142: Training Loss = 0.4498\n",
            "Step 142: Test Loss = 0.3757\n",
            "Step 143: Training Loss = 0.6385\n",
            "Step 143: Test Loss = 0.5388\n",
            "Step 144: Training Loss = 0.6171\n",
            "Step 144: Test Loss = 0.5053\n",
            "Step 145: Training Loss = 0.5925\n",
            "Step 145: Test Loss = 0.4761\n",
            "Step 146: Training Loss = 0.5115\n",
            "Step 146: Test Loss = 0.4095\n",
            "Step 147: Training Loss = 0.5754\n",
            "Step 147: Test Loss = 0.4484\n",
            "Step 148: Training Loss = 0.7741\n",
            "Step 148: Test Loss = 0.6022\n",
            "Step 149: Training Loss = 0.7032\n",
            "Step 149: Test Loss = 0.5729\n",
            "Step 150: Training Loss = 0.5093\n",
            "Step 150: Test Loss = 0.3664\n",
            "Step 151: Training Loss = 0.6177\n",
            "Step 151: Test Loss = 0.4839\n",
            "Step 152: Training Loss = 0.7188\n",
            "Step 152: Test Loss = 0.5336\n",
            "Step 153: Training Loss = 0.6764\n",
            "Step 153: Test Loss = 0.5564\n",
            "Step 154: Training Loss = 0.5725\n",
            "Step 154: Test Loss = 0.4446\n",
            "Step 155: Training Loss = 0.7877\n",
            "Step 155: Test Loss = 0.6269\n",
            "Step 156: Training Loss = 0.4547\n",
            "Step 156: Test Loss = 0.3359\n",
            "Step 157: Training Loss = 0.4546\n",
            "Step 157: Test Loss = 0.3540\n",
            "Step 158: Training Loss = 0.4548\n",
            "Step 158: Test Loss = 0.3797\n",
            "Step 159: Training Loss = 0.4313\n",
            "Step 159: Test Loss = 0.3411\n",
            "Step 160: Training Loss = 0.5038\n",
            "Step 160: Test Loss = 0.3924\n",
            "Step 161: Training Loss = 0.6223\n",
            "Step 161: Test Loss = 0.5259\n",
            "Step 162: Training Loss = 0.4523\n",
            "Step 162: Test Loss = 0.3651\n",
            "Step 163: Training Loss = 0.5857\n",
            "Step 163: Test Loss = 0.4945\n",
            "Step 164: Training Loss = 0.4362\n",
            "Step 164: Test Loss = 0.3632\n",
            "Step 165: Training Loss = 0.5291\n",
            "Step 165: Test Loss = 0.4420\n",
            "Step 166: Training Loss = 0.5721\n",
            "Step 166: Test Loss = 0.4509\n",
            "Step 167: Training Loss = 0.4725\n",
            "Step 167: Test Loss = 0.3728\n",
            "Step 168: Training Loss = 0.5445\n",
            "Step 168: Test Loss = 0.4316\n",
            "Step 169: Training Loss = 0.5241\n",
            "Step 169: Test Loss = 0.4358\n",
            "Step 170: Training Loss = 0.4339\n",
            "Step 170: Test Loss = 0.3719\n",
            "Step 171: Training Loss = 0.7089\n",
            "Step 171: Test Loss = 0.4815\n",
            "Step 172: Training Loss = 0.4516\n",
            "Step 172: Test Loss = 0.3538\n",
            "Step 173: Training Loss = 0.4048\n",
            "Step 173: Test Loss = 0.3163\n",
            "Step 174: Training Loss = 0.4293\n",
            "Step 174: Test Loss = 0.3305\n",
            "Step 175: Training Loss = 0.5494\n",
            "Step 175: Test Loss = 0.3867\n",
            "Step 176: Training Loss = 0.5347\n",
            "Step 176: Test Loss = 0.4317\n",
            "Step 177: Training Loss = 0.5022\n",
            "Step 177: Test Loss = 0.3751\n",
            "Step 178: Training Loss = 0.5006\n",
            "Step 178: Test Loss = 0.3991\n",
            "Step 179: Training Loss = 0.4732\n",
            "Step 179: Test Loss = 0.4013\n",
            "Step 180: Training Loss = 0.5585\n",
            "Step 180: Test Loss = 0.4472\n",
            "Step 181: Training Loss = 0.4277\n",
            "Step 181: Test Loss = 0.3362\n",
            "Step 182: Training Loss = 0.5417\n",
            "Step 182: Test Loss = 0.4324\n",
            "Step 183: Training Loss = 0.4496\n",
            "Step 183: Test Loss = 0.3779\n",
            "Step 184: Training Loss = 0.3760\n",
            "Step 184: Test Loss = 0.2979\n",
            "Step 185: Training Loss = 0.4910\n",
            "Step 185: Test Loss = 0.3488\n",
            "Step 186: Training Loss = 0.4531\n",
            "Step 186: Test Loss = 0.3619\n",
            "Step 187: Training Loss = 0.4176\n",
            "Step 187: Test Loss = 0.3397\n",
            "Step 188: Training Loss = 0.5436\n",
            "Step 188: Test Loss = 0.4662\n",
            "Step 189: Training Loss = 0.5523\n",
            "Step 189: Test Loss = 0.4399\n",
            "Step 190: Training Loss = 0.5157\n",
            "Step 190: Test Loss = 0.4001\n",
            "Step 191: Training Loss = 0.5974\n",
            "Step 191: Test Loss = 0.4371\n",
            "Step 192: Training Loss = 0.4810\n",
            "Step 192: Test Loss = 0.3292\n",
            "Step 193: Training Loss = 0.4997\n",
            "Step 193: Test Loss = 0.3694\n",
            "Step 194: Training Loss = 0.5085\n",
            "Step 194: Test Loss = 0.3788\n",
            "Step 195: Training Loss = 0.4604\n",
            "Step 195: Test Loss = 0.3914\n",
            "Step 196: Training Loss = 0.6309\n",
            "Step 196: Test Loss = 0.5367\n",
            "Step 197: Training Loss = 0.5310\n",
            "Step 197: Test Loss = 0.4100\n",
            "Step 198: Training Loss = 0.5308\n",
            "Step 198: Test Loss = 0.3916\n",
            "Step 199: Training Loss = 0.5153\n",
            "Step 199: Test Loss = 0.3997\n",
            "Step 200: Training Loss = 0.4611\n",
            "Step 200: Test Loss = 0.3720\n",
            "200 10% (0m 23s) Train Loss: 0.6016, Test Loss: 0.4825, Accuracy: 0.7862 - ag; jag slog honom, och i min fortornelse holl jag / swedish ✓\n",
            "Step 201: Training Loss = 0.4711\n",
            "Step 201: Test Loss = 0.3936\n",
            "Step 202: Training Loss = 0.5972\n",
            "Step 202: Test Loss = 0.5031\n",
            "Step 203: Training Loss = 0.4780\n",
            "Step 203: Test Loss = 0.3824\n",
            "Step 204: Training Loss = 0.4692\n",
            "Step 204: Test Loss = 0.3847\n",
            "Step 205: Training Loss = 0.5649\n",
            "Step 205: Test Loss = 0.3731\n",
            "Step 206: Training Loss = 0.5368\n",
            "Step 206: Test Loss = 0.4015\n",
            "Step 207: Training Loss = 0.3672\n",
            "Step 207: Test Loss = 0.3180\n",
            "Step 208: Training Loss = 0.3633\n",
            "Step 208: Test Loss = 0.2879\n",
            "Step 209: Training Loss = 0.4735\n",
            "Step 209: Test Loss = 0.3838\n",
            "Step 210: Training Loss = 0.5583\n",
            "Step 210: Test Loss = 0.4556\n",
            "Step 211: Training Loss = 0.5875\n",
            "Step 211: Test Loss = 0.4485\n",
            "Step 212: Training Loss = 0.7460\n",
            "Step 212: Test Loss = 0.5503\n",
            "Step 213: Training Loss = 0.4648\n",
            "Step 213: Test Loss = 0.3596\n",
            "Step 214: Training Loss = 0.4110\n",
            "Step 214: Test Loss = 0.3373\n",
            "Step 215: Training Loss = 0.6486\n",
            "Step 215: Test Loss = 0.5133\n",
            "Step 216: Training Loss = 0.5089\n",
            "Step 216: Test Loss = 0.4327\n",
            "Step 217: Training Loss = 0.4407\n",
            "Step 217: Test Loss = 0.3488\n",
            "Step 218: Training Loss = 0.4837\n",
            "Step 218: Test Loss = 0.3688\n",
            "Step 219: Training Loss = 0.3011\n",
            "Step 219: Test Loss = 0.2419\n",
            "Step 220: Training Loss = 0.3583\n",
            "Step 220: Test Loss = 0.2886\n",
            "Step 221: Training Loss = 0.4036\n",
            "Step 221: Test Loss = 0.3200\n",
            "Step 222: Training Loss = 0.5192\n",
            "Step 222: Test Loss = 0.4082\n",
            "Step 223: Training Loss = 0.6582\n",
            "Step 223: Test Loss = 0.5355\n",
            "Step 224: Training Loss = 0.4594\n",
            "Step 224: Test Loss = 0.3755\n",
            "Step 225: Training Loss = 0.6065\n",
            "Step 225: Test Loss = 0.4726\n",
            "Step 226: Training Loss = 0.3573\n",
            "Step 226: Test Loss = 0.2728\n",
            "Step 227: Training Loss = 0.4381\n",
            "Step 227: Test Loss = 0.3539\n",
            "Step 228: Training Loss = 0.4501\n",
            "Step 228: Test Loss = 0.3420\n",
            "Step 229: Training Loss = 0.3409\n",
            "Step 229: Test Loss = 0.2449\n",
            "Step 230: Training Loss = 0.7182\n",
            "Step 230: Test Loss = 0.4680\n",
            "Step 231: Training Loss = 0.3351\n",
            "Step 231: Test Loss = 0.2588\n",
            "Step 232: Training Loss = 0.4694\n",
            "Step 232: Test Loss = 0.3496\n",
            "Step 233: Training Loss = 0.4519\n",
            "Step 233: Test Loss = 0.3516\n",
            "Step 234: Training Loss = 0.4428\n",
            "Step 234: Test Loss = 0.3608\n",
            "Step 235: Training Loss = 0.4146\n",
            "Step 235: Test Loss = 0.3452\n",
            "Step 236: Training Loss = 0.4108\n",
            "Step 236: Test Loss = 0.3478\n",
            "Step 237: Training Loss = 0.6421\n",
            "Step 237: Test Loss = 0.4175\n",
            "Step 238: Training Loss = 0.2258\n",
            "Step 238: Test Loss = 0.1865\n",
            "Step 239: Training Loss = 0.5655\n",
            "Step 239: Test Loss = 0.4083\n",
            "Step 240: Training Loss = 0.3198\n",
            "Step 240: Test Loss = 0.2499\n",
            "Step 241: Training Loss = 0.3593\n",
            "Step 241: Test Loss = 0.3040\n",
            "Step 242: Training Loss = 0.3301\n",
            "Step 242: Test Loss = 0.2801\n",
            "Step 243: Training Loss = 0.4605\n",
            "Step 243: Test Loss = 0.3577\n",
            "Step 244: Training Loss = 0.4394\n",
            "Step 244: Test Loss = 0.3307\n",
            "Step 245: Training Loss = 0.4604\n",
            "Step 245: Test Loss = 0.3175\n",
            "Step 246: Training Loss = 0.3809\n",
            "Step 246: Test Loss = 0.2777\n",
            "Step 247: Training Loss = 0.4495\n",
            "Step 247: Test Loss = 0.3510\n",
            "Step 248: Training Loss = 0.5160\n",
            "Step 248: Test Loss = 0.4077\n",
            "Step 249: Training Loss = 0.3646\n",
            "Step 249: Test Loss = 0.2492\n",
            "Step 250: Training Loss = 0.3306\n",
            "Step 250: Test Loss = 0.2451\n",
            "Step 251: Training Loss = 0.2833\n",
            "Step 251: Test Loss = 0.2149\n",
            "Step 252: Training Loss = 0.4670\n",
            "Step 252: Test Loss = 0.3435\n",
            "Step 253: Training Loss = 0.4618\n",
            "Step 253: Test Loss = 0.3677\n",
            "Step 254: Training Loss = 0.4693\n",
            "Step 254: Test Loss = 0.3574\n",
            "Step 255: Training Loss = 0.3965\n",
            "Step 255: Test Loss = 0.2621\n",
            "Step 256: Training Loss = 0.3947\n",
            "Step 256: Test Loss = 0.3088\n",
            "Step 257: Training Loss = 0.2891\n",
            "Step 257: Test Loss = 0.2131\n",
            "Step 258: Training Loss = 0.3450\n",
            "Step 258: Test Loss = 0.2749\n",
            "Step 259: Training Loss = 0.3632\n",
            "Step 259: Test Loss = 0.2761\n",
            "Step 260: Training Loss = 0.3206\n",
            "Step 260: Test Loss = 0.2501\n",
            "Step 261: Training Loss = 0.3898\n",
            "Step 261: Test Loss = 0.2889\n",
            "Step 262: Training Loss = 0.2985\n",
            "Step 262: Test Loss = 0.2092\n",
            "Step 263: Training Loss = 0.3011\n",
            "Step 263: Test Loss = 0.2374\n",
            "Step 264: Training Loss = 0.4292\n",
            "Step 264: Test Loss = 0.3275\n",
            "Step 265: Training Loss = 0.3005\n",
            "Step 265: Test Loss = 0.2393\n",
            "Step 266: Training Loss = 0.3016\n",
            "Step 266: Test Loss = 0.1942\n",
            "Step 267: Training Loss = 0.3343\n",
            "Step 267: Test Loss = 0.2099\n",
            "Step 268: Training Loss = 0.3294\n",
            "Step 268: Test Loss = 0.2325\n",
            "Step 269: Training Loss = 0.4548\n",
            "Step 269: Test Loss = 0.3764\n",
            "Step 270: Training Loss = 0.3941\n",
            "Step 270: Test Loss = 0.3248\n",
            "Step 271: Training Loss = 0.4489\n",
            "Step 271: Test Loss = 0.3242\n",
            "Step 272: Training Loss = 0.4748\n",
            "Step 272: Test Loss = 0.3153\n",
            "Step 273: Training Loss = 0.3364\n",
            "Step 273: Test Loss = 0.2487\n",
            "Step 274: Training Loss = 0.2979\n",
            "Step 274: Test Loss = 0.2524\n",
            "Step 275: Training Loss = 0.4749\n",
            "Step 275: Test Loss = 0.3494\n",
            "Step 276: Training Loss = 0.3462\n",
            "Step 276: Test Loss = 0.2575\n",
            "Step 277: Training Loss = 0.2465\n",
            "Step 277: Test Loss = 0.2206\n",
            "Step 278: Training Loss = 0.4188\n",
            "Step 278: Test Loss = 0.2907\n",
            "Step 279: Training Loss = 0.2977\n",
            "Step 279: Test Loss = 0.2427\n",
            "Step 280: Training Loss = 0.3968\n",
            "Step 280: Test Loss = 0.2725\n",
            "Step 281: Training Loss = 0.2354\n",
            "Step 281: Test Loss = 0.1718\n",
            "Step 282: Training Loss = 0.4618\n",
            "Step 282: Test Loss = 0.3385\n",
            "Step 283: Training Loss = 0.4200\n",
            "Step 283: Test Loss = 0.3122\n",
            "Step 284: Training Loss = 0.2418\n",
            "Step 284: Test Loss = 0.1755\n",
            "Step 285: Training Loss = 0.1838\n",
            "Step 285: Test Loss = 0.1574\n",
            "Step 286: Training Loss = 0.3048\n",
            "Step 286: Test Loss = 0.2350\n",
            "Step 287: Training Loss = 0.3236\n",
            "Step 287: Test Loss = 0.2577\n",
            "Step 288: Training Loss = 0.1882\n",
            "Step 288: Test Loss = 0.1084\n",
            "Step 289: Training Loss = 0.2662\n",
            "Step 289: Test Loss = 0.2081\n",
            "Step 290: Training Loss = 0.4473\n",
            "Step 290: Test Loss = 0.3164\n",
            "Step 291: Training Loss = 0.2815\n",
            "Step 291: Test Loss = 0.1827\n",
            "Step 292: Training Loss = 0.3830\n",
            "Step 292: Test Loss = 0.2266\n",
            "Step 293: Training Loss = 0.2826\n",
            "Step 293: Test Loss = 0.2264\n",
            "Step 294: Training Loss = 0.3524\n",
            "Step 294: Test Loss = 0.2689\n",
            "Step 295: Training Loss = 0.3954\n",
            "Step 295: Test Loss = 0.2898\n",
            "Step 296: Training Loss = 0.4675\n",
            "Step 296: Test Loss = 0.3352\n",
            "Step 297: Training Loss = 0.3126\n",
            "Step 297: Test Loss = 0.2142\n",
            "Step 298: Training Loss = 0.3503\n",
            "Step 298: Test Loss = 0.2904\n",
            "Step 299: Training Loss = 0.2122\n",
            "Step 299: Test Loss = 0.1742\n",
            "Step 300: Training Loss = 0.4860\n",
            "Step 300: Test Loss = 0.3883\n",
            "300 15% (0m 35s) Train Loss: 0.4081, Test Loss: 0.3112, Accuracy: 0.8560 - ierto de un manto. Saul entonces entendio que era  / spanish ✓\n",
            "Step 301: Training Loss = 0.2869\n",
            "Step 301: Test Loss = 0.2065\n",
            "Step 302: Training Loss = 0.2583\n",
            "Step 302: Test Loss = 0.2106\n",
            "Step 303: Training Loss = 0.2463\n",
            "Step 303: Test Loss = 0.1592\n",
            "Step 304: Training Loss = 0.3381\n",
            "Step 304: Test Loss = 0.2687\n",
            "Step 305: Training Loss = 0.4462\n",
            "Step 305: Test Loss = 0.3245\n",
            "Step 306: Training Loss = 0.5186\n",
            "Step 306: Test Loss = 0.4170\n",
            "Step 307: Training Loss = 0.2608\n",
            "Step 307: Test Loss = 0.2068\n",
            "Step 308: Training Loss = 0.2803\n",
            "Step 308: Test Loss = 0.2459\n",
            "Step 309: Training Loss = 0.2333\n",
            "Step 309: Test Loss = 0.1827\n",
            "Step 310: Training Loss = 0.4361\n",
            "Step 310: Test Loss = 0.3228\n",
            "Step 311: Training Loss = 0.4649\n",
            "Step 311: Test Loss = 0.3476\n",
            "Step 312: Training Loss = 0.2647\n",
            "Step 312: Test Loss = 0.2101\n",
            "Step 313: Training Loss = 0.3529\n",
            "Step 313: Test Loss = 0.2664\n",
            "Step 314: Training Loss = 0.3257\n",
            "Step 314: Test Loss = 0.2341\n",
            "Step 315: Training Loss = 0.3225\n",
            "Step 315: Test Loss = 0.2399\n",
            "Step 316: Training Loss = 0.3570\n",
            "Step 316: Test Loss = 0.2753\n",
            "Step 317: Training Loss = 0.3091\n",
            "Step 317: Test Loss = 0.2210\n",
            "Step 318: Training Loss = 0.2284\n",
            "Step 318: Test Loss = 0.1932\n",
            "Step 319: Training Loss = 0.2509\n",
            "Step 319: Test Loss = 0.1995\n",
            "Step 320: Training Loss = 0.5134\n",
            "Step 320: Test Loss = 0.3792\n",
            "Step 321: Training Loss = 0.2855\n",
            "Step 321: Test Loss = 0.2111\n",
            "Step 322: Training Loss = 0.2326\n",
            "Step 322: Test Loss = 0.1860\n",
            "Step 323: Training Loss = 0.2863\n",
            "Step 323: Test Loss = 0.2230\n",
            "Step 324: Training Loss = 0.3689\n",
            "Step 324: Test Loss = 0.2285\n",
            "Step 325: Training Loss = 0.2864\n",
            "Step 325: Test Loss = 0.1839\n",
            "Step 326: Training Loss = 0.3152\n",
            "Step 326: Test Loss = 0.2332\n",
            "Step 327: Training Loss = 0.3281\n",
            "Step 327: Test Loss = 0.2636\n",
            "Step 328: Training Loss = 0.4455\n",
            "Step 328: Test Loss = 0.3067\n",
            "Step 329: Training Loss = 0.3711\n",
            "Step 329: Test Loss = 0.2734\n",
            "Step 330: Training Loss = 0.2780\n",
            "Step 330: Test Loss = 0.1745\n",
            "Step 331: Training Loss = 0.3011\n",
            "Step 331: Test Loss = 0.2141\n",
            "Step 332: Training Loss = 0.4559\n",
            "Step 332: Test Loss = 0.3112\n",
            "Step 333: Training Loss = 0.2616\n",
            "Step 333: Test Loss = 0.2117\n",
            "Step 334: Training Loss = 0.3579\n",
            "Step 334: Test Loss = 0.2869\n",
            "Step 335: Training Loss = 0.5095\n",
            "Step 335: Test Loss = 0.3221\n",
            "Step 336: Training Loss = 0.3815\n",
            "Step 336: Test Loss = 0.2801\n",
            "Step 337: Training Loss = 0.2781\n",
            "Step 337: Test Loss = 0.2384\n",
            "Step 338: Training Loss = 0.4239\n",
            "Step 338: Test Loss = 0.3290\n",
            "Step 339: Training Loss = 0.2829\n",
            "Step 339: Test Loss = 0.2064\n",
            "Step 340: Training Loss = 0.2399\n",
            "Step 340: Test Loss = 0.1900\n",
            "Step 341: Training Loss = 0.3008\n",
            "Step 341: Test Loss = 0.2188\n",
            "Step 342: Training Loss = 0.2555\n",
            "Step 342: Test Loss = 0.2016\n",
            "Step 343: Training Loss = 0.4462\n",
            "Step 343: Test Loss = 0.3197\n",
            "Step 344: Training Loss = 0.3736\n",
            "Step 344: Test Loss = 0.2726\n",
            "Step 345: Training Loss = 0.3738\n",
            "Step 345: Test Loss = 0.2812\n",
            "Step 346: Training Loss = 0.3694\n",
            "Step 346: Test Loss = 0.2879\n",
            "Step 347: Training Loss = 0.3033\n",
            "Step 347: Test Loss = 0.2139\n",
            "Step 348: Training Loss = 0.3622\n",
            "Step 348: Test Loss = 0.3074\n",
            "Step 349: Training Loss = 0.4226\n",
            "Step 349: Test Loss = 0.3504\n",
            "Step 350: Training Loss = 0.2386\n",
            "Step 350: Test Loss = 0.1961\n",
            "Step 351: Training Loss = 0.3284\n",
            "Step 351: Test Loss = 0.2573\n",
            "Step 352: Training Loss = 0.2603\n",
            "Step 352: Test Loss = 0.1944\n",
            "Step 353: Training Loss = 0.2554\n",
            "Step 353: Test Loss = 0.1751\n",
            "Step 354: Training Loss = 0.3894\n",
            "Step 354: Test Loss = 0.2345\n",
            "Step 355: Training Loss = 0.4154\n",
            "Step 355: Test Loss = 0.2786\n",
            "Step 356: Training Loss = 0.3246\n",
            "Step 356: Test Loss = 0.2640\n",
            "Step 357: Training Loss = 0.2749\n",
            "Step 357: Test Loss = 0.2167\n",
            "Step 358: Training Loss = 0.4330\n",
            "Step 358: Test Loss = 0.3311\n",
            "Step 359: Training Loss = 0.3566\n",
            "Step 359: Test Loss = 0.2948\n",
            "Step 360: Training Loss = 0.3132\n",
            "Step 360: Test Loss = 0.2350\n",
            "Step 361: Training Loss = 0.3553\n",
            "Step 361: Test Loss = 0.2995\n",
            "Step 362: Training Loss = 0.3902\n",
            "Step 362: Test Loss = 0.2757\n",
            "Step 363: Training Loss = 0.3456\n",
            "Step 363: Test Loss = 0.2725\n",
            "Step 364: Training Loss = 0.4036\n",
            "Step 364: Test Loss = 0.2933\n",
            "Step 365: Training Loss = 0.4601\n",
            "Step 365: Test Loss = 0.3037\n",
            "Step 366: Training Loss = 0.3404\n",
            "Step 366: Test Loss = 0.2727\n",
            "Step 367: Training Loss = 0.2332\n",
            "Step 367: Test Loss = 0.1675\n",
            "Step 368: Training Loss = 0.3081\n",
            "Step 368: Test Loss = 0.2609\n",
            "Step 369: Training Loss = 0.3222\n",
            "Step 369: Test Loss = 0.2301\n",
            "Step 370: Training Loss = 0.2761\n",
            "Step 370: Test Loss = 0.2196\n",
            "Step 371: Training Loss = 0.2744\n",
            "Step 371: Test Loss = 0.2002\n",
            "Step 372: Training Loss = 0.2507\n",
            "Step 372: Test Loss = 0.1984\n",
            "Step 373: Training Loss = 0.3612\n",
            "Step 373: Test Loss = 0.2760\n",
            "Step 374: Training Loss = 0.3007\n",
            "Step 374: Test Loss = 0.2175\n",
            "Step 375: Training Loss = 0.3431\n",
            "Step 375: Test Loss = 0.2301\n",
            "Step 376: Training Loss = 0.3098\n",
            "Step 376: Test Loss = 0.1969\n",
            "Step 377: Training Loss = 0.2433\n",
            "Step 377: Test Loss = 0.1788\n",
            "Step 378: Training Loss = 0.2307\n",
            "Step 378: Test Loss = 0.1982\n",
            "Step 379: Training Loss = 0.2727\n",
            "Step 379: Test Loss = 0.2314\n",
            "Step 380: Training Loss = 0.2833\n",
            "Step 380: Test Loss = 0.1853\n",
            "Step 381: Training Loss = 0.4286\n",
            "Step 381: Test Loss = 0.2742\n",
            "Step 382: Training Loss = 0.2517\n",
            "Step 382: Test Loss = 0.1877\n",
            "Step 383: Training Loss = 0.4048\n",
            "Step 383: Test Loss = 0.2863\n",
            "Step 384: Training Loss = 0.2720\n",
            "Step 384: Test Loss = 0.1759\n",
            "Step 385: Training Loss = 0.2272\n",
            "Step 385: Test Loss = 0.1628\n",
            "Step 386: Training Loss = 0.2892\n",
            "Step 386: Test Loss = 0.2160\n",
            "Step 387: Training Loss = 0.3201\n",
            "Step 387: Test Loss = 0.2536\n",
            "Step 388: Training Loss = 0.2067\n",
            "Step 388: Test Loss = 0.1473\n",
            "Step 389: Training Loss = 0.3467\n",
            "Step 389: Test Loss = 0.2115\n",
            "Step 390: Training Loss = 0.3459\n",
            "Step 390: Test Loss = 0.2523\n",
            "Step 391: Training Loss = 0.2245\n",
            "Step 391: Test Loss = 0.1785\n",
            "Step 392: Training Loss = 0.3325\n",
            "Step 392: Test Loss = 0.2712\n",
            "Step 393: Training Loss = 0.3290\n",
            "Step 393: Test Loss = 0.2179\n",
            "Step 394: Training Loss = 0.3817\n",
            "Step 394: Test Loss = 0.2887\n",
            "Step 395: Training Loss = 0.5355\n",
            "Step 395: Test Loss = 0.4080\n",
            "Step 396: Training Loss = 0.3064\n",
            "Step 396: Test Loss = 0.2342\n",
            "Step 397: Training Loss = 0.3606\n",
            "Step 397: Test Loss = 0.2486\n",
            "Step 398: Training Loss = 0.3348\n",
            "Step 398: Test Loss = 0.2521\n",
            "Step 399: Training Loss = 0.2523\n",
            "Step 399: Test Loss = 0.1874\n",
            "Step 400: Training Loss = 0.3590\n",
            "Step 400: Test Loss = 0.2244\n",
            "400 20% (0m 46s) Train Loss: 0.3300, Test Loss: 0.2450, Accuracy: 0.8826 - lustukleri icin  Onlari orada yargilayacagim. Cunk / turkish ✓\n",
            "Step 401: Training Loss = 0.3519\n",
            "Step 401: Test Loss = 0.2625\n",
            "Step 402: Training Loss = 0.2631\n",
            "Step 402: Test Loss = 0.1817\n",
            "Step 403: Training Loss = 0.2723\n",
            "Step 403: Test Loss = 0.1910\n",
            "Step 404: Training Loss = 0.2875\n",
            "Step 404: Test Loss = 0.2110\n",
            "Step 405: Training Loss = 0.4403\n",
            "Step 405: Test Loss = 0.3301\n",
            "Step 406: Training Loss = 0.3148\n",
            "Step 406: Test Loss = 0.2275\n",
            "Step 407: Training Loss = 0.3322\n",
            "Step 407: Test Loss = 0.2036\n",
            "Step 408: Training Loss = 0.2354\n",
            "Step 408: Test Loss = 0.1799\n",
            "Step 409: Training Loss = 0.2569\n",
            "Step 409: Test Loss = 0.2117\n",
            "Step 410: Training Loss = 0.3496\n",
            "Step 410: Test Loss = 0.2710\n",
            "Step 411: Training Loss = 0.2466\n",
            "Step 411: Test Loss = 0.1609\n",
            "Step 412: Training Loss = 0.3368\n",
            "Step 412: Test Loss = 0.2237\n",
            "Step 413: Training Loss = 0.2160\n",
            "Step 413: Test Loss = 0.1459\n",
            "Step 414: Training Loss = 0.3287\n",
            "Step 414: Test Loss = 0.2773\n",
            "Step 415: Training Loss = 0.4453\n",
            "Step 415: Test Loss = 0.3346\n",
            "Step 416: Training Loss = 0.3138\n",
            "Step 416: Test Loss = 0.2513\n",
            "Step 417: Training Loss = 0.2749\n",
            "Step 417: Test Loss = 0.2010\n",
            "Step 418: Training Loss = 0.3081\n",
            "Step 418: Test Loss = 0.2156\n",
            "Step 419: Training Loss = 0.2944\n",
            "Step 419: Test Loss = 0.2548\n",
            "Step 420: Training Loss = 0.3379\n",
            "Step 420: Test Loss = 0.2587\n",
            "Step 421: Training Loss = 0.3325\n",
            "Step 421: Test Loss = 0.2358\n",
            "Step 422: Training Loss = 0.1663\n",
            "Step 422: Test Loss = 0.1125\n",
            "Step 423: Training Loss = 0.2498\n",
            "Step 423: Test Loss = 0.1965\n",
            "Step 424: Training Loss = 0.2431\n",
            "Step 424: Test Loss = 0.1683\n",
            "Step 425: Training Loss = 0.2715\n",
            "Step 425: Test Loss = 0.2006\n",
            "Step 426: Training Loss = 0.2229\n",
            "Step 426: Test Loss = 0.1493\n",
            "Step 427: Training Loss = 0.3387\n",
            "Step 427: Test Loss = 0.2408\n",
            "Step 428: Training Loss = 0.2219\n",
            "Step 428: Test Loss = 0.1568\n",
            "Step 429: Training Loss = 0.2412\n",
            "Step 429: Test Loss = 0.2008\n",
            "Step 430: Training Loss = 0.2230\n",
            "Step 430: Test Loss = 0.1430\n",
            "Step 431: Training Loss = 0.1001\n",
            "Step 431: Test Loss = 0.0823\n",
            "Step 432: Training Loss = 0.2441\n",
            "Step 432: Test Loss = 0.1673\n",
            "Step 433: Training Loss = 0.2668\n",
            "Step 433: Test Loss = 0.2033\n",
            "Step 434: Training Loss = 0.2761\n",
            "Step 434: Test Loss = 0.1640\n",
            "Step 435: Training Loss = 0.3157\n",
            "Step 435: Test Loss = 0.2218\n",
            "Step 436: Training Loss = 0.2020\n",
            "Step 436: Test Loss = 0.1177\n",
            "Step 437: Training Loss = 0.2576\n",
            "Step 437: Test Loss = 0.1925\n",
            "Step 438: Training Loss = 0.3650\n",
            "Step 438: Test Loss = 0.2478\n",
            "Step 439: Training Loss = 0.1592\n",
            "Step 439: Test Loss = 0.1392\n",
            "Step 440: Training Loss = 0.2003\n",
            "Step 440: Test Loss = 0.1503\n",
            "Step 441: Training Loss = 0.2890\n",
            "Step 441: Test Loss = 0.2148\n",
            "Step 442: Training Loss = 0.3463\n",
            "Step 442: Test Loss = 0.2871\n",
            "Step 443: Training Loss = 0.4309\n",
            "Step 443: Test Loss = 0.3186\n",
            "Step 444: Training Loss = 0.2231\n",
            "Step 444: Test Loss = 0.1688\n",
            "Step 445: Training Loss = 0.1986\n",
            "Step 445: Test Loss = 0.1526\n",
            "Step 446: Training Loss = 0.2473\n",
            "Step 446: Test Loss = 0.2119\n",
            "Step 447: Training Loss = 0.3238\n",
            "Step 447: Test Loss = 0.2317\n",
            "Step 448: Training Loss = 0.1257\n",
            "Step 448: Test Loss = 0.0899\n",
            "Step 449: Training Loss = 0.3339\n",
            "Step 449: Test Loss = 0.2310\n",
            "Step 450: Training Loss = 0.2781\n",
            "Step 450: Test Loss = 0.2101\n",
            "Step 451: Training Loss = 0.2556\n",
            "Step 451: Test Loss = 0.2060\n",
            "Step 452: Training Loss = 0.2151\n",
            "Step 452: Test Loss = 0.1721\n",
            "Step 453: Training Loss = 0.2391\n",
            "Step 453: Test Loss = 0.1627\n",
            "Step 454: Training Loss = 0.2595\n",
            "Step 454: Test Loss = 0.2069\n",
            "Step 455: Training Loss = 0.2073\n",
            "Step 455: Test Loss = 0.1458\n",
            "Step 456: Training Loss = 0.2289\n",
            "Step 456: Test Loss = 0.1811\n",
            "Step 457: Training Loss = 0.2990\n",
            "Step 457: Test Loss = 0.2221\n",
            "Step 458: Training Loss = 0.2953\n",
            "Step 458: Test Loss = 0.2277\n",
            "Step 459: Training Loss = 0.1817\n",
            "Step 459: Test Loss = 0.1453\n",
            "Step 460: Training Loss = 0.2289\n",
            "Step 460: Test Loss = 0.1715\n",
            "Step 461: Training Loss = 0.2328\n",
            "Step 461: Test Loss = 0.1472\n",
            "Step 462: Training Loss = 0.2477\n",
            "Step 462: Test Loss = 0.1587\n",
            "Step 463: Training Loss = 0.1938\n",
            "Step 463: Test Loss = 0.1341\n",
            "Step 464: Training Loss = 0.2055\n",
            "Step 464: Test Loss = 0.1602\n",
            "Step 465: Training Loss = 0.2170\n",
            "Step 465: Test Loss = 0.1765\n",
            "Step 466: Training Loss = 0.3989\n",
            "Step 466: Test Loss = 0.2681\n",
            "Step 467: Training Loss = 0.2614\n",
            "Step 467: Test Loss = 0.2007\n",
            "Step 468: Training Loss = 0.1999\n",
            "Step 468: Test Loss = 0.1239\n",
            "Step 469: Training Loss = 0.2323\n",
            "Step 469: Test Loss = 0.1933\n",
            "Step 470: Training Loss = 0.2078\n",
            "Step 470: Test Loss = 0.1560\n",
            "Step 471: Training Loss = 0.1642\n",
            "Step 471: Test Loss = 0.1160\n",
            "Step 472: Training Loss = 0.3054\n",
            "Step 472: Test Loss = 0.2469\n",
            "Step 473: Training Loss = 0.2453\n",
            "Step 473: Test Loss = 0.1764\n",
            "Step 474: Training Loss = 0.2819\n",
            "Step 474: Test Loss = 0.2338\n",
            "Step 475: Training Loss = 0.2228\n",
            "Step 475: Test Loss = 0.1566\n",
            "Step 476: Training Loss = 0.2751\n",
            "Step 476: Test Loss = 0.1963\n",
            "Step 477: Training Loss = 0.2718\n",
            "Step 477: Test Loss = 0.2096\n",
            "Step 478: Training Loss = 0.2781\n",
            "Step 478: Test Loss = 0.1836\n",
            "Step 479: Training Loss = 0.1820\n",
            "Step 479: Test Loss = 0.1598\n",
            "Step 480: Training Loss = 0.2206\n",
            "Step 480: Test Loss = 0.1809\n",
            "Step 481: Training Loss = 0.2733\n",
            "Step 481: Test Loss = 0.1895\n",
            "Step 482: Training Loss = 0.4437\n",
            "Step 482: Test Loss = 0.2907\n",
            "Step 483: Training Loss = 0.3128\n",
            "Step 483: Test Loss = 0.2477\n",
            "Step 484: Training Loss = 0.2852\n",
            "Step 484: Test Loss = 0.2040\n",
            "Step 485: Training Loss = 0.1886\n",
            "Step 485: Test Loss = 0.1548\n",
            "Step 486: Training Loss = 0.1381\n",
            "Step 486: Test Loss = 0.0986\n",
            "Step 487: Training Loss = 0.3114\n",
            "Step 487: Test Loss = 0.2066\n",
            "Step 488: Training Loss = 0.2899\n",
            "Step 488: Test Loss = 0.1980\n",
            "Step 489: Training Loss = 0.2426\n",
            "Step 489: Test Loss = 0.1773\n",
            "Step 490: Training Loss = 0.3701\n",
            "Step 490: Test Loss = 0.2886\n",
            "Step 491: Training Loss = 0.1477\n",
            "Step 491: Test Loss = 0.1044\n",
            "Step 492: Training Loss = 0.3709\n",
            "Step 492: Test Loss = 0.2575\n",
            "Step 493: Training Loss = 0.2843\n",
            "Step 493: Test Loss = 0.1719\n",
            "Step 494: Training Loss = 0.2571\n",
            "Step 494: Test Loss = 0.2071\n",
            "Step 495: Training Loss = 0.3247\n",
            "Step 495: Test Loss = 0.2107\n",
            "Step 496: Training Loss = 0.3287\n",
            "Step 496: Test Loss = 0.2843\n",
            "Step 497: Training Loss = 0.2174\n",
            "Step 497: Test Loss = 0.1530\n",
            "Step 498: Training Loss = 0.3004\n",
            "Step 498: Test Loss = 0.2191\n",
            "Step 499: Training Loss = 0.1409\n",
            "Step 499: Test Loss = 0.1017\n",
            "Step 500: Training Loss = 0.2518\n",
            "Step 500: Test Loss = 0.1679\n",
            "500 25% (0m 58s) Train Loss: 0.2664, Test Loss: 0.1955, Accuracy: 0.9016 - ada davanti a me queste tre volte; se non fosse us / portuguese ✗ (italian)\n",
            "Step 501: Training Loss = 0.3588\n",
            "Step 501: Test Loss = 0.2909\n",
            "Step 502: Training Loss = 0.2592\n",
            "Step 502: Test Loss = 0.1905\n",
            "Step 503: Training Loss = 0.1478\n",
            "Step 503: Test Loss = 0.0879\n",
            "Step 504: Training Loss = 0.2426\n",
            "Step 504: Test Loss = 0.1625\n",
            "Step 505: Training Loss = 0.2242\n",
            "Step 505: Test Loss = 0.1480\n",
            "Step 506: Training Loss = 0.1229\n",
            "Step 506: Test Loss = 0.0879\n",
            "Step 507: Training Loss = 0.2034\n",
            "Step 507: Test Loss = 0.1620\n",
            "Step 508: Training Loss = 0.2848\n",
            "Step 508: Test Loss = 0.2166\n",
            "Step 509: Training Loss = 0.2178\n",
            "Step 509: Test Loss = 0.1546\n",
            "Step 510: Training Loss = 0.1947\n",
            "Step 510: Test Loss = 0.1144\n",
            "Step 511: Training Loss = 0.2511\n",
            "Step 511: Test Loss = 0.1937\n",
            "Step 512: Training Loss = 0.1002\n",
            "Step 512: Test Loss = 0.0800\n",
            "Step 513: Training Loss = 0.1845\n",
            "Step 513: Test Loss = 0.1319\n",
            "Step 514: Training Loss = 0.2729\n",
            "Step 514: Test Loss = 0.1406\n",
            "Step 515: Training Loss = 0.2405\n",
            "Step 515: Test Loss = 0.1779\n",
            "Step 516: Training Loss = 0.1923\n",
            "Step 516: Test Loss = 0.1055\n",
            "Step 517: Training Loss = 0.2067\n",
            "Step 517: Test Loss = 0.1668\n",
            "Step 518: Training Loss = 0.3036\n",
            "Step 518: Test Loss = 0.1929\n",
            "Step 519: Training Loss = 0.0963\n",
            "Step 519: Test Loss = 0.0830\n",
            "Step 520: Training Loss = 0.2003\n",
            "Step 520: Test Loss = 0.1524\n",
            "Step 521: Training Loss = 0.3344\n",
            "Step 521: Test Loss = 0.2520\n",
            "Step 522: Training Loss = 0.1258\n",
            "Step 522: Test Loss = 0.1039\n",
            "Step 523: Training Loss = 0.2614\n",
            "Step 523: Test Loss = 0.2107\n",
            "Step 524: Training Loss = 0.1614\n",
            "Step 524: Test Loss = 0.1206\n",
            "Step 525: Training Loss = 0.2236\n",
            "Step 525: Test Loss = 0.1639\n",
            "Step 526: Training Loss = 0.2902\n",
            "Step 526: Test Loss = 0.1349\n",
            "Step 527: Training Loss = 0.3855\n",
            "Step 527: Test Loss = 0.2832\n",
            "Step 528: Training Loss = 0.1503\n",
            "Step 528: Test Loss = 0.1144\n",
            "Step 529: Training Loss = 0.3729\n",
            "Step 529: Test Loss = 0.2430\n",
            "Step 530: Training Loss = 0.3018\n",
            "Step 530: Test Loss = 0.1758\n",
            "Step 531: Training Loss = 0.2828\n",
            "Step 531: Test Loss = 0.1779\n",
            "Step 532: Training Loss = 0.2806\n",
            "Step 532: Test Loss = 0.2011\n",
            "Step 533: Training Loss = 0.1904\n",
            "Step 533: Test Loss = 0.1643\n",
            "Step 534: Training Loss = 0.3423\n",
            "Step 534: Test Loss = 0.2496\n",
            "Step 535: Training Loss = 0.1805\n",
            "Step 535: Test Loss = 0.1088\n",
            "Step 536: Training Loss = 0.1901\n",
            "Step 536: Test Loss = 0.1170\n",
            "Step 537: Training Loss = 0.4103\n",
            "Step 537: Test Loss = 0.3184\n",
            "Step 538: Training Loss = 0.2706\n",
            "Step 538: Test Loss = 0.1968\n",
            "Step 539: Training Loss = 0.1876\n",
            "Step 539: Test Loss = 0.1474\n",
            "Step 540: Training Loss = 0.1499\n",
            "Step 540: Test Loss = 0.1201\n",
            "Step 541: Training Loss = 0.1843\n",
            "Step 541: Test Loss = 0.1217\n",
            "Step 542: Training Loss = 0.1855\n",
            "Step 542: Test Loss = 0.1543\n",
            "Step 543: Training Loss = 0.2038\n",
            "Step 543: Test Loss = 0.1352\n",
            "Step 544: Training Loss = 0.1552\n",
            "Step 544: Test Loss = 0.1209\n",
            "Step 545: Training Loss = 0.2404\n",
            "Step 545: Test Loss = 0.1414\n",
            "Step 546: Training Loss = 0.2401\n",
            "Step 546: Test Loss = 0.1652\n",
            "Step 547: Training Loss = 0.3896\n",
            "Step 547: Test Loss = 0.3171\n",
            "Step 548: Training Loss = 0.2578\n",
            "Step 548: Test Loss = 0.2003\n",
            "Step 549: Training Loss = 0.1432\n",
            "Step 549: Test Loss = 0.1076\n",
            "Step 550: Training Loss = 0.3135\n",
            "Step 550: Test Loss = 0.2180\n",
            "Step 551: Training Loss = 0.1826\n",
            "Step 551: Test Loss = 0.1543\n",
            "Step 552: Training Loss = 0.1442\n",
            "Step 552: Test Loss = 0.0966\n",
            "Step 553: Training Loss = 0.2275\n",
            "Step 553: Test Loss = 0.1241\n",
            "Step 554: Training Loss = 0.2123\n",
            "Step 554: Test Loss = 0.1543\n",
            "Step 555: Training Loss = 0.1971\n",
            "Step 555: Test Loss = 0.1293\n",
            "Step 556: Training Loss = 0.1528\n",
            "Step 556: Test Loss = 0.1172\n",
            "Step 557: Training Loss = 0.2098\n",
            "Step 557: Test Loss = 0.1404\n",
            "Step 558: Training Loss = 0.2627\n",
            "Step 558: Test Loss = 0.1600\n",
            "Step 559: Training Loss = 0.1686\n",
            "Step 559: Test Loss = 0.1185\n",
            "Step 560: Training Loss = 0.1685\n",
            "Step 560: Test Loss = 0.1321\n",
            "Step 561: Training Loss = 0.1739\n",
            "Step 561: Test Loss = 0.1117\n",
            "Step 562: Training Loss = 0.1758\n",
            "Step 562: Test Loss = 0.1072\n",
            "Step 563: Training Loss = 0.2360\n",
            "Step 563: Test Loss = 0.1929\n",
            "Step 564: Training Loss = 0.3390\n",
            "Step 564: Test Loss = 0.2539\n",
            "Step 565: Training Loss = 0.3034\n",
            "Step 565: Test Loss = 0.2363\n",
            "Step 566: Training Loss = 0.2436\n",
            "Step 566: Test Loss = 0.1626\n",
            "Step 567: Training Loss = 0.2254\n",
            "Step 567: Test Loss = 0.1345\n",
            "Step 568: Training Loss = 0.2764\n",
            "Step 568: Test Loss = 0.2010\n",
            "Step 569: Training Loss = 0.2076\n",
            "Step 569: Test Loss = 0.1709\n",
            "Step 570: Training Loss = 0.2177\n",
            "Step 570: Test Loss = 0.1298\n",
            "Step 571: Training Loss = 0.1397\n",
            "Step 571: Test Loss = 0.1070\n",
            "Step 572: Training Loss = 0.2099\n",
            "Step 572: Test Loss = 0.1587\n",
            "Step 573: Training Loss = 0.2056\n",
            "Step 573: Test Loss = 0.1501\n",
            "Step 574: Training Loss = 0.1526\n",
            "Step 574: Test Loss = 0.1132\n",
            "Step 575: Training Loss = 0.2420\n",
            "Step 575: Test Loss = 0.1676\n",
            "Step 576: Training Loss = 0.2019\n",
            "Step 576: Test Loss = 0.1349\n",
            "Step 577: Training Loss = 0.1576\n",
            "Step 577: Test Loss = 0.0966\n",
            "Step 578: Training Loss = 0.2960\n",
            "Step 578: Test Loss = 0.1692\n",
            "Step 579: Training Loss = 0.1278\n",
            "Step 579: Test Loss = 0.0970\n",
            "Step 580: Training Loss = 0.2448\n",
            "Step 580: Test Loss = 0.1740\n",
            "Step 581: Training Loss = 0.2335\n",
            "Step 581: Test Loss = 0.1525\n",
            "Step 582: Training Loss = 0.1256\n",
            "Step 582: Test Loss = 0.0871\n",
            "Step 583: Training Loss = 0.3055\n",
            "Step 583: Test Loss = 0.2390\n",
            "Step 584: Training Loss = 0.2794\n",
            "Step 584: Test Loss = 0.1762\n",
            "Step 585: Training Loss = 0.1240\n",
            "Step 585: Test Loss = 0.0906\n",
            "Step 586: Training Loss = 0.3396\n",
            "Step 586: Test Loss = 0.2580\n",
            "Step 587: Training Loss = 0.2445\n",
            "Step 587: Test Loss = 0.1553\n",
            "Step 588: Training Loss = 0.1450\n",
            "Step 588: Test Loss = 0.1100\n",
            "Step 589: Training Loss = 0.2238\n",
            "Step 589: Test Loss = 0.1649\n",
            "Step 590: Training Loss = 0.3057\n",
            "Step 590: Test Loss = 0.2239\n",
            "Step 591: Training Loss = 0.2573\n",
            "Step 591: Test Loss = 0.1406\n",
            "Step 592: Training Loss = 0.2618\n",
            "Step 592: Test Loss = 0.1764\n",
            "Step 593: Training Loss = 0.1166\n",
            "Step 593: Test Loss = 0.0813\n",
            "Step 594: Training Loss = 0.1225\n",
            "Step 594: Test Loss = 0.0860\n",
            "Step 595: Training Loss = 0.3050\n",
            "Step 595: Test Loss = 0.2057\n",
            "Step 596: Training Loss = 0.1943\n",
            "Step 596: Test Loss = 0.1060\n",
            "Step 597: Training Loss = 0.1602\n",
            "Step 597: Test Loss = 0.1359\n",
            "Step 598: Training Loss = 0.1873\n",
            "Step 598: Test Loss = 0.1414\n",
            "Step 599: Training Loss = 0.2129\n",
            "Step 599: Test Loss = 0.1490\n",
            "Step 600: Training Loss = 0.2082\n",
            "Step 600: Test Loss = 0.1606\n",
            "600 30% (1m 10s) Train Loss: 0.2237, Test Loss: 0.1576, Accuracy: 0.9229 - a dagen en gang omkring staden och atervande sedan / swedish ✓\n",
            "Step 601: Training Loss = 0.1800\n",
            "Step 601: Test Loss = 0.1221\n",
            "Step 602: Training Loss = 0.3184\n",
            "Step 602: Test Loss = 0.2105\n",
            "Step 603: Training Loss = 0.2552\n",
            "Step 603: Test Loss = 0.1671\n",
            "Step 604: Training Loss = 0.1731\n",
            "Step 604: Test Loss = 0.1101\n",
            "Step 605: Training Loss = 0.1266\n",
            "Step 605: Test Loss = 0.0800\n",
            "Step 606: Training Loss = 0.3124\n",
            "Step 606: Test Loss = 0.1866\n",
            "Step 607: Training Loss = 0.2326\n",
            "Step 607: Test Loss = 0.1568\n",
            "Step 608: Training Loss = 0.3601\n",
            "Step 608: Test Loss = 0.2346\n",
            "Step 609: Training Loss = 0.1545\n",
            "Step 609: Test Loss = 0.0926\n",
            "Step 610: Training Loss = 0.1028\n",
            "Step 610: Test Loss = 0.0788\n",
            "Step 611: Training Loss = 0.2226\n",
            "Step 611: Test Loss = 0.1723\n",
            "Step 612: Training Loss = 0.3085\n",
            "Step 612: Test Loss = 0.2107\n",
            "Step 613: Training Loss = 0.2891\n",
            "Step 613: Test Loss = 0.1858\n",
            "Step 614: Training Loss = 0.0908\n",
            "Step 614: Test Loss = 0.0621\n",
            "Step 615: Training Loss = 0.1685\n",
            "Step 615: Test Loss = 0.0948\n",
            "Step 616: Training Loss = 0.2910\n",
            "Step 616: Test Loss = 0.2062\n",
            "Step 617: Training Loss = 0.1542\n",
            "Step 617: Test Loss = 0.1094\n",
            "Step 618: Training Loss = 0.1316\n",
            "Step 618: Test Loss = 0.0947\n",
            "Step 619: Training Loss = 0.1614\n",
            "Step 619: Test Loss = 0.1262\n",
            "Step 620: Training Loss = 0.1976\n",
            "Step 620: Test Loss = 0.1457\n",
            "Step 621: Training Loss = 0.2222\n",
            "Step 621: Test Loss = 0.1647\n",
            "Step 622: Training Loss = 0.2181\n",
            "Step 622: Test Loss = 0.1125\n",
            "Step 623: Training Loss = 0.2115\n",
            "Step 623: Test Loss = 0.1386\n",
            "Step 624: Training Loss = 0.3169\n",
            "Step 624: Test Loss = 0.2184\n",
            "Step 625: Training Loss = 0.0718\n",
            "Step 625: Test Loss = 0.0524\n",
            "Step 626: Training Loss = 0.1974\n",
            "Step 626: Test Loss = 0.1450\n",
            "Step 627: Training Loss = 0.1530\n",
            "Step 627: Test Loss = 0.1166\n",
            "Step 628: Training Loss = 0.2259\n",
            "Step 628: Test Loss = 0.1564\n",
            "Step 629: Training Loss = 0.2015\n",
            "Step 629: Test Loss = 0.1096\n",
            "Step 630: Training Loss = 0.2284\n",
            "Step 630: Test Loss = 0.1468\n",
            "Step 631: Training Loss = 0.1648\n",
            "Step 631: Test Loss = 0.1241\n",
            "Step 632: Training Loss = 0.1499\n",
            "Step 632: Test Loss = 0.0909\n",
            "Step 633: Training Loss = 0.3595\n",
            "Step 633: Test Loss = 0.2379\n",
            "Step 634: Training Loss = 0.2453\n",
            "Step 634: Test Loss = 0.1397\n",
            "Step 635: Training Loss = 0.1674\n",
            "Step 635: Test Loss = 0.1333\n",
            "Step 636: Training Loss = 0.2371\n",
            "Step 636: Test Loss = 0.1159\n",
            "Step 637: Training Loss = 0.2470\n",
            "Step 637: Test Loss = 0.1691\n",
            "Step 638: Training Loss = 0.3024\n",
            "Step 638: Test Loss = 0.2002\n",
            "Step 639: Training Loss = 0.1611\n",
            "Step 639: Test Loss = 0.1104\n",
            "Step 640: Training Loss = 0.2272\n",
            "Step 640: Test Loss = 0.1689\n",
            "Step 641: Training Loss = 0.2532\n",
            "Step 641: Test Loss = 0.1753\n",
            "Step 642: Training Loss = 0.1243\n",
            "Step 642: Test Loss = 0.1089\n",
            "Step 643: Training Loss = 0.2993\n",
            "Step 643: Test Loss = 0.1790\n",
            "Step 644: Training Loss = 0.1795\n",
            "Step 644: Test Loss = 0.1410\n",
            "Step 645: Training Loss = 0.2195\n",
            "Step 645: Test Loss = 0.1473\n",
            "Step 646: Training Loss = 0.3292\n",
            "Step 646: Test Loss = 0.2427\n",
            "Step 647: Training Loss = 0.1775\n",
            "Step 647: Test Loss = 0.0999\n",
            "Step 648: Training Loss = 0.1262\n",
            "Step 648: Test Loss = 0.0894\n",
            "Step 649: Training Loss = 0.1945\n",
            "Step 649: Test Loss = 0.1214\n",
            "Step 650: Training Loss = 0.2022\n",
            "Step 650: Test Loss = 0.1393\n",
            "Step 651: Training Loss = 0.2605\n",
            "Step 651: Test Loss = 0.1760\n",
            "Step 652: Training Loss = 0.1594\n",
            "Step 652: Test Loss = 0.0799\n",
            "Step 653: Training Loss = 0.1983\n",
            "Step 653: Test Loss = 0.1284\n",
            "Step 654: Training Loss = 0.2014\n",
            "Step 654: Test Loss = 0.1270\n",
            "Step 655: Training Loss = 0.2006\n",
            "Step 655: Test Loss = 0.1284\n",
            "Step 656: Training Loss = 0.1887\n",
            "Step 656: Test Loss = 0.1459\n",
            "Step 657: Training Loss = 0.2070\n",
            "Step 657: Test Loss = 0.1295\n",
            "Step 658: Training Loss = 0.2105\n",
            "Step 658: Test Loss = 0.1646\n",
            "Step 659: Training Loss = 0.1966\n",
            "Step 659: Test Loss = 0.1309\n",
            "Step 660: Training Loss = 0.1493\n",
            "Step 660: Test Loss = 0.1084\n",
            "Step 661: Training Loss = 0.1786\n",
            "Step 661: Test Loss = 0.1201\n",
            "Step 662: Training Loss = 0.2273\n",
            "Step 662: Test Loss = 0.1478\n",
            "Step 663: Training Loss = 0.1361\n",
            "Step 663: Test Loss = 0.0819\n",
            "Step 664: Training Loss = 0.2709\n",
            "Step 664: Test Loss = 0.1806\n",
            "Step 665: Training Loss = 0.2948\n",
            "Step 665: Test Loss = 0.2332\n",
            "Step 666: Training Loss = 0.1801\n",
            "Step 666: Test Loss = 0.1137\n",
            "Step 667: Training Loss = 0.3274\n",
            "Step 667: Test Loss = 0.1739\n",
            "Step 668: Training Loss = 0.1690\n",
            "Step 668: Test Loss = 0.1019\n",
            "Step 669: Training Loss = 0.2669\n",
            "Step 669: Test Loss = 0.1783\n",
            "Step 670: Training Loss = 0.2402\n",
            "Step 670: Test Loss = 0.1561\n",
            "Step 671: Training Loss = 0.2702\n",
            "Step 671: Test Loss = 0.1885\n",
            "Step 672: Training Loss = 0.2424\n",
            "Step 672: Test Loss = 0.1700\n",
            "Step 673: Training Loss = 0.2414\n",
            "Step 673: Test Loss = 0.1457\n",
            "Step 674: Training Loss = 0.3262\n",
            "Step 674: Test Loss = 0.2488\n",
            "Step 675: Training Loss = 0.1315\n",
            "Step 675: Test Loss = 0.0751\n",
            "Step 676: Training Loss = 0.2367\n",
            "Step 676: Test Loss = 0.1389\n",
            "Step 677: Training Loss = 0.1698\n",
            "Step 677: Test Loss = 0.1216\n",
            "Step 678: Training Loss = 0.0864\n",
            "Step 678: Test Loss = 0.0688\n",
            "Step 679: Training Loss = 0.1868\n",
            "Step 679: Test Loss = 0.1076\n",
            "Step 680: Training Loss = 0.1952\n",
            "Step 680: Test Loss = 0.1401\n",
            "Step 681: Training Loss = 0.1486\n",
            "Step 681: Test Loss = 0.1255\n",
            "Step 682: Training Loss = 0.1125\n",
            "Step 682: Test Loss = 0.0868\n",
            "Step 683: Training Loss = 0.2403\n",
            "Step 683: Test Loss = 0.1422\n",
            "Step 684: Training Loss = 0.2137\n",
            "Step 684: Test Loss = 0.1063\n",
            "Step 685: Training Loss = 0.1003\n",
            "Step 685: Test Loss = 0.0735\n",
            "Step 686: Training Loss = 0.1394\n",
            "Step 686: Test Loss = 0.1036\n",
            "Step 687: Training Loss = 0.2146\n",
            "Step 687: Test Loss = 0.1179\n",
            "Step 688: Training Loss = 0.1798\n",
            "Step 688: Test Loss = 0.1135\n",
            "Step 689: Training Loss = 0.2247\n",
            "Step 689: Test Loss = 0.1309\n",
            "Step 690: Training Loss = 0.3424\n",
            "Step 690: Test Loss = 0.2171\n",
            "Step 691: Training Loss = 0.1694\n",
            "Step 691: Test Loss = 0.1235\n",
            "Step 692: Training Loss = 0.2740\n",
            "Step 692: Test Loss = 0.2068\n",
            "Step 693: Training Loss = 0.2035\n",
            "Step 693: Test Loss = 0.1549\n",
            "Step 694: Training Loss = 0.2523\n",
            "Step 694: Test Loss = 0.1967\n",
            "Step 695: Training Loss = 0.1647\n",
            "Step 695: Test Loss = 0.1192\n",
            "Step 696: Training Loss = 0.3302\n",
            "Step 696: Test Loss = 0.2168\n",
            "Step 697: Training Loss = 0.1002\n",
            "Step 697: Test Loss = 0.0949\n",
            "Step 698: Training Loss = 0.0902\n",
            "Step 698: Test Loss = 0.0619\n",
            "Step 699: Training Loss = 0.3116\n",
            "Step 699: Test Loss = 0.1824\n",
            "Step 700: Training Loss = 0.2877\n",
            "Step 700: Test Loss = 0.1566\n",
            "700 35% (1m 22s) Train Loss: 0.2109, Test Loss: 0.1408, Accuracy: 0.9254 - s as tribos de Israel, dez homens de cada cem, cem / french ✗ (portuguese)\n",
            "Step 701: Training Loss = 0.1572\n",
            "Step 701: Test Loss = 0.0958\n",
            "Step 702: Training Loss = 0.1543\n",
            "Step 702: Test Loss = 0.1196\n",
            "Step 703: Training Loss = 0.1723\n",
            "Step 703: Test Loss = 0.1227\n",
            "Step 704: Training Loss = 0.3278\n",
            "Step 704: Test Loss = 0.2451\n",
            "Step 705: Training Loss = 0.1838\n",
            "Step 705: Test Loss = 0.1433\n",
            "Step 706: Training Loss = 0.2625\n",
            "Step 706: Test Loss = 0.1874\n",
            "Step 707: Training Loss = 0.1327\n",
            "Step 707: Test Loss = 0.0577\n",
            "Step 708: Training Loss = 0.1415\n",
            "Step 708: Test Loss = 0.0989\n",
            "Step 709: Training Loss = 0.1200\n",
            "Step 709: Test Loss = 0.0774\n",
            "Step 710: Training Loss = 0.1581\n",
            "Step 710: Test Loss = 0.1053\n",
            "Step 711: Training Loss = 0.1820\n",
            "Step 711: Test Loss = 0.1081\n",
            "Step 712: Training Loss = 0.2308\n",
            "Step 712: Test Loss = 0.1619\n",
            "Step 713: Training Loss = 0.0975\n",
            "Step 713: Test Loss = 0.0602\n",
            "Step 714: Training Loss = 0.2104\n",
            "Step 714: Test Loss = 0.1631\n",
            "Step 715: Training Loss = 0.2182\n",
            "Step 715: Test Loss = 0.1234\n",
            "Step 716: Training Loss = 0.2174\n",
            "Step 716: Test Loss = 0.1404\n",
            "Step 717: Training Loss = 0.3201\n",
            "Step 717: Test Loss = 0.2001\n",
            "Step 718: Training Loss = 0.1845\n",
            "Step 718: Test Loss = 0.1303\n",
            "Step 719: Training Loss = 0.1310\n",
            "Step 719: Test Loss = 0.0789\n",
            "Step 720: Training Loss = 0.0909\n",
            "Step 720: Test Loss = 0.0740\n",
            "Step 721: Training Loss = 0.1478\n",
            "Step 721: Test Loss = 0.1086\n",
            "Step 722: Training Loss = 0.2498\n",
            "Step 722: Test Loss = 0.1392\n",
            "Step 723: Training Loss = 0.1717\n",
            "Step 723: Test Loss = 0.0910\n",
            "Step 724: Training Loss = 0.2789\n",
            "Step 724: Test Loss = 0.2082\n",
            "Step 725: Training Loss = 0.1936\n",
            "Step 725: Test Loss = 0.1231\n",
            "Step 726: Training Loss = 0.1009\n",
            "Step 726: Test Loss = 0.0566\n",
            "Step 727: Training Loss = 0.2106\n",
            "Step 727: Test Loss = 0.1425\n",
            "Step 728: Training Loss = 0.1932\n",
            "Step 728: Test Loss = 0.1114\n",
            "Step 729: Training Loss = 0.2607\n",
            "Step 729: Test Loss = 0.1398\n",
            "Step 730: Training Loss = 0.1048\n",
            "Step 730: Test Loss = 0.0653\n",
            "Step 731: Training Loss = 0.1922\n",
            "Step 731: Test Loss = 0.1206\n",
            "Step 732: Training Loss = 0.1941\n",
            "Step 732: Test Loss = 0.1056\n",
            "Step 733: Training Loss = 0.1420\n",
            "Step 733: Test Loss = 0.0831\n",
            "Step 734: Training Loss = 0.2171\n",
            "Step 734: Test Loss = 0.1518\n",
            "Step 735: Training Loss = 0.1593\n",
            "Step 735: Test Loss = 0.0846\n",
            "Step 736: Training Loss = 0.1322\n",
            "Step 736: Test Loss = 0.0854\n",
            "Step 737: Training Loss = 0.2025\n",
            "Step 737: Test Loss = 0.1346\n",
            "Step 738: Training Loss = 0.1785\n",
            "Step 738: Test Loss = 0.1265\n",
            "Step 739: Training Loss = 0.2922\n",
            "Step 739: Test Loss = 0.2085\n",
            "Step 740: Training Loss = 0.2683\n",
            "Step 740: Test Loss = 0.1817\n",
            "Step 741: Training Loss = 0.3084\n",
            "Step 741: Test Loss = 0.1967\n",
            "Step 742: Training Loss = 0.2215\n",
            "Step 742: Test Loss = 0.1633\n",
            "Step 743: Training Loss = 0.1499\n",
            "Step 743: Test Loss = 0.0892\n",
            "Step 744: Training Loss = 0.1466\n",
            "Step 744: Test Loss = 0.1090\n",
            "Step 745: Training Loss = 0.2589\n",
            "Step 745: Test Loss = 0.1354\n",
            "Step 746: Training Loss = 0.1656\n",
            "Step 746: Test Loss = 0.1059\n",
            "Step 747: Training Loss = 0.2679\n",
            "Step 747: Test Loss = 0.1422\n",
            "Step 748: Training Loss = 0.2175\n",
            "Step 748: Test Loss = 0.1325\n",
            "Step 749: Training Loss = 0.3223\n",
            "Step 749: Test Loss = 0.1891\n",
            "Step 750: Training Loss = 0.1620\n",
            "Step 750: Test Loss = 0.0982\n",
            "Step 751: Training Loss = 0.2309\n",
            "Step 751: Test Loss = 0.1584\n",
            "Step 752: Training Loss = 0.1619\n",
            "Step 752: Test Loss = 0.0837\n",
            "Step 753: Training Loss = 0.1185\n",
            "Step 753: Test Loss = 0.0952\n",
            "Step 754: Training Loss = 0.2760\n",
            "Step 754: Test Loss = 0.2069\n",
            "Step 755: Training Loss = 0.2927\n",
            "Step 755: Test Loss = 0.1977\n",
            "Step 756: Training Loss = 0.3401\n",
            "Step 756: Test Loss = 0.1720\n",
            "Step 757: Training Loss = 0.3534\n",
            "Step 757: Test Loss = 0.1429\n",
            "Step 758: Training Loss = 0.1591\n",
            "Step 758: Test Loss = 0.1082\n",
            "Step 759: Training Loss = 0.1552\n",
            "Step 759: Test Loss = 0.1205\n",
            "Step 760: Training Loss = 0.2172\n",
            "Step 760: Test Loss = 0.1754\n",
            "Step 761: Training Loss = 0.2058\n",
            "Step 761: Test Loss = 0.1408\n",
            "Step 762: Training Loss = 0.2064\n",
            "Step 762: Test Loss = 0.1139\n",
            "Step 763: Training Loss = 0.3324\n",
            "Step 763: Test Loss = 0.2523\n",
            "Step 764: Training Loss = 0.3549\n",
            "Step 764: Test Loss = 0.1704\n",
            "Step 765: Training Loss = 0.1366\n",
            "Step 765: Test Loss = 0.1021\n",
            "Step 766: Training Loss = 0.2722\n",
            "Step 766: Test Loss = 0.1746\n",
            "Step 767: Training Loss = 0.1188\n",
            "Step 767: Test Loss = 0.0767\n",
            "Step 768: Training Loss = 0.1584\n",
            "Step 768: Test Loss = 0.1115\n",
            "Step 769: Training Loss = 0.1186\n",
            "Step 769: Test Loss = 0.0766\n",
            "Step 770: Training Loss = 0.1765\n",
            "Step 770: Test Loss = 0.1198\n",
            "Step 771: Training Loss = 0.1356\n",
            "Step 771: Test Loss = 0.1042\n",
            "Step 772: Training Loss = 0.1803\n",
            "Step 772: Test Loss = 0.1084\n",
            "Step 773: Training Loss = 0.1721\n",
            "Step 773: Test Loss = 0.1025\n",
            "Step 774: Training Loss = 0.1281\n",
            "Step 774: Test Loss = 0.0874\n",
            "Step 775: Training Loss = 0.1856\n",
            "Step 775: Test Loss = 0.1049\n",
            "Step 776: Training Loss = 0.1783\n",
            "Step 776: Test Loss = 0.0716\n",
            "Step 777: Training Loss = 0.1121\n",
            "Step 777: Test Loss = 0.0827\n",
            "Step 778: Training Loss = 0.2233\n",
            "Step 778: Test Loss = 0.1303\n",
            "Step 779: Training Loss = 0.2234\n",
            "Step 779: Test Loss = 0.1506\n",
            "Step 780: Training Loss = 0.1650\n",
            "Step 780: Test Loss = 0.1179\n",
            "Step 781: Training Loss = 0.2010\n",
            "Step 781: Test Loss = 0.1368\n",
            "Step 782: Training Loss = 0.2044\n",
            "Step 782: Test Loss = 0.1468\n",
            "Step 783: Training Loss = 0.1899\n",
            "Step 783: Test Loss = 0.1218\n",
            "Step 784: Training Loss = 0.1981\n",
            "Step 784: Test Loss = 0.1155\n",
            "Step 785: Training Loss = 0.1867\n",
            "Step 785: Test Loss = 0.1084\n",
            "Step 786: Training Loss = 0.1886\n",
            "Step 786: Test Loss = 0.1106\n",
            "Step 787: Training Loss = 0.1063\n",
            "Step 787: Test Loss = 0.0771\n",
            "Step 788: Training Loss = 0.0817\n",
            "Step 788: Test Loss = 0.0541\n",
            "Step 789: Training Loss = 0.1245\n",
            "Step 789: Test Loss = 0.0989\n",
            "Step 790: Training Loss = 0.1098\n",
            "Step 790: Test Loss = 0.0859\n",
            "Step 791: Training Loss = 0.3017\n",
            "Step 791: Test Loss = 0.2100\n",
            "Step 792: Training Loss = 0.2100\n",
            "Step 792: Test Loss = 0.1181\n",
            "Step 793: Training Loss = 0.1973\n",
            "Step 793: Test Loss = 0.1171\n",
            "Step 794: Training Loss = 0.2601\n",
            "Step 794: Test Loss = 0.1571\n",
            "Step 795: Training Loss = 0.1396\n",
            "Step 795: Test Loss = 0.1083\n",
            "Step 796: Training Loss = 0.2012\n",
            "Step 796: Test Loss = 0.1174\n",
            "Step 797: Training Loss = 0.1454\n",
            "Step 797: Test Loss = 0.0903\n",
            "Step 798: Training Loss = 0.1168\n",
            "Step 798: Test Loss = 0.0984\n",
            "Step 799: Training Loss = 0.2125\n",
            "Step 799: Test Loss = 0.1184\n",
            "Step 800: Training Loss = 0.1511\n",
            "Step 800: Test Loss = 0.0912\n",
            "800 40% (1m 33s) Train Loss: 0.1942, Test Loss: 0.1247, Accuracy: 0.9334 - uds with great power and glory. And then shall he  / english ✓\n",
            "Step 801: Training Loss = 0.2114\n",
            "Step 801: Test Loss = 0.1103\n",
            "Step 802: Training Loss = 0.1765\n",
            "Step 802: Test Loss = 0.1142\n",
            "Step 803: Training Loss = 0.1352\n",
            "Step 803: Test Loss = 0.0772\n",
            "Step 804: Training Loss = 0.1225\n",
            "Step 804: Test Loss = 0.0784\n",
            "Step 805: Training Loss = 0.1359\n",
            "Step 805: Test Loss = 0.0896\n",
            "Step 806: Training Loss = 0.1490\n",
            "Step 806: Test Loss = 0.1046\n",
            "Step 807: Training Loss = 0.0943\n",
            "Step 807: Test Loss = 0.0641\n",
            "Step 808: Training Loss = 0.1329\n",
            "Step 808: Test Loss = 0.0800\n",
            "Step 809: Training Loss = 0.1614\n",
            "Step 809: Test Loss = 0.1171\n",
            "Step 810: Training Loss = 0.0878\n",
            "Step 810: Test Loss = 0.0620\n",
            "Step 811: Training Loss = 0.1527\n",
            "Step 811: Test Loss = 0.1015\n",
            "Step 812: Training Loss = 0.1417\n",
            "Step 812: Test Loss = 0.1060\n",
            "Step 813: Training Loss = 0.1694\n",
            "Step 813: Test Loss = 0.0865\n",
            "Step 814: Training Loss = 0.1962\n",
            "Step 814: Test Loss = 0.1313\n",
            "Step 815: Training Loss = 0.1806\n",
            "Step 815: Test Loss = 0.1156\n",
            "Step 816: Training Loss = 0.2129\n",
            "Step 816: Test Loss = 0.1440\n",
            "Step 817: Training Loss = 0.1665\n",
            "Step 817: Test Loss = 0.1189\n",
            "Step 818: Training Loss = 0.2106\n",
            "Step 818: Test Loss = 0.1380\n",
            "Step 819: Training Loss = 0.1104\n",
            "Step 819: Test Loss = 0.0762\n",
            "Step 820: Training Loss = 0.1174\n",
            "Step 820: Test Loss = 0.0927\n",
            "Step 821: Training Loss = 0.2847\n",
            "Step 821: Test Loss = 0.1681\n",
            "Step 822: Training Loss = 0.1816\n",
            "Step 822: Test Loss = 0.1334\n",
            "Step 823: Training Loss = 0.1295\n",
            "Step 823: Test Loss = 0.0982\n",
            "Step 824: Training Loss = 0.2468\n",
            "Step 824: Test Loss = 0.1347\n",
            "Step 825: Training Loss = 0.1606\n",
            "Step 825: Test Loss = 0.1172\n",
            "Step 826: Training Loss = 0.1853\n",
            "Step 826: Test Loss = 0.1068\n",
            "Step 827: Training Loss = 0.1885\n",
            "Step 827: Test Loss = 0.1381\n",
            "Step 828: Training Loss = 0.1085\n",
            "Step 828: Test Loss = 0.0613\n",
            "Step 829: Training Loss = 0.1144\n",
            "Step 829: Test Loss = 0.0879\n",
            "Step 830: Training Loss = 0.1026\n",
            "Step 830: Test Loss = 0.0535\n",
            "Step 831: Training Loss = 0.1964\n",
            "Step 831: Test Loss = 0.1212\n",
            "Step 832: Training Loss = 0.1925\n",
            "Step 832: Test Loss = 0.1320\n",
            "Step 833: Training Loss = 0.1165\n",
            "Step 833: Test Loss = 0.0711\n",
            "Step 834: Training Loss = 0.1695\n",
            "Step 834: Test Loss = 0.0999\n",
            "Step 835: Training Loss = 0.1013\n",
            "Step 835: Test Loss = 0.0757\n",
            "Step 836: Training Loss = 0.1019\n",
            "Step 836: Test Loss = 0.0715\n",
            "Step 837: Training Loss = 0.1608\n",
            "Step 837: Test Loss = 0.1030\n",
            "Step 838: Training Loss = 0.3072\n",
            "Step 838: Test Loss = 0.1848\n",
            "Step 839: Training Loss = 0.1582\n",
            "Step 839: Test Loss = 0.0830\n",
            "Step 840: Training Loss = 0.1846\n",
            "Step 840: Test Loss = 0.1097\n",
            "Step 841: Training Loss = 0.1535\n",
            "Step 841: Test Loss = 0.0725\n",
            "Step 842: Training Loss = 0.2540\n",
            "Step 842: Test Loss = 0.1824\n",
            "Step 843: Training Loss = 0.1828\n",
            "Step 843: Test Loss = 0.0965\n",
            "Step 844: Training Loss = 0.1435\n",
            "Step 844: Test Loss = 0.0713\n",
            "Step 845: Training Loss = 0.1132\n",
            "Step 845: Test Loss = 0.0752\n",
            "Step 846: Training Loss = 0.1236\n",
            "Step 846: Test Loss = 0.0907\n",
            "Step 847: Training Loss = 0.2036\n",
            "Step 847: Test Loss = 0.1528\n",
            "Step 848: Training Loss = 0.1717\n",
            "Step 848: Test Loss = 0.1412\n",
            "Step 849: Training Loss = 0.1958\n",
            "Step 849: Test Loss = 0.1020\n",
            "Step 850: Training Loss = 0.1860\n",
            "Step 850: Test Loss = 0.1206\n",
            "Step 851: Training Loss = 0.1809\n",
            "Step 851: Test Loss = 0.1076\n",
            "Step 852: Training Loss = 0.2042\n",
            "Step 852: Test Loss = 0.1159\n",
            "Step 853: Training Loss = 0.1913\n",
            "Step 853: Test Loss = 0.1427\n",
            "Step 854: Training Loss = 0.3275\n",
            "Step 854: Test Loss = 0.2450\n",
            "Step 855: Training Loss = 0.2004\n",
            "Step 855: Test Loss = 0.1161\n",
            "Step 856: Training Loss = 0.0878\n",
            "Step 856: Test Loss = 0.0739\n",
            "Step 857: Training Loss = 0.1824\n",
            "Step 857: Test Loss = 0.1381\n",
            "Step 858: Training Loss = 0.0805\n",
            "Step 858: Test Loss = 0.0438\n",
            "Step 859: Training Loss = 0.2205\n",
            "Step 859: Test Loss = 0.1076\n",
            "Step 860: Training Loss = 0.2183\n",
            "Step 860: Test Loss = 0.1181\n",
            "Step 861: Training Loss = 0.1016\n",
            "Step 861: Test Loss = 0.0693\n",
            "Step 862: Training Loss = 0.0726\n",
            "Step 862: Test Loss = 0.0351\n",
            "Step 863: Training Loss = 0.2934\n",
            "Step 863: Test Loss = 0.1623\n",
            "Step 864: Training Loss = 0.0955\n",
            "Step 864: Test Loss = 0.0559\n",
            "Step 865: Training Loss = 0.1779\n",
            "Step 865: Test Loss = 0.1016\n",
            "Step 866: Training Loss = 0.2274\n",
            "Step 866: Test Loss = 0.1528\n",
            "Step 867: Training Loss = 0.1421\n",
            "Step 867: Test Loss = 0.0844\n",
            "Step 868: Training Loss = 0.1831\n",
            "Step 868: Test Loss = 0.1244\n",
            "Step 869: Training Loss = 0.1844\n",
            "Step 869: Test Loss = 0.0981\n",
            "Step 870: Training Loss = 0.1531\n",
            "Step 870: Test Loss = 0.0850\n",
            "Step 871: Training Loss = 0.1989\n",
            "Step 871: Test Loss = 0.1186\n",
            "Step 872: Training Loss = 0.0744\n",
            "Step 872: Test Loss = 0.0518\n",
            "Step 873: Training Loss = 0.2305\n",
            "Step 873: Test Loss = 0.1466\n",
            "Step 874: Training Loss = 0.1560\n",
            "Step 874: Test Loss = 0.1111\n",
            "Step 875: Training Loss = 0.2877\n",
            "Step 875: Test Loss = 0.1901\n",
            "Step 876: Training Loss = 0.1174\n",
            "Step 876: Test Loss = 0.0751\n",
            "Step 877: Training Loss = 0.1424\n",
            "Step 877: Test Loss = 0.0882\n",
            "Step 878: Training Loss = 0.1554\n",
            "Step 878: Test Loss = 0.1324\n",
            "Step 879: Training Loss = 0.3728\n",
            "Step 879: Test Loss = 0.2482\n",
            "Step 880: Training Loss = 0.0963\n",
            "Step 880: Test Loss = 0.0546\n",
            "Step 881: Training Loss = 0.1703\n",
            "Step 881: Test Loss = 0.0952\n",
            "Step 882: Training Loss = 0.0932\n",
            "Step 882: Test Loss = 0.0610\n",
            "Step 883: Training Loss = 0.0841\n",
            "Step 883: Test Loss = 0.0733\n",
            "Step 884: Training Loss = 0.2226\n",
            "Step 884: Test Loss = 0.1374\n",
            "Step 885: Training Loss = 0.1706\n",
            "Step 885: Test Loss = 0.1202\n",
            "Step 886: Training Loss = 0.1301\n",
            "Step 886: Test Loss = 0.0769\n",
            "Step 887: Training Loss = 0.1768\n",
            "Step 887: Test Loss = 0.1258\n",
            "Step 888: Training Loss = 0.2868\n",
            "Step 888: Test Loss = 0.1258\n",
            "Step 889: Training Loss = 0.3272\n",
            "Step 889: Test Loss = 0.2032\n",
            "Step 890: Training Loss = 0.1490\n",
            "Step 890: Test Loss = 0.1138\n",
            "Step 891: Training Loss = 0.0892\n",
            "Step 891: Test Loss = 0.0706\n",
            "Step 892: Training Loss = 0.2567\n",
            "Step 892: Test Loss = 0.1816\n",
            "Step 893: Training Loss = 0.2035\n",
            "Step 893: Test Loss = 0.1192\n",
            "Step 894: Training Loss = 0.2496\n",
            "Step 894: Test Loss = 0.1273\n",
            "Step 895: Training Loss = 0.1915\n",
            "Step 895: Test Loss = 0.0968\n",
            "Step 896: Training Loss = 0.1402\n",
            "Step 896: Test Loss = 0.0844\n",
            "Step 897: Training Loss = 0.0988\n",
            "Step 897: Test Loss = 0.0785\n",
            "Step 898: Training Loss = 0.1658\n",
            "Step 898: Test Loss = 0.1249\n",
            "Step 899: Training Loss = 0.2676\n",
            "Step 899: Test Loss = 0.2090\n",
            "Step 900: Training Loss = 0.1331\n",
            "Step 900: Test Loss = 0.0719\n",
            "900 45% (1m 45s) Train Loss: 0.1715, Test Loss: 0.1096, Accuracy: 0.9416 - I korero ano a Ihowa ki a Mohi i taua tino rangi a / maori ✓\n",
            "Step 901: Training Loss = 0.1154\n",
            "Step 901: Test Loss = 0.0739\n",
            "Step 902: Training Loss = 0.1767\n",
            "Step 902: Test Loss = 0.1478\n",
            "Step 903: Training Loss = 0.2066\n",
            "Step 903: Test Loss = 0.1363\n",
            "Step 904: Training Loss = 0.3551\n",
            "Step 904: Test Loss = 0.2628\n",
            "Step 905: Training Loss = 0.1699\n",
            "Step 905: Test Loss = 0.1148\n",
            "Step 906: Training Loss = 0.1261\n",
            "Step 906: Test Loss = 0.1021\n",
            "Step 907: Training Loss = 0.2269\n",
            "Step 907: Test Loss = 0.1403\n",
            "Step 908: Training Loss = 0.1270\n",
            "Step 908: Test Loss = 0.1066\n",
            "Step 909: Training Loss = 0.2046\n",
            "Step 909: Test Loss = 0.1493\n",
            "Step 910: Training Loss = 0.1504\n",
            "Step 910: Test Loss = 0.1098\n",
            "Step 911: Training Loss = 0.1105\n",
            "Step 911: Test Loss = 0.0830\n",
            "Step 912: Training Loss = 0.2144\n",
            "Step 912: Test Loss = 0.1579\n",
            "Step 913: Training Loss = 0.1514\n",
            "Step 913: Test Loss = 0.0831\n",
            "Step 914: Training Loss = 0.1004\n",
            "Step 914: Test Loss = 0.0712\n",
            "Step 915: Training Loss = 0.1333\n",
            "Step 915: Test Loss = 0.0653\n",
            "Step 916: Training Loss = 0.1389\n",
            "Step 916: Test Loss = 0.0916\n",
            "Step 917: Training Loss = 0.1797\n",
            "Step 917: Test Loss = 0.0785\n",
            "Step 918: Training Loss = 0.1117\n",
            "Step 918: Test Loss = 0.0890\n",
            "Step 919: Training Loss = 0.1114\n",
            "Step 919: Test Loss = 0.0566\n",
            "Step 920: Training Loss = 0.0691\n",
            "Step 920: Test Loss = 0.0498\n",
            "Step 921: Training Loss = 0.1819\n",
            "Step 921: Test Loss = 0.1107\n",
            "Step 922: Training Loss = 0.2537\n",
            "Step 922: Test Loss = 0.1258\n",
            "Step 923: Training Loss = 0.1582\n",
            "Step 923: Test Loss = 0.1140\n",
            "Step 924: Training Loss = 0.1066\n",
            "Step 924: Test Loss = 0.0536\n",
            "Step 925: Training Loss = 0.1364\n",
            "Step 925: Test Loss = 0.0956\n",
            "Step 926: Training Loss = 0.1638\n",
            "Step 926: Test Loss = 0.0991\n",
            "Step 927: Training Loss = 0.1155\n",
            "Step 927: Test Loss = 0.0728\n",
            "Step 928: Training Loss = 0.1471\n",
            "Step 928: Test Loss = 0.0768\n",
            "Step 929: Training Loss = 0.1230\n",
            "Step 929: Test Loss = 0.0856\n",
            "Step 930: Training Loss = 0.2505\n",
            "Step 930: Test Loss = 0.1651\n",
            "Step 931: Training Loss = 0.2266\n",
            "Step 931: Test Loss = 0.1121\n",
            "Step 932: Training Loss = 0.2045\n",
            "Step 932: Test Loss = 0.1201\n",
            "Step 933: Training Loss = 0.1142\n",
            "Step 933: Test Loss = 0.0891\n",
            "Step 934: Training Loss = 0.1314\n",
            "Step 934: Test Loss = 0.0646\n",
            "Step 935: Training Loss = 0.2193\n",
            "Step 935: Test Loss = 0.1379\n",
            "Step 936: Training Loss = 0.2643\n",
            "Step 936: Test Loss = 0.1685\n",
            "Step 937: Training Loss = 0.1927\n",
            "Step 937: Test Loss = 0.1219\n",
            "Step 938: Training Loss = 0.2236\n",
            "Step 938: Test Loss = 0.1279\n",
            "Step 939: Training Loss = 0.1594\n",
            "Step 939: Test Loss = 0.0946\n",
            "Step 940: Training Loss = 0.2316\n",
            "Step 940: Test Loss = 0.1365\n",
            "Step 941: Training Loss = 0.2300\n",
            "Step 941: Test Loss = 0.1644\n",
            "Step 942: Training Loss = 0.1940\n",
            "Step 942: Test Loss = 0.1308\n",
            "Step 943: Training Loss = 0.1946\n",
            "Step 943: Test Loss = 0.1266\n",
            "Step 944: Training Loss = 0.1396\n",
            "Step 944: Test Loss = 0.0774\n",
            "Step 945: Training Loss = 0.3060\n",
            "Step 945: Test Loss = 0.2165\n",
            "Step 946: Training Loss = 0.2833\n",
            "Step 946: Test Loss = 0.1779\n",
            "Step 947: Training Loss = 0.2506\n",
            "Step 947: Test Loss = 0.1800\n",
            "Step 948: Training Loss = 0.2092\n",
            "Step 948: Test Loss = 0.1374\n",
            "Step 949: Training Loss = 0.2360\n",
            "Step 949: Test Loss = 0.1678\n",
            "Step 950: Training Loss = 0.1278\n",
            "Step 950: Test Loss = 0.0988\n",
            "Step 951: Training Loss = 0.1476\n",
            "Step 951: Test Loss = 0.0827\n",
            "Step 952: Training Loss = 0.1471\n",
            "Step 952: Test Loss = 0.0961\n",
            "Step 953: Training Loss = 0.1468\n",
            "Step 953: Test Loss = 0.0831\n",
            "Step 954: Training Loss = 0.2553\n",
            "Step 954: Test Loss = 0.1599\n",
            "Step 955: Training Loss = 0.1425\n",
            "Step 955: Test Loss = 0.0849\n",
            "Step 956: Training Loss = 0.1727\n",
            "Step 956: Test Loss = 0.0966\n",
            "Step 957: Training Loss = 0.0636\n",
            "Step 957: Test Loss = 0.0532\n",
            "Step 958: Training Loss = 0.1836\n",
            "Step 958: Test Loss = 0.1068\n",
            "Step 959: Training Loss = 0.1703\n",
            "Step 959: Test Loss = 0.0689\n",
            "Step 960: Training Loss = 0.1903\n",
            "Step 960: Test Loss = 0.1131\n",
            "Step 961: Training Loss = 0.0859\n",
            "Step 961: Test Loss = 0.0578\n",
            "Step 962: Training Loss = 0.2730\n",
            "Step 962: Test Loss = 0.1550\n",
            "Step 963: Training Loss = 0.2478\n",
            "Step 963: Test Loss = 0.1667\n",
            "Step 964: Training Loss = 0.1594\n",
            "Step 964: Test Loss = 0.0783\n",
            "Step 965: Training Loss = 0.1121\n",
            "Step 965: Test Loss = 0.0621\n",
            "Step 966: Training Loss = 0.1125\n",
            "Step 966: Test Loss = 0.0821\n",
            "Step 967: Training Loss = 0.2224\n",
            "Step 967: Test Loss = 0.1159\n",
            "Step 968: Training Loss = 0.2051\n",
            "Step 968: Test Loss = 0.1290\n",
            "Step 969: Training Loss = 0.1554\n",
            "Step 969: Test Loss = 0.1048\n",
            "Step 970: Training Loss = 0.2168\n",
            "Step 970: Test Loss = 0.1634\n",
            "Step 971: Training Loss = 0.1683\n",
            "Step 971: Test Loss = 0.1128\n",
            "Step 972: Training Loss = 0.1472\n",
            "Step 972: Test Loss = 0.0850\n",
            "Step 973: Training Loss = 0.0717\n",
            "Step 973: Test Loss = 0.0405\n",
            "Step 974: Training Loss = 0.1950\n",
            "Step 974: Test Loss = 0.1350\n",
            "Step 975: Training Loss = 0.1547\n",
            "Step 975: Test Loss = 0.0898\n",
            "Step 976: Training Loss = 0.1950\n",
            "Step 976: Test Loss = 0.1046\n",
            "Step 977: Training Loss = 0.1418\n",
            "Step 977: Test Loss = 0.0656\n",
            "Step 978: Training Loss = 0.1332\n",
            "Step 978: Test Loss = 0.0923\n",
            "Step 979: Training Loss = 0.1762\n",
            "Step 979: Test Loss = 0.0962\n",
            "Step 980: Training Loss = 0.0746\n",
            "Step 980: Test Loss = 0.0475\n",
            "Step 981: Training Loss = 0.0650\n",
            "Step 981: Test Loss = 0.0397\n",
            "Step 982: Training Loss = 0.1297\n",
            "Step 982: Test Loss = 0.0715\n",
            "Step 983: Training Loss = 0.1310\n",
            "Step 983: Test Loss = 0.0942\n",
            "Step 984: Training Loss = 0.2842\n",
            "Step 984: Test Loss = 0.1488\n",
            "Step 985: Training Loss = 0.1131\n",
            "Step 985: Test Loss = 0.0670\n",
            "Step 986: Training Loss = 0.2431\n",
            "Step 986: Test Loss = 0.1722\n",
            "Step 987: Training Loss = 0.1382\n",
            "Step 987: Test Loss = 0.1009\n",
            "Step 988: Training Loss = 0.2037\n",
            "Step 988: Test Loss = 0.1345\n",
            "Step 989: Training Loss = 0.1414\n",
            "Step 989: Test Loss = 0.0789\n",
            "Step 990: Training Loss = 0.3924\n",
            "Step 990: Test Loss = 0.2173\n",
            "Step 991: Training Loss = 0.2180\n",
            "Step 991: Test Loss = 0.1272\n",
            "Step 992: Training Loss = 0.2645\n",
            "Step 992: Test Loss = 0.1273\n",
            "Step 993: Training Loss = 0.1928\n",
            "Step 993: Test Loss = 0.1007\n",
            "Step 994: Training Loss = 0.2247\n",
            "Step 994: Test Loss = 0.1613\n",
            "Step 995: Training Loss = 0.1595\n",
            "Step 995: Test Loss = 0.1128\n",
            "Step 996: Training Loss = 0.1778\n",
            "Step 996: Test Loss = 0.1040\n",
            "Step 997: Training Loss = 0.2402\n",
            "Step 997: Test Loss = 0.1269\n",
            "Step 998: Training Loss = 0.2432\n",
            "Step 998: Test Loss = 0.0963\n",
            "Step 999: Training Loss = 0.1613\n",
            "Step 999: Test Loss = 0.1221\n",
            "Step 1000: Training Loss = 0.2321\n",
            "Step 1000: Test Loss = 0.1645\n",
            "1000 50% (1m 56s) Train Loss: 0.1778, Test Loss: 0.1112, Accuracy: 0.9399 - es qui etaient sur la face de la terre furent exte / french ✓\n",
            "Step 1001: Training Loss = 0.2385\n",
            "Step 1001: Test Loss = 0.0795\n",
            "Step 1002: Training Loss = 0.2098\n",
            "Step 1002: Test Loss = 0.1523\n",
            "Step 1003: Training Loss = 0.1515\n",
            "Step 1003: Test Loss = 0.0796\n",
            "Step 1004: Training Loss = 0.1428\n",
            "Step 1004: Test Loss = 0.1021\n",
            "Step 1005: Training Loss = 0.2393\n",
            "Step 1005: Test Loss = 0.1409\n",
            "Step 1006: Training Loss = 0.0890\n",
            "Step 1006: Test Loss = 0.0578\n",
            "Step 1007: Training Loss = 0.0736\n",
            "Step 1007: Test Loss = 0.0559\n",
            "Step 1008: Training Loss = 0.1492\n",
            "Step 1008: Test Loss = 0.0699\n",
            "Step 1009: Training Loss = 0.2129\n",
            "Step 1009: Test Loss = 0.1643\n",
            "Step 1010: Training Loss = 0.1375\n",
            "Step 1010: Test Loss = 0.0968\n",
            "Step 1011: Training Loss = 0.1533\n",
            "Step 1011: Test Loss = 0.0979\n",
            "Step 1012: Training Loss = 0.2120\n",
            "Step 1012: Test Loss = 0.1056\n",
            "Step 1013: Training Loss = 0.1862\n",
            "Step 1013: Test Loss = 0.1215\n",
            "Step 1014: Training Loss = 0.1274\n",
            "Step 1014: Test Loss = 0.0953\n",
            "Step 1015: Training Loss = 0.1051\n",
            "Step 1015: Test Loss = 0.0746\n",
            "Step 1016: Training Loss = 0.1029\n",
            "Step 1016: Test Loss = 0.0838\n",
            "Step 1017: Training Loss = 0.1808\n",
            "Step 1017: Test Loss = 0.1054\n",
            "Step 1018: Training Loss = 0.1964\n",
            "Step 1018: Test Loss = 0.1233\n",
            "Step 1019: Training Loss = 0.1835\n",
            "Step 1019: Test Loss = 0.0667\n",
            "Step 1020: Training Loss = 0.1627\n",
            "Step 1020: Test Loss = 0.0842\n",
            "Step 1021: Training Loss = 0.2443\n",
            "Step 1021: Test Loss = 0.1562\n",
            "Step 1022: Training Loss = 0.0997\n",
            "Step 1022: Test Loss = 0.0584\n",
            "Step 1023: Training Loss = 0.0531\n",
            "Step 1023: Test Loss = 0.0389\n",
            "Step 1024: Training Loss = 0.1747\n",
            "Step 1024: Test Loss = 0.1177\n",
            "Step 1025: Training Loss = 0.1704\n",
            "Step 1025: Test Loss = 0.1094\n",
            "Step 1026: Training Loss = 0.0963\n",
            "Step 1026: Test Loss = 0.0736\n",
            "Step 1027: Training Loss = 0.1670\n",
            "Step 1027: Test Loss = 0.1120\n",
            "Step 1028: Training Loss = 0.2529\n",
            "Step 1028: Test Loss = 0.1879\n",
            "Step 1029: Training Loss = 0.1817\n",
            "Step 1029: Test Loss = 0.1373\n",
            "Step 1030: Training Loss = 0.1634\n",
            "Step 1030: Test Loss = 0.1131\n",
            "Step 1031: Training Loss = 0.1287\n",
            "Step 1031: Test Loss = 0.0759\n",
            "Step 1032: Training Loss = 0.1740\n",
            "Step 1032: Test Loss = 0.1137\n",
            "Step 1033: Training Loss = 0.1280\n",
            "Step 1033: Test Loss = 0.0945\n",
            "Step 1034: Training Loss = 0.1365\n",
            "Step 1034: Test Loss = 0.0946\n",
            "Step 1035: Training Loss = 0.1964\n",
            "Step 1035: Test Loss = 0.1401\n",
            "Step 1036: Training Loss = 0.0573\n",
            "Step 1036: Test Loss = 0.0340\n",
            "Step 1037: Training Loss = 0.1261\n",
            "Step 1037: Test Loss = 0.0889\n",
            "Step 1038: Training Loss = 0.1256\n",
            "Step 1038: Test Loss = 0.0699\n",
            "Step 1039: Training Loss = 0.0971\n",
            "Step 1039: Test Loss = 0.0531\n",
            "Step 1040: Training Loss = 0.2409\n",
            "Step 1040: Test Loss = 0.1371\n",
            "Step 1041: Training Loss = 0.2090\n",
            "Step 1041: Test Loss = 0.1434\n",
            "Step 1042: Training Loss = 0.0948\n",
            "Step 1042: Test Loss = 0.0628\n",
            "Step 1043: Training Loss = 0.0975\n",
            "Step 1043: Test Loss = 0.0561\n",
            "Step 1044: Training Loss = 0.1540\n",
            "Step 1044: Test Loss = 0.1156\n",
            "Step 1045: Training Loss = 0.3144\n",
            "Step 1045: Test Loss = 0.2049\n",
            "Step 1046: Training Loss = 0.1217\n",
            "Step 1046: Test Loss = 0.0874\n",
            "Step 1047: Training Loss = 0.1026\n",
            "Step 1047: Test Loss = 0.0628\n",
            "Step 1048: Training Loss = 0.1369\n",
            "Step 1048: Test Loss = 0.0708\n",
            "Step 1049: Training Loss = 0.3558\n",
            "Step 1049: Test Loss = 0.2067\n",
            "Step 1050: Training Loss = 0.1383\n",
            "Step 1050: Test Loss = 0.0849\n",
            "Step 1051: Training Loss = 0.1466\n",
            "Step 1051: Test Loss = 0.1077\n",
            "Step 1052: Training Loss = 0.1792\n",
            "Step 1052: Test Loss = 0.1375\n",
            "Step 1053: Training Loss = 0.0863\n",
            "Step 1053: Test Loss = 0.0659\n",
            "Step 1054: Training Loss = 0.1248\n",
            "Step 1054: Test Loss = 0.0922\n",
            "Step 1055: Training Loss = 0.1667\n",
            "Step 1055: Test Loss = 0.0907\n",
            "Step 1056: Training Loss = 0.1002\n",
            "Step 1056: Test Loss = 0.0676\n",
            "Step 1057: Training Loss = 0.1616\n",
            "Step 1057: Test Loss = 0.1154\n",
            "Step 1058: Training Loss = 0.1178\n",
            "Step 1058: Test Loss = 0.0831\n",
            "Step 1059: Training Loss = 0.0944\n",
            "Step 1059: Test Loss = 0.0583\n",
            "Step 1060: Training Loss = 0.0842\n",
            "Step 1060: Test Loss = 0.0555\n",
            "Step 1061: Training Loss = 0.0839\n",
            "Step 1061: Test Loss = 0.0576\n",
            "Step 1062: Training Loss = 0.2100\n",
            "Step 1062: Test Loss = 0.1298\n",
            "Step 1063: Training Loss = 0.0794\n",
            "Step 1063: Test Loss = 0.0480\n",
            "Step 1064: Training Loss = 0.1790\n",
            "Step 1064: Test Loss = 0.0969\n",
            "Step 1065: Training Loss = 0.0998\n",
            "Step 1065: Test Loss = 0.0367\n",
            "Step 1066: Training Loss = 0.1531\n",
            "Step 1066: Test Loss = 0.1278\n",
            "Step 1067: Training Loss = 0.1203\n",
            "Step 1067: Test Loss = 0.0721\n",
            "Step 1068: Training Loss = 0.1218\n",
            "Step 1068: Test Loss = 0.0688\n",
            "Step 1069: Training Loss = 0.1659\n",
            "Step 1069: Test Loss = 0.1026\n",
            "Step 1070: Training Loss = 0.0516\n",
            "Step 1070: Test Loss = 0.0343\n",
            "Step 1071: Training Loss = 0.0377\n",
            "Step 1071: Test Loss = 0.0290\n",
            "Step 1072: Training Loss = 0.1632\n",
            "Step 1072: Test Loss = 0.0960\n",
            "Step 1073: Training Loss = 0.2237\n",
            "Step 1073: Test Loss = 0.1298\n",
            "Step 1074: Training Loss = 0.2298\n",
            "Step 1074: Test Loss = 0.1178\n",
            "Step 1075: Training Loss = 0.1583\n",
            "Step 1075: Test Loss = 0.0686\n",
            "Step 1076: Training Loss = 0.2197\n",
            "Step 1076: Test Loss = 0.1303\n",
            "Step 1077: Training Loss = 0.2701\n",
            "Step 1077: Test Loss = 0.1531\n",
            "Step 1078: Training Loss = 0.1819\n",
            "Step 1078: Test Loss = 0.0994\n",
            "Step 1079: Training Loss = 0.0643\n",
            "Step 1079: Test Loss = 0.0509\n",
            "Step 1080: Training Loss = 0.1426\n",
            "Step 1080: Test Loss = 0.0872\n",
            "Step 1081: Training Loss = 0.1490\n",
            "Step 1081: Test Loss = 0.1140\n",
            "Step 1082: Training Loss = 0.2205\n",
            "Step 1082: Test Loss = 0.1345\n",
            "Step 1083: Training Loss = 0.1426\n",
            "Step 1083: Test Loss = 0.0796\n",
            "Step 1084: Training Loss = 0.1966\n",
            "Step 1084: Test Loss = 0.1051\n",
            "Step 1085: Training Loss = 0.1399\n",
            "Step 1085: Test Loss = 0.0932\n",
            "Step 1086: Training Loss = 0.2611\n",
            "Step 1086: Test Loss = 0.1607\n",
            "Step 1087: Training Loss = 0.1995\n",
            "Step 1087: Test Loss = 0.1221\n",
            "Step 1088: Training Loss = 0.1359\n",
            "Step 1088: Test Loss = 0.0792\n",
            "Step 1089: Training Loss = 0.1828\n",
            "Step 1089: Test Loss = 0.1267\n",
            "Step 1090: Training Loss = 0.0752\n",
            "Step 1090: Test Loss = 0.0292\n",
            "Step 1091: Training Loss = 0.2184\n",
            "Step 1091: Test Loss = 0.1705\n",
            "Step 1092: Training Loss = 0.1511\n",
            "Step 1092: Test Loss = 0.1239\n",
            "Step 1093: Training Loss = 0.0761\n",
            "Step 1093: Test Loss = 0.0487\n",
            "Step 1094: Training Loss = 0.2116\n",
            "Step 1094: Test Loss = 0.1632\n",
            "Step 1095: Training Loss = 0.1397\n",
            "Step 1095: Test Loss = 0.0903\n",
            "Step 1096: Training Loss = 0.0849\n",
            "Step 1096: Test Loss = 0.0703\n",
            "Step 1097: Training Loss = 0.1239\n",
            "Step 1097: Test Loss = 0.0726\n",
            "Step 1098: Training Loss = 0.1261\n",
            "Step 1098: Test Loss = 0.0868\n",
            "Step 1099: Training Loss = 0.1935\n",
            "Step 1099: Test Loss = 0.1364\n",
            "Step 1100: Training Loss = 0.2174\n",
            "Step 1100: Test Loss = 0.1512\n",
            "1100 55% (2m 8s) Train Loss: 0.1546, Test Loss: 0.0983, Accuracy: 0.9488 - si a plecat. Cind au rasarit firele de griu si au  / romanian ✓\n",
            "Step 1101: Training Loss = 0.0865\n",
            "Step 1101: Test Loss = 0.0472\n",
            "Step 1102: Training Loss = 0.0412\n",
            "Step 1102: Test Loss = 0.0358\n",
            "Step 1103: Training Loss = 0.2254\n",
            "Step 1103: Test Loss = 0.1712\n",
            "Step 1104: Training Loss = 0.0696\n",
            "Step 1104: Test Loss = 0.0502\n",
            "Step 1105: Training Loss = 0.2384\n",
            "Step 1105: Test Loss = 0.1284\n",
            "Step 1106: Training Loss = 0.1105\n",
            "Step 1106: Test Loss = 0.0659\n",
            "Step 1107: Training Loss = 0.1771\n",
            "Step 1107: Test Loss = 0.0891\n",
            "Step 1108: Training Loss = 0.1700\n",
            "Step 1108: Test Loss = 0.0993\n",
            "Step 1109: Training Loss = 0.1724\n",
            "Step 1109: Test Loss = 0.0816\n",
            "Step 1110: Training Loss = 0.1241\n",
            "Step 1110: Test Loss = 0.0478\n",
            "Step 1111: Training Loss = 0.0932\n",
            "Step 1111: Test Loss = 0.0658\n",
            "Step 1112: Training Loss = 0.0722\n",
            "Step 1112: Test Loss = 0.0311\n",
            "Step 1113: Training Loss = 0.1034\n",
            "Step 1113: Test Loss = 0.0740\n",
            "Step 1114: Training Loss = 0.1733\n",
            "Step 1114: Test Loss = 0.0829\n",
            "Step 1115: Training Loss = 0.0690\n",
            "Step 1115: Test Loss = 0.0516\n",
            "Step 1116: Training Loss = 0.0610\n",
            "Step 1116: Test Loss = 0.0439\n",
            "Step 1117: Training Loss = 0.0825\n",
            "Step 1117: Test Loss = 0.0496\n",
            "Step 1118: Training Loss = 0.1246\n",
            "Step 1118: Test Loss = 0.0818\n",
            "Step 1119: Training Loss = 0.1136\n",
            "Step 1119: Test Loss = 0.0660\n",
            "Step 1120: Training Loss = 0.2861\n",
            "Step 1120: Test Loss = 0.1713\n",
            "Step 1121: Training Loss = 0.1380\n",
            "Step 1121: Test Loss = 0.0749\n",
            "Step 1122: Training Loss = 0.2007\n",
            "Step 1122: Test Loss = 0.1281\n",
            "Step 1123: Training Loss = 0.1426\n",
            "Step 1123: Test Loss = 0.0639\n",
            "Step 1124: Training Loss = 0.1405\n",
            "Step 1124: Test Loss = 0.0812\n",
            "Step 1125: Training Loss = 0.2172\n",
            "Step 1125: Test Loss = 0.1263\n",
            "Step 1126: Training Loss = 0.0928\n",
            "Step 1126: Test Loss = 0.0559\n",
            "Step 1127: Training Loss = 0.1285\n",
            "Step 1127: Test Loss = 0.0893\n",
            "Step 1128: Training Loss = 0.1274\n",
            "Step 1128: Test Loss = 0.0637\n",
            "Step 1129: Training Loss = 0.0835\n",
            "Step 1129: Test Loss = 0.0477\n",
            "Step 1130: Training Loss = 0.1476\n",
            "Step 1130: Test Loss = 0.1085\n",
            "Step 1131: Training Loss = 0.2277\n",
            "Step 1131: Test Loss = 0.1436\n",
            "Step 1132: Training Loss = 0.1667\n",
            "Step 1132: Test Loss = 0.1244\n",
            "Step 1133: Training Loss = 0.0799\n",
            "Step 1133: Test Loss = 0.0312\n",
            "Step 1134: Training Loss = 0.0808\n",
            "Step 1134: Test Loss = 0.0541\n",
            "Step 1135: Training Loss = 0.1041\n",
            "Step 1135: Test Loss = 0.0616\n",
            "Step 1136: Training Loss = 0.0820\n",
            "Step 1136: Test Loss = 0.0434\n",
            "Step 1137: Training Loss = 0.0891\n",
            "Step 1137: Test Loss = 0.0495\n",
            "Step 1138: Training Loss = 0.1265\n",
            "Step 1138: Test Loss = 0.0931\n",
            "Step 1139: Training Loss = 0.0910\n",
            "Step 1139: Test Loss = 0.0561\n",
            "Step 1140: Training Loss = 0.1005\n",
            "Step 1140: Test Loss = 0.0800\n",
            "Step 1141: Training Loss = 0.1415\n",
            "Step 1141: Test Loss = 0.0959\n",
            "Step 1142: Training Loss = 0.1911\n",
            "Step 1142: Test Loss = 0.1581\n",
            "Step 1143: Training Loss = 0.0411\n",
            "Step 1143: Test Loss = 0.0278\n",
            "Step 1144: Training Loss = 0.2277\n",
            "Step 1144: Test Loss = 0.1011\n",
            "Step 1145: Training Loss = 0.1696\n",
            "Step 1145: Test Loss = 0.1213\n",
            "Step 1146: Training Loss = 0.0979\n",
            "Step 1146: Test Loss = 0.0721\n",
            "Step 1147: Training Loss = 0.1168\n",
            "Step 1147: Test Loss = 0.0377\n",
            "Step 1148: Training Loss = 0.0792\n",
            "Step 1148: Test Loss = 0.0346\n",
            "Step 1149: Training Loss = 0.1776\n",
            "Step 1149: Test Loss = 0.1164\n",
            "Step 1150: Training Loss = 0.2468\n",
            "Step 1150: Test Loss = 0.1624\n",
            "Step 1151: Training Loss = 0.1141\n",
            "Step 1151: Test Loss = 0.0780\n",
            "Step 1152: Training Loss = 0.0481\n",
            "Step 1152: Test Loss = 0.0330\n",
            "Step 1153: Training Loss = 0.3039\n",
            "Step 1153: Test Loss = 0.2189\n",
            "Step 1154: Training Loss = 0.0805\n",
            "Step 1154: Test Loss = 0.0486\n",
            "Step 1155: Training Loss = 0.0551\n",
            "Step 1155: Test Loss = 0.0376\n",
            "Step 1156: Training Loss = 0.2326\n",
            "Step 1156: Test Loss = 0.1214\n",
            "Step 1157: Training Loss = 0.1301\n",
            "Step 1157: Test Loss = 0.0796\n",
            "Step 1158: Training Loss = 0.1305\n",
            "Step 1158: Test Loss = 0.0937\n",
            "Step 1159: Training Loss = 0.1650\n",
            "Step 1159: Test Loss = 0.0977\n",
            "Step 1160: Training Loss = 0.1784\n",
            "Step 1160: Test Loss = 0.1132\n",
            "Step 1161: Training Loss = 0.1794\n",
            "Step 1161: Test Loss = 0.1062\n",
            "Step 1162: Training Loss = 0.2267\n",
            "Step 1162: Test Loss = 0.1412\n",
            "Step 1163: Training Loss = 0.1619\n",
            "Step 1163: Test Loss = 0.1063\n",
            "Step 1164: Training Loss = 0.0475\n",
            "Step 1164: Test Loss = 0.0288\n",
            "Step 1165: Training Loss = 0.0721\n",
            "Step 1165: Test Loss = 0.0463\n",
            "Step 1166: Training Loss = 0.1491\n",
            "Step 1166: Test Loss = 0.1135\n",
            "Step 1167: Training Loss = 0.1809\n",
            "Step 1167: Test Loss = 0.1285\n",
            "Step 1168: Training Loss = 0.0872\n",
            "Step 1168: Test Loss = 0.0644\n",
            "Step 1169: Training Loss = 0.1979\n",
            "Step 1169: Test Loss = 0.1185\n",
            "Step 1170: Training Loss = 0.1411\n",
            "Step 1170: Test Loss = 0.0995\n",
            "Step 1171: Training Loss = 0.1374\n",
            "Step 1171: Test Loss = 0.0958\n",
            "Step 1172: Training Loss = 0.2546\n",
            "Step 1172: Test Loss = 0.1829\n",
            "Step 1173: Training Loss = 0.1000\n",
            "Step 1173: Test Loss = 0.0377\n",
            "Step 1174: Training Loss = 0.1494\n",
            "Step 1174: Test Loss = 0.1109\n",
            "Step 1175: Training Loss = 0.1427\n",
            "Step 1175: Test Loss = 0.0781\n",
            "Step 1176: Training Loss = 0.1021\n",
            "Step 1176: Test Loss = 0.0601\n",
            "Step 1177: Training Loss = 0.1379\n",
            "Step 1177: Test Loss = 0.0640\n",
            "Step 1178: Training Loss = 0.0697\n",
            "Step 1178: Test Loss = 0.0501\n",
            "Step 1179: Training Loss = 0.0496\n",
            "Step 1179: Test Loss = 0.0403\n",
            "Step 1180: Training Loss = 0.1478\n",
            "Step 1180: Test Loss = 0.0952\n",
            "Step 1181: Training Loss = 0.1404\n",
            "Step 1181: Test Loss = 0.0737\n",
            "Step 1182: Training Loss = 0.1379\n",
            "Step 1182: Test Loss = 0.0630\n",
            "Step 1183: Training Loss = 0.1248\n",
            "Step 1183: Test Loss = 0.0898\n",
            "Step 1184: Training Loss = 0.1007\n",
            "Step 1184: Test Loss = 0.0703\n",
            "Step 1185: Training Loss = 0.1474\n",
            "Step 1185: Test Loss = 0.1046\n",
            "Step 1186: Training Loss = 0.0900\n",
            "Step 1186: Test Loss = 0.0408\n",
            "Step 1187: Training Loss = 0.0862\n",
            "Step 1187: Test Loss = 0.0450\n",
            "Step 1188: Training Loss = 0.0890\n",
            "Step 1188: Test Loss = 0.0621\n",
            "Step 1189: Training Loss = 0.1169\n",
            "Step 1189: Test Loss = 0.0567\n",
            "Step 1190: Training Loss = 0.0883\n",
            "Step 1190: Test Loss = 0.0479\n",
            "Step 1191: Training Loss = 0.1496\n",
            "Step 1191: Test Loss = 0.0887\n",
            "Step 1192: Training Loss = 0.1008\n",
            "Step 1192: Test Loss = 0.0452\n",
            "Step 1193: Training Loss = 0.1510\n",
            "Step 1193: Test Loss = 0.0390\n",
            "Step 1194: Training Loss = 0.2236\n",
            "Step 1194: Test Loss = 0.1522\n",
            "Step 1195: Training Loss = 0.1277\n",
            "Step 1195: Test Loss = 0.0787\n",
            "Step 1196: Training Loss = 0.1226\n",
            "Step 1196: Test Loss = 0.0712\n",
            "Step 1197: Training Loss = 0.1421\n",
            "Step 1197: Test Loss = 0.1035\n",
            "Step 1198: Training Loss = 0.1468\n",
            "Step 1198: Test Loss = 0.1080\n",
            "Step 1199: Training Loss = 0.0928\n",
            "Step 1199: Test Loss = 0.0558\n",
            "Step 1200: Training Loss = 0.1773\n",
            "Step 1200: Test Loss = 0.1058\n",
            "1200 60% (2m 20s) Train Loss: 0.1338, Test Loss: 0.0823, Accuracy: 0.9573 - e Kleider seiner Sohne zum Priestertum. Da ging di / german ✓\n",
            "Step 1201: Training Loss = 0.1319\n",
            "Step 1201: Test Loss = 0.0865\n",
            "Step 1202: Training Loss = 0.2253\n",
            "Step 1202: Test Loss = 0.1025\n",
            "Step 1203: Training Loss = 0.1002\n",
            "Step 1203: Test Loss = 0.0567\n",
            "Step 1204: Training Loss = 0.0981\n",
            "Step 1204: Test Loss = 0.0605\n",
            "Step 1205: Training Loss = 0.1091\n",
            "Step 1205: Test Loss = 0.0822\n",
            "Step 1206: Training Loss = 0.2363\n",
            "Step 1206: Test Loss = 0.1224\n",
            "Step 1207: Training Loss = 0.1914\n",
            "Step 1207: Test Loss = 0.1247\n",
            "Step 1208: Training Loss = 0.1328\n",
            "Step 1208: Test Loss = 0.0554\n",
            "Step 1209: Training Loss = 0.1719\n",
            "Step 1209: Test Loss = 0.0987\n",
            "Step 1210: Training Loss = 0.1594\n",
            "Step 1210: Test Loss = 0.1043\n",
            "Step 1211: Training Loss = 0.1177\n",
            "Step 1211: Test Loss = 0.0844\n",
            "Step 1212: Training Loss = 0.2475\n",
            "Step 1212: Test Loss = 0.1465\n",
            "Step 1213: Training Loss = 0.0911\n",
            "Step 1213: Test Loss = 0.0733\n",
            "Step 1214: Training Loss = 0.1466\n",
            "Step 1214: Test Loss = 0.0971\n",
            "Step 1215: Training Loss = 0.2711\n",
            "Step 1215: Test Loss = 0.1759\n",
            "Step 1216: Training Loss = 0.0812\n",
            "Step 1216: Test Loss = 0.0687\n",
            "Step 1217: Training Loss = 0.0941\n",
            "Step 1217: Test Loss = 0.0539\n",
            "Step 1218: Training Loss = 0.1457\n",
            "Step 1218: Test Loss = 0.0980\n",
            "Step 1219: Training Loss = 0.1301\n",
            "Step 1219: Test Loss = 0.0983\n",
            "Step 1220: Training Loss = 0.0920\n",
            "Step 1220: Test Loss = 0.0639\n",
            "Step 1221: Training Loss = 0.0842\n",
            "Step 1221: Test Loss = 0.0395\n",
            "Step 1222: Training Loss = 0.1078\n",
            "Step 1222: Test Loss = 0.0705\n",
            "Step 1223: Training Loss = 0.1494\n",
            "Step 1223: Test Loss = 0.0936\n",
            "Step 1224: Training Loss = 0.0723\n",
            "Step 1224: Test Loss = 0.0510\n",
            "Step 1225: Training Loss = 0.0693\n",
            "Step 1225: Test Loss = 0.0512\n",
            "Step 1226: Training Loss = 0.1617\n",
            "Step 1226: Test Loss = 0.1061\n",
            "Step 1227: Training Loss = 0.1805\n",
            "Step 1227: Test Loss = 0.1189\n",
            "Step 1228: Training Loss = 0.0585\n",
            "Step 1228: Test Loss = 0.0418\n",
            "Step 1229: Training Loss = 0.0929\n",
            "Step 1229: Test Loss = 0.0554\n",
            "Step 1230: Training Loss = 0.1572\n",
            "Step 1230: Test Loss = 0.1257\n",
            "Step 1231: Training Loss = 0.1398\n",
            "Step 1231: Test Loss = 0.0889\n",
            "Step 1232: Training Loss = 0.0484\n",
            "Step 1232: Test Loss = 0.0401\n",
            "Step 1233: Training Loss = 0.1089\n",
            "Step 1233: Test Loss = 0.0600\n",
            "Step 1234: Training Loss = 0.0984\n",
            "Step 1234: Test Loss = 0.0550\n",
            "Step 1235: Training Loss = 0.0426\n",
            "Step 1235: Test Loss = 0.0274\n",
            "Step 1236: Training Loss = 0.2350\n",
            "Step 1236: Test Loss = 0.1609\n",
            "Step 1237: Training Loss = 0.0524\n",
            "Step 1237: Test Loss = 0.0378\n",
            "Step 1238: Training Loss = 0.1163\n",
            "Step 1238: Test Loss = 0.0858\n",
            "Step 1239: Training Loss = 0.1069\n",
            "Step 1239: Test Loss = 0.0530\n",
            "Step 1240: Training Loss = 0.0883\n",
            "Step 1240: Test Loss = 0.0588\n",
            "Step 1241: Training Loss = 0.0505\n",
            "Step 1241: Test Loss = 0.0405\n",
            "Step 1242: Training Loss = 0.1223\n",
            "Step 1242: Test Loss = 0.0611\n",
            "Step 1243: Training Loss = 0.0839\n",
            "Step 1243: Test Loss = 0.0460\n",
            "Step 1244: Training Loss = 0.1474\n",
            "Step 1244: Test Loss = 0.1013\n",
            "Step 1245: Training Loss = 0.2046\n",
            "Step 1245: Test Loss = 0.1573\n",
            "Step 1246: Training Loss = 0.1303\n",
            "Step 1246: Test Loss = 0.0880\n",
            "Step 1247: Training Loss = 0.1403\n",
            "Step 1247: Test Loss = 0.1069\n",
            "Step 1248: Training Loss = 0.1691\n",
            "Step 1248: Test Loss = 0.1029\n",
            "Step 1249: Training Loss = 0.1125\n",
            "Step 1249: Test Loss = 0.0758\n",
            "Step 1250: Training Loss = 0.2626\n",
            "Step 1250: Test Loss = 0.1342\n",
            "Step 1251: Training Loss = 0.1775\n",
            "Step 1251: Test Loss = 0.1318\n",
            "Step 1252: Training Loss = 0.1093\n",
            "Step 1252: Test Loss = 0.0578\n",
            "Step 1253: Training Loss = 0.0640\n",
            "Step 1253: Test Loss = 0.0526\n",
            "Step 1254: Training Loss = 0.2093\n",
            "Step 1254: Test Loss = 0.1165\n",
            "Step 1255: Training Loss = 0.0717\n",
            "Step 1255: Test Loss = 0.0527\n",
            "Step 1256: Training Loss = 0.1209\n",
            "Step 1256: Test Loss = 0.0866\n",
            "Step 1257: Training Loss = 0.1167\n",
            "Step 1257: Test Loss = 0.0827\n",
            "Step 1258: Training Loss = 0.0973\n",
            "Step 1258: Test Loss = 0.0608\n",
            "Step 1259: Training Loss = 0.1505\n",
            "Step 1259: Test Loss = 0.0963\n",
            "Step 1260: Training Loss = 0.1926\n",
            "Step 1260: Test Loss = 0.1286\n",
            "Step 1261: Training Loss = 0.0990\n",
            "Step 1261: Test Loss = 0.0763\n",
            "Step 1262: Training Loss = 0.0894\n",
            "Step 1262: Test Loss = 0.0672\n",
            "Step 1263: Training Loss = 0.0651\n",
            "Step 1263: Test Loss = 0.0424\n",
            "Step 1264: Training Loss = 0.0761\n",
            "Step 1264: Test Loss = 0.0547\n",
            "Step 1265: Training Loss = 0.0780\n",
            "Step 1265: Test Loss = 0.0453\n",
            "Step 1266: Training Loss = 0.1210\n",
            "Step 1266: Test Loss = 0.0594\n",
            "Step 1267: Training Loss = 0.1266\n",
            "Step 1267: Test Loss = 0.0924\n",
            "Step 1268: Training Loss = 0.0798\n",
            "Step 1268: Test Loss = 0.0561\n",
            "Step 1269: Training Loss = 0.1561\n",
            "Step 1269: Test Loss = 0.1079\n",
            "Step 1270: Training Loss = 0.1011\n",
            "Step 1270: Test Loss = 0.0489\n",
            "Step 1271: Training Loss = 0.0929\n",
            "Step 1271: Test Loss = 0.0319\n",
            "Step 1272: Training Loss = 0.1427\n",
            "Step 1272: Test Loss = 0.0805\n",
            "Step 1273: Training Loss = 0.0425\n",
            "Step 1273: Test Loss = 0.0276\n",
            "Step 1274: Training Loss = 0.0664\n",
            "Step 1274: Test Loss = 0.0437\n",
            "Step 1275: Training Loss = 0.1328\n",
            "Step 1275: Test Loss = 0.0813\n",
            "Step 1276: Training Loss = 0.1503\n",
            "Step 1276: Test Loss = 0.0646\n",
            "Step 1277: Training Loss = 0.0795\n",
            "Step 1277: Test Loss = 0.0425\n",
            "Step 1278: Training Loss = 0.1763\n",
            "Step 1278: Test Loss = 0.1111\n",
            "Step 1279: Training Loss = 0.0470\n",
            "Step 1279: Test Loss = 0.0326\n",
            "Step 1280: Training Loss = 0.1538\n",
            "Step 1280: Test Loss = 0.1149\n",
            "Step 1281: Training Loss = 0.1820\n",
            "Step 1281: Test Loss = 0.1332\n",
            "Step 1282: Training Loss = 0.0401\n",
            "Step 1282: Test Loss = 0.0185\n",
            "Step 1283: Training Loss = 0.1114\n",
            "Step 1283: Test Loss = 0.0871\n",
            "Step 1284: Training Loss = 0.1593\n",
            "Step 1284: Test Loss = 0.0943\n",
            "Step 1285: Training Loss = 0.1727\n",
            "Step 1285: Test Loss = 0.1024\n",
            "Step 1286: Training Loss = 0.1799\n",
            "Step 1286: Test Loss = 0.1109\n",
            "Step 1287: Training Loss = 0.2448\n",
            "Step 1287: Test Loss = 0.1281\n",
            "Step 1288: Training Loss = 0.1371\n",
            "Step 1288: Test Loss = 0.0878\n",
            "Step 1289: Training Loss = 0.0996\n",
            "Step 1289: Test Loss = 0.0635\n",
            "Step 1290: Training Loss = 0.0573\n",
            "Step 1290: Test Loss = 0.0360\n",
            "Step 1291: Training Loss = 0.0920\n",
            "Step 1291: Test Loss = 0.0628\n",
            "Step 1292: Training Loss = 0.0905\n",
            "Step 1292: Test Loss = 0.0641\n",
            "Step 1293: Training Loss = 0.1946\n",
            "Step 1293: Test Loss = 0.0812\n",
            "Step 1294: Training Loss = 0.2381\n",
            "Step 1294: Test Loss = 0.1308\n",
            "Step 1295: Training Loss = 0.1411\n",
            "Step 1295: Test Loss = 0.0932\n",
            "Step 1296: Training Loss = 0.0644\n",
            "Step 1296: Test Loss = 0.0371\n",
            "Step 1297: Training Loss = 0.1939\n",
            "Step 1297: Test Loss = 0.0973\n",
            "Step 1298: Training Loss = 0.0661\n",
            "Step 1298: Test Loss = 0.0391\n",
            "Step 1299: Training Loss = 0.1398\n",
            "Step 1299: Test Loss = 0.0794\n",
            "Step 1300: Training Loss = 0.0581\n",
            "Step 1300: Test Loss = 0.0481\n",
            "1300 65% (2m 31s) Train Loss: 0.1262, Test Loss: 0.0793, Accuracy: 0.9607 - veremecon. Vi esploras mian koron, ekzamenas gxin  / esperanto ✓\n",
            "Step 1301: Training Loss = 0.0698\n",
            "Step 1301: Test Loss = 0.0532\n",
            "Step 1302: Training Loss = 0.1242\n",
            "Step 1302: Test Loss = 0.0639\n",
            "Step 1303: Training Loss = 0.1651\n",
            "Step 1303: Test Loss = 0.0946\n",
            "Step 1304: Training Loss = 0.1054\n",
            "Step 1304: Test Loss = 0.0712\n",
            "Step 1305: Training Loss = 0.1067\n",
            "Step 1305: Test Loss = 0.0815\n",
            "Step 1306: Training Loss = 0.1234\n",
            "Step 1306: Test Loss = 0.0783\n",
            "Step 1307: Training Loss = 0.0747\n",
            "Step 1307: Test Loss = 0.0370\n",
            "Step 1308: Training Loss = 0.1637\n",
            "Step 1308: Test Loss = 0.1140\n",
            "Step 1309: Training Loss = 0.0541\n",
            "Step 1309: Test Loss = 0.0371\n",
            "Step 1310: Training Loss = 0.1541\n",
            "Step 1310: Test Loss = 0.1004\n",
            "Step 1311: Training Loss = 0.0944\n",
            "Step 1311: Test Loss = 0.0544\n",
            "Step 1312: Training Loss = 0.1127\n",
            "Step 1312: Test Loss = 0.0785\n",
            "Step 1313: Training Loss = 0.0476\n",
            "Step 1313: Test Loss = 0.0358\n",
            "Step 1314: Training Loss = 0.1277\n",
            "Step 1314: Test Loss = 0.0480\n",
            "Step 1315: Training Loss = 0.1346\n",
            "Step 1315: Test Loss = 0.0756\n",
            "Step 1316: Training Loss = 0.1494\n",
            "Step 1316: Test Loss = 0.0600\n",
            "Step 1317: Training Loss = 0.1541\n",
            "Step 1317: Test Loss = 0.1029\n",
            "Step 1318: Training Loss = 0.2296\n",
            "Step 1318: Test Loss = 0.1082\n",
            "Step 1319: Training Loss = 0.0380\n",
            "Step 1319: Test Loss = 0.0254\n",
            "Step 1320: Training Loss = 0.1564\n",
            "Step 1320: Test Loss = 0.0555\n",
            "Step 1321: Training Loss = 0.1010\n",
            "Step 1321: Test Loss = 0.0683\n",
            "Step 1322: Training Loss = 0.1329\n",
            "Step 1322: Test Loss = 0.0568\n",
            "Step 1323: Training Loss = 0.1137\n",
            "Step 1323: Test Loss = 0.0926\n",
            "Step 1324: Training Loss = 0.0659\n",
            "Step 1324: Test Loss = 0.0370\n",
            "Step 1325: Training Loss = 0.2003\n",
            "Step 1325: Test Loss = 0.1198\n",
            "Step 1326: Training Loss = 0.1350\n",
            "Step 1326: Test Loss = 0.0855\n",
            "Step 1327: Training Loss = 0.0767\n",
            "Step 1327: Test Loss = 0.0334\n",
            "Step 1328: Training Loss = 0.1447\n",
            "Step 1328: Test Loss = 0.0963\n",
            "Step 1329: Training Loss = 0.0837\n",
            "Step 1329: Test Loss = 0.0584\n",
            "Step 1330: Training Loss = 0.1195\n",
            "Step 1330: Test Loss = 0.0533\n",
            "Step 1331: Training Loss = 0.2030\n",
            "Step 1331: Test Loss = 0.1149\n",
            "Step 1332: Training Loss = 0.1672\n",
            "Step 1332: Test Loss = 0.0866\n",
            "Step 1333: Training Loss = 0.1127\n",
            "Step 1333: Test Loss = 0.0801\n",
            "Step 1334: Training Loss = 0.0652\n",
            "Step 1334: Test Loss = 0.0267\n",
            "Step 1335: Training Loss = 0.1723\n",
            "Step 1335: Test Loss = 0.1167\n",
            "Step 1336: Training Loss = 0.1398\n",
            "Step 1336: Test Loss = 0.0736\n",
            "Step 1337: Training Loss = 0.1594\n",
            "Step 1337: Test Loss = 0.0766\n",
            "Step 1338: Training Loss = 0.1072\n",
            "Step 1338: Test Loss = 0.0703\n",
            "Step 1339: Training Loss = 0.0541\n",
            "Step 1339: Test Loss = 0.0324\n",
            "Step 1340: Training Loss = 0.0637\n",
            "Step 1340: Test Loss = 0.0407\n",
            "Step 1341: Training Loss = 0.1781\n",
            "Step 1341: Test Loss = 0.1048\n",
            "Step 1342: Training Loss = 0.1287\n",
            "Step 1342: Test Loss = 0.0786\n",
            "Step 1343: Training Loss = 0.2024\n",
            "Step 1343: Test Loss = 0.1382\n",
            "Step 1344: Training Loss = 0.1478\n",
            "Step 1344: Test Loss = 0.0628\n",
            "Step 1345: Training Loss = 0.0720\n",
            "Step 1345: Test Loss = 0.0345\n",
            "Step 1346: Training Loss = 0.2585\n",
            "Step 1346: Test Loss = 0.1974\n",
            "Step 1347: Training Loss = 0.1726\n",
            "Step 1347: Test Loss = 0.1041\n",
            "Step 1348: Training Loss = 0.1598\n",
            "Step 1348: Test Loss = 0.0922\n",
            "Step 1349: Training Loss = 0.0924\n",
            "Step 1349: Test Loss = 0.0536\n",
            "Step 1350: Training Loss = 0.1356\n",
            "Step 1350: Test Loss = 0.0967\n",
            "Step 1351: Training Loss = 0.1487\n",
            "Step 1351: Test Loss = 0.0896\n",
            "Step 1352: Training Loss = 0.0742\n",
            "Step 1352: Test Loss = 0.0382\n",
            "Step 1353: Training Loss = 0.0970\n",
            "Step 1353: Test Loss = 0.0466\n",
            "Step 1354: Training Loss = 0.1413\n",
            "Step 1354: Test Loss = 0.0731\n",
            "Step 1355: Training Loss = 0.2362\n",
            "Step 1355: Test Loss = 0.1548\n",
            "Step 1356: Training Loss = 0.1566\n",
            "Step 1356: Test Loss = 0.1081\n",
            "Step 1357: Training Loss = 0.1388\n",
            "Step 1357: Test Loss = 0.0772\n",
            "Step 1358: Training Loss = 0.1259\n",
            "Step 1358: Test Loss = 0.0507\n",
            "Step 1359: Training Loss = 0.1140\n",
            "Step 1359: Test Loss = 0.0562\n",
            "Step 1360: Training Loss = 0.0610\n",
            "Step 1360: Test Loss = 0.0434\n",
            "Step 1361: Training Loss = 0.1759\n",
            "Step 1361: Test Loss = 0.0734\n",
            "Step 1362: Training Loss = 0.1685\n",
            "Step 1362: Test Loss = 0.1039\n",
            "Step 1363: Training Loss = 0.0991\n",
            "Step 1363: Test Loss = 0.0230\n",
            "Step 1364: Training Loss = 0.0747\n",
            "Step 1364: Test Loss = 0.0478\n",
            "Step 1365: Training Loss = 0.0640\n",
            "Step 1365: Test Loss = 0.0323\n",
            "Step 1366: Training Loss = 0.0790\n",
            "Step 1366: Test Loss = 0.0592\n",
            "Step 1367: Training Loss = 0.1063\n",
            "Step 1367: Test Loss = 0.0753\n",
            "Step 1368: Training Loss = 0.1328\n",
            "Step 1368: Test Loss = 0.0634\n",
            "Step 1369: Training Loss = 0.2166\n",
            "Step 1369: Test Loss = 0.1405\n",
            "Step 1370: Training Loss = 0.1274\n",
            "Step 1370: Test Loss = 0.0493\n",
            "Step 1371: Training Loss = 0.0834\n",
            "Step 1371: Test Loss = 0.0560\n",
            "Step 1372: Training Loss = 0.1927\n",
            "Step 1372: Test Loss = 0.1116\n",
            "Step 1373: Training Loss = 0.1267\n",
            "Step 1373: Test Loss = 0.0667\n",
            "Step 1374: Training Loss = 0.0682\n",
            "Step 1374: Test Loss = 0.0444\n",
            "Step 1375: Training Loss = 0.1463\n",
            "Step 1375: Test Loss = 0.1112\n",
            "Step 1376: Training Loss = 0.1375\n",
            "Step 1376: Test Loss = 0.0662\n",
            "Step 1377: Training Loss = 0.1497\n",
            "Step 1377: Test Loss = 0.0888\n",
            "Step 1378: Training Loss = 0.2048\n",
            "Step 1378: Test Loss = 0.1485\n",
            "Step 1379: Training Loss = 0.1903\n",
            "Step 1379: Test Loss = 0.0932\n",
            "Step 1380: Training Loss = 0.1008\n",
            "Step 1380: Test Loss = 0.0613\n",
            "Step 1381: Training Loss = 0.1156\n",
            "Step 1381: Test Loss = 0.0884\n",
            "Step 1382: Training Loss = 0.1181\n",
            "Step 1382: Test Loss = 0.0681\n",
            "Step 1383: Training Loss = 0.1011\n",
            "Step 1383: Test Loss = 0.0710\n",
            "Step 1384: Training Loss = 0.1457\n",
            "Step 1384: Test Loss = 0.1018\n",
            "Step 1385: Training Loss = 0.1004\n",
            "Step 1385: Test Loss = 0.0583\n",
            "Step 1386: Training Loss = 0.1742\n",
            "Step 1386: Test Loss = 0.1151\n",
            "Step 1387: Training Loss = 0.1518\n",
            "Step 1387: Test Loss = 0.0773\n",
            "Step 1388: Training Loss = 0.1757\n",
            "Step 1388: Test Loss = 0.1125\n",
            "Step 1389: Training Loss = 0.1225\n",
            "Step 1389: Test Loss = 0.0800\n",
            "Step 1390: Training Loss = 0.1115\n",
            "Step 1390: Test Loss = 0.0539\n",
            "Step 1391: Training Loss = 0.0980\n",
            "Step 1391: Test Loss = 0.0503\n",
            "Step 1392: Training Loss = 0.1901\n",
            "Step 1392: Test Loss = 0.1176\n",
            "Step 1393: Training Loss = 0.1366\n",
            "Step 1393: Test Loss = 0.0721\n",
            "Step 1394: Training Loss = 0.1065\n",
            "Step 1394: Test Loss = 0.0837\n",
            "Step 1395: Training Loss = 0.1332\n",
            "Step 1395: Test Loss = 0.0439\n",
            "Step 1396: Training Loss = 0.1332\n",
            "Step 1396: Test Loss = 0.0688\n",
            "Step 1397: Training Loss = 0.1028\n",
            "Step 1397: Test Loss = 0.0677\n",
            "Step 1398: Training Loss = 0.1097\n",
            "Step 1398: Test Loss = 0.0526\n",
            "Step 1399: Training Loss = 0.2980\n",
            "Step 1399: Test Loss = 0.1924\n",
            "Step 1400: Training Loss = 0.1899\n",
            "Step 1400: Test Loss = 0.0814\n",
            "1400 70% (2m 43s) Train Loss: 0.1310, Test Loss: 0.0767, Accuracy: 0.9582 - u bi tan hai. Dap rang: Chung toi no chiu nguoi ta / vietnamese ✓\n",
            "Step 1401: Training Loss = 0.1032\n",
            "Step 1401: Test Loss = 0.0860\n",
            "Step 1402: Training Loss = 0.1247\n",
            "Step 1402: Test Loss = 0.0678\n",
            "Step 1403: Training Loss = 0.1466\n",
            "Step 1403: Test Loss = 0.0803\n",
            "Step 1404: Training Loss = 0.0990\n",
            "Step 1404: Test Loss = 0.0480\n",
            "Step 1405: Training Loss = 0.1059\n",
            "Step 1405: Test Loss = 0.0659\n",
            "Step 1406: Training Loss = 0.1603\n",
            "Step 1406: Test Loss = 0.1050\n",
            "Step 1407: Training Loss = 0.1211\n",
            "Step 1407: Test Loss = 0.0693\n",
            "Step 1408: Training Loss = 0.0429\n",
            "Step 1408: Test Loss = 0.0247\n",
            "Step 1409: Training Loss = 0.1172\n",
            "Step 1409: Test Loss = 0.0560\n",
            "Step 1410: Training Loss = 0.1038\n",
            "Step 1410: Test Loss = 0.0696\n",
            "Step 1411: Training Loss = 0.2002\n",
            "Step 1411: Test Loss = 0.1297\n",
            "Step 1412: Training Loss = 0.0588\n",
            "Step 1412: Test Loss = 0.0420\n",
            "Step 1413: Training Loss = 0.1232\n",
            "Step 1413: Test Loss = 0.0936\n",
            "Step 1414: Training Loss = 0.1002\n",
            "Step 1414: Test Loss = 0.0523\n",
            "Step 1415: Training Loss = 0.0566\n",
            "Step 1415: Test Loss = 0.0426\n",
            "Step 1416: Training Loss = 0.0616\n",
            "Step 1416: Test Loss = 0.0467\n",
            "Step 1417: Training Loss = 0.1471\n",
            "Step 1417: Test Loss = 0.0838\n",
            "Step 1418: Training Loss = 0.1551\n",
            "Step 1418: Test Loss = 0.0685\n",
            "Step 1419: Training Loss = 0.1343\n",
            "Step 1419: Test Loss = 0.0524\n",
            "Step 1420: Training Loss = 0.0924\n",
            "Step 1420: Test Loss = 0.0557\n",
            "Step 1421: Training Loss = 0.1541\n",
            "Step 1421: Test Loss = 0.1248\n",
            "Step 1422: Training Loss = 0.0975\n",
            "Step 1422: Test Loss = 0.0527\n",
            "Step 1423: Training Loss = 0.1777\n",
            "Step 1423: Test Loss = 0.1372\n",
            "Step 1424: Training Loss = 0.0750\n",
            "Step 1424: Test Loss = 0.0320\n",
            "Step 1425: Training Loss = 0.1541\n",
            "Step 1425: Test Loss = 0.0806\n",
            "Step 1426: Training Loss = 0.0962\n",
            "Step 1426: Test Loss = 0.0709\n",
            "Step 1427: Training Loss = 0.1051\n",
            "Step 1427: Test Loss = 0.0565\n",
            "Step 1428: Training Loss = 0.0996\n",
            "Step 1428: Test Loss = 0.0704\n",
            "Step 1429: Training Loss = 0.1241\n",
            "Step 1429: Test Loss = 0.0748\n",
            "Step 1430: Training Loss = 0.0741\n",
            "Step 1430: Test Loss = 0.0390\n",
            "Step 1431: Training Loss = 0.1025\n",
            "Step 1431: Test Loss = 0.0486\n",
            "Step 1432: Training Loss = 0.0490\n",
            "Step 1432: Test Loss = 0.0329\n",
            "Step 1433: Training Loss = 0.1267\n",
            "Step 1433: Test Loss = 0.0453\n",
            "Step 1434: Training Loss = 0.0664\n",
            "Step 1434: Test Loss = 0.0520\n",
            "Step 1435: Training Loss = 0.1875\n",
            "Step 1435: Test Loss = 0.1118\n",
            "Step 1436: Training Loss = 0.1198\n",
            "Step 1436: Test Loss = 0.0544\n",
            "Step 1437: Training Loss = 0.0808\n",
            "Step 1437: Test Loss = 0.0332\n",
            "Step 1438: Training Loss = 0.1139\n",
            "Step 1438: Test Loss = 0.0784\n",
            "Step 1439: Training Loss = 0.0825\n",
            "Step 1439: Test Loss = 0.0462\n",
            "Step 1440: Training Loss = 0.0903\n",
            "Step 1440: Test Loss = 0.0723\n",
            "Step 1441: Training Loss = 0.1757\n",
            "Step 1441: Test Loss = 0.1051\n",
            "Step 1442: Training Loss = 0.0836\n",
            "Step 1442: Test Loss = 0.0480\n",
            "Step 1443: Training Loss = 0.1361\n",
            "Step 1443: Test Loss = 0.0769\n",
            "Step 1444: Training Loss = 0.1119\n",
            "Step 1444: Test Loss = 0.0507\n",
            "Step 1445: Training Loss = 0.0680\n",
            "Step 1445: Test Loss = 0.0423\n",
            "Step 1446: Training Loss = 0.1766\n",
            "Step 1446: Test Loss = 0.1143\n",
            "Step 1447: Training Loss = 0.1079\n",
            "Step 1447: Test Loss = 0.0391\n",
            "Step 1448: Training Loss = 0.2044\n",
            "Step 1448: Test Loss = 0.1041\n",
            "Step 1449: Training Loss = 0.2350\n",
            "Step 1449: Test Loss = 0.1869\n",
            "Step 1450: Training Loss = 0.0688\n",
            "Step 1450: Test Loss = 0.0466\n",
            "Step 1451: Training Loss = 0.0818\n",
            "Step 1451: Test Loss = 0.0399\n",
            "Step 1452: Training Loss = 0.0379\n",
            "Step 1452: Test Loss = 0.0225\n",
            "Step 1453: Training Loss = 0.0673\n",
            "Step 1453: Test Loss = 0.0342\n",
            "Step 1454: Training Loss = 0.1394\n",
            "Step 1454: Test Loss = 0.0530\n",
            "Step 1455: Training Loss = 0.1680\n",
            "Step 1455: Test Loss = 0.1139\n",
            "Step 1456: Training Loss = 0.2186\n",
            "Step 1456: Test Loss = 0.1351\n",
            "Step 1457: Training Loss = 0.1022\n",
            "Step 1457: Test Loss = 0.0726\n",
            "Step 1458: Training Loss = 0.1303\n",
            "Step 1458: Test Loss = 0.0801\n",
            "Step 1459: Training Loss = 0.2141\n",
            "Step 1459: Test Loss = 0.1316\n",
            "Step 1460: Training Loss = 0.0737\n",
            "Step 1460: Test Loss = 0.0563\n",
            "Step 1461: Training Loss = 0.1578\n",
            "Step 1461: Test Loss = 0.0736\n",
            "Step 1462: Training Loss = 0.0339\n",
            "Step 1462: Test Loss = 0.0236\n",
            "Step 1463: Training Loss = 0.1123\n",
            "Step 1463: Test Loss = 0.0652\n",
            "Step 1464: Training Loss = 0.1777\n",
            "Step 1464: Test Loss = 0.1197\n",
            "Step 1465: Training Loss = 0.1048\n",
            "Step 1465: Test Loss = 0.0936\n",
            "Step 1466: Training Loss = 0.0522\n",
            "Step 1466: Test Loss = 0.0382\n",
            "Step 1467: Training Loss = 0.1521\n",
            "Step 1467: Test Loss = 0.1025\n",
            "Step 1468: Training Loss = 0.1339\n",
            "Step 1468: Test Loss = 0.0838\n",
            "Step 1469: Training Loss = 0.0995\n",
            "Step 1469: Test Loss = 0.0701\n",
            "Step 1470: Training Loss = 0.1592\n",
            "Step 1470: Test Loss = 0.0998\n",
            "Step 1471: Training Loss = 0.1196\n",
            "Step 1471: Test Loss = 0.0459\n",
            "Step 1472: Training Loss = 0.1306\n",
            "Step 1472: Test Loss = 0.0748\n",
            "Step 1473: Training Loss = 0.0977\n",
            "Step 1473: Test Loss = 0.0347\n",
            "Step 1474: Training Loss = 0.1027\n",
            "Step 1474: Test Loss = 0.0764\n",
            "Step 1475: Training Loss = 0.0977\n",
            "Step 1475: Test Loss = 0.0834\n",
            "Step 1476: Training Loss = 0.1719\n",
            "Step 1476: Test Loss = 0.1184\n",
            "Step 1477: Training Loss = 0.0855\n",
            "Step 1477: Test Loss = 0.0476\n",
            "Step 1478: Training Loss = 0.1015\n",
            "Step 1478: Test Loss = 0.0493\n",
            "Step 1479: Training Loss = 0.0905\n",
            "Step 1479: Test Loss = 0.0348\n",
            "Step 1480: Training Loss = 0.1225\n",
            "Step 1480: Test Loss = 0.0648\n",
            "Step 1481: Training Loss = 0.1094\n",
            "Step 1481: Test Loss = 0.0565\n",
            "Step 1482: Training Loss = 0.0885\n",
            "Step 1482: Test Loss = 0.0556\n",
            "Step 1483: Training Loss = 0.1215\n",
            "Step 1483: Test Loss = 0.0890\n",
            "Step 1484: Training Loss = 0.1269\n",
            "Step 1484: Test Loss = 0.0689\n",
            "Step 1485: Training Loss = 0.1124\n",
            "Step 1485: Test Loss = 0.0787\n",
            "Step 1486: Training Loss = 0.0820\n",
            "Step 1486: Test Loss = 0.0545\n",
            "Step 1487: Training Loss = 0.1693\n",
            "Step 1487: Test Loss = 0.1185\n",
            "Step 1488: Training Loss = 0.1889\n",
            "Step 1488: Test Loss = 0.1385\n",
            "Step 1489: Training Loss = 0.0647\n",
            "Step 1489: Test Loss = 0.0468\n",
            "Step 1490: Training Loss = 0.1048\n",
            "Step 1490: Test Loss = 0.0717\n",
            "Step 1491: Training Loss = 0.1377\n",
            "Step 1491: Test Loss = 0.0601\n",
            "Step 1492: Training Loss = 0.1194\n",
            "Step 1492: Test Loss = 0.0459\n",
            "Step 1493: Training Loss = 0.1347\n",
            "Step 1493: Test Loss = 0.0691\n",
            "Step 1494: Training Loss = 0.0689\n",
            "Step 1494: Test Loss = 0.0433\n",
            "Step 1495: Training Loss = 0.1288\n",
            "Step 1495: Test Loss = 0.0636\n",
            "Step 1496: Training Loss = 0.2110\n",
            "Step 1496: Test Loss = 0.1207\n",
            "Step 1497: Training Loss = 0.0932\n",
            "Step 1497: Test Loss = 0.0331\n",
            "Step 1498: Training Loss = 0.0440\n",
            "Step 1498: Test Loss = 0.0283\n",
            "Step 1499: Training Loss = 0.1311\n",
            "Step 1499: Test Loss = 0.0650\n",
            "Step 1500: Training Loss = 0.1662\n",
            "Step 1500: Test Loss = 0.1191\n",
            "1500 75% (2m 55s) Train Loss: 0.1174, Test Loss: 0.0703, Accuracy: 0.9603 - Mia sinjoro, ho regxo, vi jxuris ja al via servant / esperanto ✓\n",
            "Step 1501: Training Loss = 0.1410\n",
            "Step 1501: Test Loss = 0.1032\n",
            "Step 1502: Training Loss = 0.1759\n",
            "Step 1502: Test Loss = 0.1294\n",
            "Step 1503: Training Loss = 0.1619\n",
            "Step 1503: Test Loss = 0.1011\n",
            "Step 1504: Training Loss = 0.1014\n",
            "Step 1504: Test Loss = 0.0569\n",
            "Step 1505: Training Loss = 0.0754\n",
            "Step 1505: Test Loss = 0.0444\n",
            "Step 1506: Training Loss = 0.1363\n",
            "Step 1506: Test Loss = 0.0902\n",
            "Step 1507: Training Loss = 0.1208\n",
            "Step 1507: Test Loss = 0.0774\n",
            "Step 1508: Training Loss = 0.2089\n",
            "Step 1508: Test Loss = 0.1085\n",
            "Step 1509: Training Loss = 0.0769\n",
            "Step 1509: Test Loss = 0.0547\n",
            "Step 1510: Training Loss = 0.2112\n",
            "Step 1510: Test Loss = 0.1350\n",
            "Step 1511: Training Loss = 0.2355\n",
            "Step 1511: Test Loss = 0.1382\n",
            "Step 1512: Training Loss = 0.0705\n",
            "Step 1512: Test Loss = 0.0289\n",
            "Step 1513: Training Loss = 0.0915\n",
            "Step 1513: Test Loss = 0.0718\n",
            "Step 1514: Training Loss = 0.0824\n",
            "Step 1514: Test Loss = 0.0570\n",
            "Step 1515: Training Loss = 0.1243\n",
            "Step 1515: Test Loss = 0.0513\n",
            "Step 1516: Training Loss = 0.1350\n",
            "Step 1516: Test Loss = 0.0949\n",
            "Step 1517: Training Loss = 0.0431\n",
            "Step 1517: Test Loss = 0.0313\n",
            "Step 1518: Training Loss = 0.2805\n",
            "Step 1518: Test Loss = 0.1930\n",
            "Step 1519: Training Loss = 0.1089\n",
            "Step 1519: Test Loss = 0.0506\n",
            "Step 1520: Training Loss = 0.1016\n",
            "Step 1520: Test Loss = 0.0693\n",
            "Step 1521: Training Loss = 0.1972\n",
            "Step 1521: Test Loss = 0.0991\n",
            "Step 1522: Training Loss = 0.1124\n",
            "Step 1522: Test Loss = 0.0555\n",
            "Step 1523: Training Loss = 0.0428\n",
            "Step 1523: Test Loss = 0.0267\n",
            "Step 1524: Training Loss = 0.0886\n",
            "Step 1524: Test Loss = 0.0394\n",
            "Step 1525: Training Loss = 0.1191\n",
            "Step 1525: Test Loss = 0.0519\n",
            "Step 1526: Training Loss = 0.0594\n",
            "Step 1526: Test Loss = 0.0408\n",
            "Step 1527: Training Loss = 0.0779\n",
            "Step 1527: Test Loss = 0.0420\n",
            "Step 1528: Training Loss = 0.0679\n",
            "Step 1528: Test Loss = 0.0357\n",
            "Step 1529: Training Loss = 0.2346\n",
            "Step 1529: Test Loss = 0.1540\n",
            "Step 1530: Training Loss = 0.1452\n",
            "Step 1530: Test Loss = 0.0680\n",
            "Step 1531: Training Loss = 0.2473\n",
            "Step 1531: Test Loss = 0.1057\n",
            "Step 1532: Training Loss = 0.0415\n",
            "Step 1532: Test Loss = 0.0300\n",
            "Step 1533: Training Loss = 0.0615\n",
            "Step 1533: Test Loss = 0.0444\n",
            "Step 1534: Training Loss = 0.0720\n",
            "Step 1534: Test Loss = 0.0517\n",
            "Step 1535: Training Loss = 0.1076\n",
            "Step 1535: Test Loss = 0.0752\n",
            "Step 1536: Training Loss = 0.1441\n",
            "Step 1536: Test Loss = 0.1100\n",
            "Step 1537: Training Loss = 0.1417\n",
            "Step 1537: Test Loss = 0.0471\n",
            "Step 1538: Training Loss = 0.0594\n",
            "Step 1538: Test Loss = 0.0408\n",
            "Step 1539: Training Loss = 0.0838\n",
            "Step 1539: Test Loss = 0.0523\n",
            "Step 1540: Training Loss = 0.1565\n",
            "Step 1540: Test Loss = 0.0766\n",
            "Step 1541: Training Loss = 0.1719\n",
            "Step 1541: Test Loss = 0.0948\n",
            "Step 1542: Training Loss = 0.0808\n",
            "Step 1542: Test Loss = 0.0518\n",
            "Step 1543: Training Loss = 0.0687\n",
            "Step 1543: Test Loss = 0.0390\n",
            "Step 1544: Training Loss = 0.0902\n",
            "Step 1544: Test Loss = 0.0595\n",
            "Step 1545: Training Loss = 0.1264\n",
            "Step 1545: Test Loss = 0.0804\n",
            "Step 1546: Training Loss = 0.0506\n",
            "Step 1546: Test Loss = 0.0373\n",
            "Step 1547: Training Loss = 0.0987\n",
            "Step 1547: Test Loss = 0.0383\n",
            "Step 1548: Training Loss = 0.1145\n",
            "Step 1548: Test Loss = 0.0581\n",
            "Step 1549: Training Loss = 0.0937\n",
            "Step 1549: Test Loss = 0.0502\n",
            "Step 1550: Training Loss = 0.1138\n",
            "Step 1550: Test Loss = 0.0421\n",
            "Step 1551: Training Loss = 0.0439\n",
            "Step 1551: Test Loss = 0.0341\n",
            "Step 1552: Training Loss = 0.0585\n",
            "Step 1552: Test Loss = 0.0418\n",
            "Step 1553: Training Loss = 0.1443\n",
            "Step 1553: Test Loss = 0.0859\n",
            "Step 1554: Training Loss = 0.0425\n",
            "Step 1554: Test Loss = 0.0345\n",
            "Step 1555: Training Loss = 0.0296\n",
            "Step 1555: Test Loss = 0.0187\n",
            "Step 1556: Training Loss = 0.1221\n",
            "Step 1556: Test Loss = 0.0607\n",
            "Step 1557: Training Loss = 0.1721\n",
            "Step 1557: Test Loss = 0.0994\n",
            "Step 1558: Training Loss = 0.1134\n",
            "Step 1558: Test Loss = 0.0300\n",
            "Step 1559: Training Loss = 0.1903\n",
            "Step 1559: Test Loss = 0.0991\n",
            "Step 1560: Training Loss = 0.0693\n",
            "Step 1560: Test Loss = 0.0281\n",
            "Step 1561: Training Loss = 0.1384\n",
            "Step 1561: Test Loss = 0.0997\n",
            "Step 1562: Training Loss = 0.1375\n",
            "Step 1562: Test Loss = 0.0741\n",
            "Step 1563: Training Loss = 0.0771\n",
            "Step 1563: Test Loss = 0.0431\n",
            "Step 1564: Training Loss = 0.0792\n",
            "Step 1564: Test Loss = 0.0376\n",
            "Step 1565: Training Loss = 0.0609\n",
            "Step 1565: Test Loss = 0.0312\n",
            "Step 1566: Training Loss = 0.0695\n",
            "Step 1566: Test Loss = 0.0455\n",
            "Step 1567: Training Loss = 0.0756\n",
            "Step 1567: Test Loss = 0.0463\n",
            "Step 1568: Training Loss = 0.0131\n",
            "Step 1568: Test Loss = 0.0111\n",
            "Step 1569: Training Loss = 0.1260\n",
            "Step 1569: Test Loss = 0.0596\n",
            "Step 1570: Training Loss = 0.1083\n",
            "Step 1570: Test Loss = 0.0670\n",
            "Step 1571: Training Loss = 0.1376\n",
            "Step 1571: Test Loss = 0.0738\n",
            "Step 1572: Training Loss = 0.1126\n",
            "Step 1572: Test Loss = 0.0300\n",
            "Step 1573: Training Loss = 0.1385\n",
            "Step 1573: Test Loss = 0.0683\n",
            "Step 1574: Training Loss = 0.1008\n",
            "Step 1574: Test Loss = 0.0563\n",
            "Step 1575: Training Loss = 0.1599\n",
            "Step 1575: Test Loss = 0.0892\n",
            "Step 1576: Training Loss = 0.1805\n",
            "Step 1576: Test Loss = 0.1248\n",
            "Step 1577: Training Loss = 0.1232\n",
            "Step 1577: Test Loss = 0.0541\n",
            "Step 1578: Training Loss = 0.1140\n",
            "Step 1578: Test Loss = 0.0939\n",
            "Step 1579: Training Loss = 0.1399\n",
            "Step 1579: Test Loss = 0.0704\n",
            "Step 1580: Training Loss = 0.0738\n",
            "Step 1580: Test Loss = 0.0419\n",
            "Step 1581: Training Loss = 0.1532\n",
            "Step 1581: Test Loss = 0.1205\n",
            "Step 1582: Training Loss = 0.0774\n",
            "Step 1582: Test Loss = 0.0261\n",
            "Step 1583: Training Loss = 0.0453\n",
            "Step 1583: Test Loss = 0.0321\n",
            "Step 1584: Training Loss = 0.0966\n",
            "Step 1584: Test Loss = 0.0679\n",
            "Step 1585: Training Loss = 0.1398\n",
            "Step 1585: Test Loss = 0.0789\n",
            "Step 1586: Training Loss = 0.0798\n",
            "Step 1586: Test Loss = 0.0426\n",
            "Step 1587: Training Loss = 0.1399\n",
            "Step 1587: Test Loss = 0.0627\n",
            "Step 1588: Training Loss = 0.1548\n",
            "Step 1588: Test Loss = 0.0958\n",
            "Step 1589: Training Loss = 0.1584\n",
            "Step 1589: Test Loss = 0.1153\n",
            "Step 1590: Training Loss = 0.0864\n",
            "Step 1590: Test Loss = 0.0636\n",
            "Step 1591: Training Loss = 0.0465\n",
            "Step 1591: Test Loss = 0.0306\n",
            "Step 1592: Training Loss = 0.1507\n",
            "Step 1592: Test Loss = 0.0690\n",
            "Step 1593: Training Loss = 0.1181\n",
            "Step 1593: Test Loss = 0.0615\n",
            "Step 1594: Training Loss = 0.0870\n",
            "Step 1594: Test Loss = 0.0634\n",
            "Step 1595: Training Loss = 0.0877\n",
            "Step 1595: Test Loss = 0.0425\n",
            "Step 1596: Training Loss = 0.0678\n",
            "Step 1596: Test Loss = 0.0452\n",
            "Step 1597: Training Loss = 0.0654\n",
            "Step 1597: Test Loss = 0.0415\n",
            "Step 1598: Training Loss = 0.1256\n",
            "Step 1598: Test Loss = 0.0717\n",
            "Step 1599: Training Loss = 0.0442\n",
            "Step 1599: Test Loss = 0.0300\n",
            "Step 1600: Training Loss = 0.0852\n",
            "Step 1600: Test Loss = 0.0293\n",
            "1600 80% (3m 6s) Train Loss: 0.1112, Test Loss: 0.0643, Accuracy: 0.9621 - mene, z kvadru rezanych na miru pilou, a to od zak / czech ✓\n",
            "Step 1601: Training Loss = 0.1089\n",
            "Step 1601: Test Loss = 0.0556\n",
            "Step 1602: Training Loss = 0.1119\n",
            "Step 1602: Test Loss = 0.0690\n",
            "Step 1603: Training Loss = 0.1678\n",
            "Step 1603: Test Loss = 0.0992\n",
            "Step 1604: Training Loss = 0.1524\n",
            "Step 1604: Test Loss = 0.0755\n",
            "Step 1605: Training Loss = 0.0532\n",
            "Step 1605: Test Loss = 0.0300\n",
            "Step 1606: Training Loss = 0.0436\n",
            "Step 1606: Test Loss = 0.0252\n",
            "Step 1607: Training Loss = 0.0629\n",
            "Step 1607: Test Loss = 0.0272\n",
            "Step 1608: Training Loss = 0.0466\n",
            "Step 1608: Test Loss = 0.0342\n",
            "Step 1609: Training Loss = 0.0994\n",
            "Step 1609: Test Loss = 0.0401\n",
            "Step 1610: Training Loss = 0.0198\n",
            "Step 1610: Test Loss = 0.0183\n",
            "Step 1611: Training Loss = 0.1458\n",
            "Step 1611: Test Loss = 0.0946\n",
            "Step 1612: Training Loss = 0.1777\n",
            "Step 1612: Test Loss = 0.0754\n",
            "Step 1613: Training Loss = 0.0679\n",
            "Step 1613: Test Loss = 0.0480\n",
            "Step 1614: Training Loss = 0.1142\n",
            "Step 1614: Test Loss = 0.0199\n",
            "Step 1615: Training Loss = 0.1146\n",
            "Step 1615: Test Loss = 0.0563\n",
            "Step 1616: Training Loss = 0.1407\n",
            "Step 1616: Test Loss = 0.0890\n",
            "Step 1617: Training Loss = 0.0561\n",
            "Step 1617: Test Loss = 0.0354\n",
            "Step 1618: Training Loss = 0.2297\n",
            "Step 1618: Test Loss = 0.1586\n",
            "Step 1619: Training Loss = 0.0522\n",
            "Step 1619: Test Loss = 0.0233\n",
            "Step 1620: Training Loss = 0.0731\n",
            "Step 1620: Test Loss = 0.0269\n",
            "Step 1621: Training Loss = 0.2405\n",
            "Step 1621: Test Loss = 0.1358\n",
            "Step 1622: Training Loss = 0.0989\n",
            "Step 1622: Test Loss = 0.0653\n",
            "Step 1623: Training Loss = 0.1265\n",
            "Step 1623: Test Loss = 0.0692\n",
            "Step 1624: Training Loss = 0.0901\n",
            "Step 1624: Test Loss = 0.0456\n",
            "Step 1625: Training Loss = 0.1096\n",
            "Step 1625: Test Loss = 0.0911\n",
            "Step 1626: Training Loss = 0.0685\n",
            "Step 1626: Test Loss = 0.0261\n",
            "Step 1627: Training Loss = 0.1142\n",
            "Step 1627: Test Loss = 0.0516\n",
            "Step 1628: Training Loss = 0.1924\n",
            "Step 1628: Test Loss = 0.1066\n",
            "Step 1629: Training Loss = 0.1588\n",
            "Step 1629: Test Loss = 0.1110\n",
            "Step 1630: Training Loss = 0.1421\n",
            "Step 1630: Test Loss = 0.0795\n",
            "Step 1631: Training Loss = 0.1131\n",
            "Step 1631: Test Loss = 0.0585\n",
            "Step 1632: Training Loss = 0.0888\n",
            "Step 1632: Test Loss = 0.0422\n",
            "Step 1633: Training Loss = 0.1082\n",
            "Step 1633: Test Loss = 0.0718\n",
            "Step 1634: Training Loss = 0.0770\n",
            "Step 1634: Test Loss = 0.0329\n",
            "Step 1635: Training Loss = 0.0530\n",
            "Step 1635: Test Loss = 0.0315\n",
            "Step 1636: Training Loss = 0.1243\n",
            "Step 1636: Test Loss = 0.0699\n",
            "Step 1637: Training Loss = 0.2765\n",
            "Step 1637: Test Loss = 0.1852\n",
            "Step 1638: Training Loss = 0.1026\n",
            "Step 1638: Test Loss = 0.0533\n",
            "Step 1639: Training Loss = 0.0730\n",
            "Step 1639: Test Loss = 0.0261\n",
            "Step 1640: Training Loss = 0.0700\n",
            "Step 1640: Test Loss = 0.0281\n",
            "Step 1641: Training Loss = 0.0406\n",
            "Step 1641: Test Loss = 0.0296\n",
            "Step 1642: Training Loss = 0.1426\n",
            "Step 1642: Test Loss = 0.0830\n",
            "Step 1643: Training Loss = 0.1170\n",
            "Step 1643: Test Loss = 0.0673\n",
            "Step 1644: Training Loss = 0.1768\n",
            "Step 1644: Test Loss = 0.1280\n",
            "Step 1645: Training Loss = 0.1689\n",
            "Step 1645: Test Loss = 0.0949\n",
            "Step 1646: Training Loss = 0.1997\n",
            "Step 1646: Test Loss = 0.1134\n",
            "Step 1647: Training Loss = 0.1466\n",
            "Step 1647: Test Loss = 0.0811\n",
            "Step 1648: Training Loss = 0.0865\n",
            "Step 1648: Test Loss = 0.0698\n",
            "Step 1649: Training Loss = 0.1357\n",
            "Step 1649: Test Loss = 0.0547\n",
            "Step 1650: Training Loss = 0.1062\n",
            "Step 1650: Test Loss = 0.0557\n",
            "Step 1651: Training Loss = 0.1179\n",
            "Step 1651: Test Loss = 0.0809\n",
            "Step 1652: Training Loss = 0.0276\n",
            "Step 1652: Test Loss = 0.0208\n",
            "Step 1653: Training Loss = 0.1358\n",
            "Step 1653: Test Loss = 0.0889\n",
            "Step 1654: Training Loss = 0.0773\n",
            "Step 1654: Test Loss = 0.0356\n",
            "Step 1655: Training Loss = 0.0697\n",
            "Step 1655: Test Loss = 0.0506\n",
            "Step 1656: Training Loss = 0.1076\n",
            "Step 1656: Test Loss = 0.0441\n",
            "Step 1657: Training Loss = 0.0294\n",
            "Step 1657: Test Loss = 0.0200\n",
            "Step 1658: Training Loss = 0.0196\n",
            "Step 1658: Test Loss = 0.0163\n",
            "Step 1659: Training Loss = 0.0577\n",
            "Step 1659: Test Loss = 0.0381\n",
            "Step 1660: Training Loss = 0.0723\n",
            "Step 1660: Test Loss = 0.0497\n",
            "Step 1661: Training Loss = 0.0800\n",
            "Step 1661: Test Loss = 0.0406\n",
            "Step 1662: Training Loss = 0.0266\n",
            "Step 1662: Test Loss = 0.0190\n",
            "Step 1663: Training Loss = 0.0949\n",
            "Step 1663: Test Loss = 0.0500\n",
            "Step 1664: Training Loss = 0.1857\n",
            "Step 1664: Test Loss = 0.1295\n",
            "Step 1665: Training Loss = 0.0507\n",
            "Step 1665: Test Loss = 0.0401\n",
            "Step 1666: Training Loss = 0.0785\n",
            "Step 1666: Test Loss = 0.0364\n",
            "Step 1667: Training Loss = 0.0549\n",
            "Step 1667: Test Loss = 0.0477\n",
            "Step 1668: Training Loss = 0.0693\n",
            "Step 1668: Test Loss = 0.0304\n",
            "Step 1669: Training Loss = 0.0952\n",
            "Step 1669: Test Loss = 0.0551\n",
            "Step 1670: Training Loss = 0.2184\n",
            "Step 1670: Test Loss = 0.1244\n",
            "Step 1671: Training Loss = 0.1015\n",
            "Step 1671: Test Loss = 0.0563\n",
            "Step 1672: Training Loss = 0.1414\n",
            "Step 1672: Test Loss = 0.0772\n",
            "Step 1673: Training Loss = 0.2299\n",
            "Step 1673: Test Loss = 0.1639\n",
            "Step 1674: Training Loss = 0.1250\n",
            "Step 1674: Test Loss = 0.0650\n",
            "Step 1675: Training Loss = 0.1267\n",
            "Step 1675: Test Loss = 0.0835\n",
            "Step 1676: Training Loss = 0.0629\n",
            "Step 1676: Test Loss = 0.0484\n",
            "Step 1677: Training Loss = 0.0693\n",
            "Step 1677: Test Loss = 0.0386\n",
            "Step 1678: Training Loss = 0.0762\n",
            "Step 1678: Test Loss = 0.0575\n",
            "Step 1679: Training Loss = 0.0818\n",
            "Step 1679: Test Loss = 0.0488\n",
            "Step 1680: Training Loss = 0.0831\n",
            "Step 1680: Test Loss = 0.0487\n",
            "Step 1681: Training Loss = 0.1208\n",
            "Step 1681: Test Loss = 0.0738\n",
            "Step 1682: Training Loss = 0.1090\n",
            "Step 1682: Test Loss = 0.0539\n",
            "Step 1683: Training Loss = 0.0349\n",
            "Step 1683: Test Loss = 0.0263\n",
            "Step 1684: Training Loss = 0.0915\n",
            "Step 1684: Test Loss = 0.0568\n",
            "Step 1685: Training Loss = 0.1210\n",
            "Step 1685: Test Loss = 0.0645\n",
            "Step 1686: Training Loss = 0.0660\n",
            "Step 1686: Test Loss = 0.0429\n",
            "Step 1687: Training Loss = 0.0358\n",
            "Step 1687: Test Loss = 0.0250\n",
            "Step 1688: Training Loss = 0.0804\n",
            "Step 1688: Test Loss = 0.0488\n",
            "Step 1689: Training Loss = 0.0915\n",
            "Step 1689: Test Loss = 0.0537\n",
            "Step 1690: Training Loss = 0.0959\n",
            "Step 1690: Test Loss = 0.0567\n",
            "Step 1691: Training Loss = 0.1459\n",
            "Step 1691: Test Loss = 0.0735\n",
            "Step 1692: Training Loss = 0.1489\n",
            "Step 1692: Test Loss = 0.0780\n",
            "Step 1693: Training Loss = 0.1949\n",
            "Step 1693: Test Loss = 0.1133\n",
            "Step 1694: Training Loss = 0.0538\n",
            "Step 1694: Test Loss = 0.0326\n",
            "Step 1695: Training Loss = 0.0479\n",
            "Step 1695: Test Loss = 0.0313\n",
            "Step 1696: Training Loss = 0.0455\n",
            "Step 1696: Test Loss = 0.0365\n",
            "Step 1697: Training Loss = 0.1050\n",
            "Step 1697: Test Loss = 0.0764\n",
            "Step 1698: Training Loss = 0.0265\n",
            "Step 1698: Test Loss = 0.0187\n",
            "Step 1699: Training Loss = 0.0737\n",
            "Step 1699: Test Loss = 0.0490\n",
            "Step 1700: Training Loss = 0.1462\n",
            "Step 1700: Test Loss = 0.0784\n",
            "1700 85% (3m 18s) Train Loss: 0.1039, Test Loss: 0.0606, Accuracy: 0.9661 - ! Draeber I Sjaele, der horer til mit Folk, og hol / danish ✓\n",
            "Step 1701: Training Loss = 0.0943\n",
            "Step 1701: Test Loss = 0.0469\n",
            "Step 1702: Training Loss = 0.1729\n",
            "Step 1702: Test Loss = 0.1308\n",
            "Step 1703: Training Loss = 0.1147\n",
            "Step 1703: Test Loss = 0.0667\n",
            "Step 1704: Training Loss = 0.0812\n",
            "Step 1704: Test Loss = 0.0619\n",
            "Step 1705: Training Loss = 0.1044\n",
            "Step 1705: Test Loss = 0.0572\n",
            "Step 1706: Training Loss = 0.0865\n",
            "Step 1706: Test Loss = 0.0460\n",
            "Step 1707: Training Loss = 0.1104\n",
            "Step 1707: Test Loss = 0.0406\n",
            "Step 1708: Training Loss = 0.1641\n",
            "Step 1708: Test Loss = 0.1053\n",
            "Step 1709: Training Loss = 0.0714\n",
            "Step 1709: Test Loss = 0.0322\n",
            "Step 1710: Training Loss = 0.1497\n",
            "Step 1710: Test Loss = 0.1127\n",
            "Step 1711: Training Loss = 0.1762\n",
            "Step 1711: Test Loss = 0.1126\n",
            "Step 1712: Training Loss = 0.0944\n",
            "Step 1712: Test Loss = 0.0737\n",
            "Step 1713: Training Loss = 0.1665\n",
            "Step 1713: Test Loss = 0.1105\n",
            "Step 1714: Training Loss = 0.1276\n",
            "Step 1714: Test Loss = 0.0922\n",
            "Step 1715: Training Loss = 0.1813\n",
            "Step 1715: Test Loss = 0.1332\n",
            "Step 1716: Training Loss = 0.1228\n",
            "Step 1716: Test Loss = 0.0704\n",
            "Step 1717: Training Loss = 0.1226\n",
            "Step 1717: Test Loss = 0.0552\n",
            "Step 1718: Training Loss = 0.1452\n",
            "Step 1718: Test Loss = 0.0887\n",
            "Step 1719: Training Loss = 0.0685\n",
            "Step 1719: Test Loss = 0.0346\n",
            "Step 1720: Training Loss = 0.1436\n",
            "Step 1720: Test Loss = 0.0845\n",
            "Step 1721: Training Loss = 0.0777\n",
            "Step 1721: Test Loss = 0.0338\n",
            "Step 1722: Training Loss = 0.0881\n",
            "Step 1722: Test Loss = 0.0463\n",
            "Step 1723: Training Loss = 0.0752\n",
            "Step 1723: Test Loss = 0.0423\n",
            "Step 1724: Training Loss = 0.0609\n",
            "Step 1724: Test Loss = 0.0362\n",
            "Step 1725: Training Loss = 0.1228\n",
            "Step 1725: Test Loss = 0.0804\n",
            "Step 1726: Training Loss = 0.0771\n",
            "Step 1726: Test Loss = 0.0548\n",
            "Step 1727: Training Loss = 0.1480\n",
            "Step 1727: Test Loss = 0.0705\n",
            "Step 1728: Training Loss = 0.0793\n",
            "Step 1728: Test Loss = 0.0463\n",
            "Step 1729: Training Loss = 0.0828\n",
            "Step 1729: Test Loss = 0.0402\n",
            "Step 1730: Training Loss = 0.0744\n",
            "Step 1730: Test Loss = 0.0260\n",
            "Step 1731: Training Loss = 0.0941\n",
            "Step 1731: Test Loss = 0.0563\n",
            "Step 1732: Training Loss = 0.1631\n",
            "Step 1732: Test Loss = 0.1059\n",
            "Step 1733: Training Loss = 0.0558\n",
            "Step 1733: Test Loss = 0.0310\n",
            "Step 1734: Training Loss = 0.0763\n",
            "Step 1734: Test Loss = 0.0352\n",
            "Step 1735: Training Loss = 0.0309\n",
            "Step 1735: Test Loss = 0.0173\n",
            "Step 1736: Training Loss = 0.0840\n",
            "Step 1736: Test Loss = 0.0428\n",
            "Step 1737: Training Loss = 0.0545\n",
            "Step 1737: Test Loss = 0.0367\n",
            "Step 1738: Training Loss = 0.1030\n",
            "Step 1738: Test Loss = 0.0609\n",
            "Step 1739: Training Loss = 0.0867\n",
            "Step 1739: Test Loss = 0.0489\n",
            "Step 1740: Training Loss = 0.1251\n",
            "Step 1740: Test Loss = 0.0667\n",
            "Step 1741: Training Loss = 0.0661\n",
            "Step 1741: Test Loss = 0.0259\n",
            "Step 1742: Training Loss = 0.0312\n",
            "Step 1742: Test Loss = 0.0262\n",
            "Step 1743: Training Loss = 0.0419\n",
            "Step 1743: Test Loss = 0.0226\n",
            "Step 1744: Training Loss = 0.1556\n",
            "Step 1744: Test Loss = 0.0880\n",
            "Step 1745: Training Loss = 0.1134\n",
            "Step 1745: Test Loss = 0.0680\n",
            "Step 1746: Training Loss = 0.0386\n",
            "Step 1746: Test Loss = 0.0167\n",
            "Step 1747: Training Loss = 0.0715\n",
            "Step 1747: Test Loss = 0.0270\n",
            "Step 1748: Training Loss = 0.0973\n",
            "Step 1748: Test Loss = 0.0472\n",
            "Step 1749: Training Loss = 0.0235\n",
            "Step 1749: Test Loss = 0.0199\n",
            "Step 1750: Training Loss = 0.0281\n",
            "Step 1750: Test Loss = 0.0209\n",
            "Step 1751: Training Loss = 0.1632\n",
            "Step 1751: Test Loss = 0.0978\n",
            "Step 1752: Training Loss = 0.0622\n",
            "Step 1752: Test Loss = 0.0360\n",
            "Step 1753: Training Loss = 0.0882\n",
            "Step 1753: Test Loss = 0.0595\n",
            "Step 1754: Training Loss = 0.0897\n",
            "Step 1754: Test Loss = 0.0411\n",
            "Step 1755: Training Loss = 0.0946\n",
            "Step 1755: Test Loss = 0.0572\n",
            "Step 1756: Training Loss = 0.0884\n",
            "Step 1756: Test Loss = 0.0451\n",
            "Step 1757: Training Loss = 0.0640\n",
            "Step 1757: Test Loss = 0.0298\n",
            "Step 1758: Training Loss = 0.0995\n",
            "Step 1758: Test Loss = 0.0432\n",
            "Step 1759: Training Loss = 0.3424\n",
            "Step 1759: Test Loss = 0.2424\n",
            "Step 1760: Training Loss = 0.0745\n",
            "Step 1760: Test Loss = 0.0441\n",
            "Step 1761: Training Loss = 0.1025\n",
            "Step 1761: Test Loss = 0.0374\n",
            "Step 1762: Training Loss = 0.0414\n",
            "Step 1762: Test Loss = 0.0231\n",
            "Step 1763: Training Loss = 0.0648\n",
            "Step 1763: Test Loss = 0.0222\n",
            "Step 1764: Training Loss = 0.1527\n",
            "Step 1764: Test Loss = 0.0717\n",
            "Step 1765: Training Loss = 0.1014\n",
            "Step 1765: Test Loss = 0.0622\n",
            "Step 1766: Training Loss = 0.0742\n",
            "Step 1766: Test Loss = 0.0395\n",
            "Step 1767: Training Loss = 0.0275\n",
            "Step 1767: Test Loss = 0.0233\n",
            "Step 1768: Training Loss = 0.1370\n",
            "Step 1768: Test Loss = 0.0964\n",
            "Step 1769: Training Loss = 0.0773\n",
            "Step 1769: Test Loss = 0.0672\n",
            "Step 1770: Training Loss = 0.0808\n",
            "Step 1770: Test Loss = 0.0495\n",
            "Step 1771: Training Loss = 0.1439\n",
            "Step 1771: Test Loss = 0.1097\n",
            "Step 1772: Training Loss = 0.1533\n",
            "Step 1772: Test Loss = 0.0822\n",
            "Step 1773: Training Loss = 0.0819\n",
            "Step 1773: Test Loss = 0.0304\n",
            "Step 1774: Training Loss = 0.1373\n",
            "Step 1774: Test Loss = 0.0934\n",
            "Step 1775: Training Loss = 0.1548\n",
            "Step 1775: Test Loss = 0.0710\n",
            "Step 1776: Training Loss = 0.0630\n",
            "Step 1776: Test Loss = 0.0223\n",
            "Step 1777: Training Loss = 0.0595\n",
            "Step 1777: Test Loss = 0.0263\n",
            "Step 1778: Training Loss = 0.0619\n",
            "Step 1778: Test Loss = 0.0110\n",
            "Step 1779: Training Loss = 0.1369\n",
            "Step 1779: Test Loss = 0.1027\n",
            "Step 1780: Training Loss = 0.1398\n",
            "Step 1780: Test Loss = 0.1033\n",
            "Step 1781: Training Loss = 0.0726\n",
            "Step 1781: Test Loss = 0.0411\n",
            "Step 1782: Training Loss = 0.0888\n",
            "Step 1782: Test Loss = 0.0533\n",
            "Step 1783: Training Loss = 0.0195\n",
            "Step 1783: Test Loss = 0.0159\n",
            "Step 1784: Training Loss = 0.1577\n",
            "Step 1784: Test Loss = 0.0684\n",
            "Step 1785: Training Loss = 0.1838\n",
            "Step 1785: Test Loss = 0.0915\n",
            "Step 1786: Training Loss = 0.1669\n",
            "Step 1786: Test Loss = 0.0817\n",
            "Step 1787: Training Loss = 0.0322\n",
            "Step 1787: Test Loss = 0.0225\n",
            "Step 1788: Training Loss = 0.0341\n",
            "Step 1788: Test Loss = 0.0211\n",
            "Step 1789: Training Loss = 0.1346\n",
            "Step 1789: Test Loss = 0.0746\n",
            "Step 1790: Training Loss = 0.0876\n",
            "Step 1790: Test Loss = 0.0662\n",
            "Step 1791: Training Loss = 0.2225\n",
            "Step 1791: Test Loss = 0.1124\n",
            "Step 1792: Training Loss = 0.1636\n",
            "Step 1792: Test Loss = 0.0810\n",
            "Step 1793: Training Loss = 0.0908\n",
            "Step 1793: Test Loss = 0.0622\n",
            "Step 1794: Training Loss = 0.0421\n",
            "Step 1794: Test Loss = 0.0261\n",
            "Step 1795: Training Loss = 0.0544\n",
            "Step 1795: Test Loss = 0.0378\n",
            "Step 1796: Training Loss = 0.0143\n",
            "Step 1796: Test Loss = 0.0074\n",
            "Step 1797: Training Loss = 0.0979\n",
            "Step 1797: Test Loss = 0.0500\n",
            "Step 1798: Training Loss = 0.0775\n",
            "Step 1798: Test Loss = 0.0499\n",
            "Step 1799: Training Loss = 0.0355\n",
            "Step 1799: Test Loss = 0.0286\n",
            "Step 1800: Training Loss = 0.1016\n",
            "Step 1800: Test Loss = 0.0389\n",
            "1800 90% (3m 30s) Train Loss: 0.0996, Test Loss: 0.0577, Accuracy: 0.9677 -  sedan han hade vikit ifran Saul. Darfor avlagsnad / swedish ✓\n",
            "Step 1801: Training Loss = 0.1135\n",
            "Step 1801: Test Loss = 0.0757\n",
            "Step 1802: Training Loss = 0.0568\n",
            "Step 1802: Test Loss = 0.0297\n",
            "Step 1803: Training Loss = 0.1890\n",
            "Step 1803: Test Loss = 0.1453\n",
            "Step 1804: Training Loss = 0.0872\n",
            "Step 1804: Test Loss = 0.0572\n",
            "Step 1805: Training Loss = 0.0365\n",
            "Step 1805: Test Loss = 0.0204\n",
            "Step 1806: Training Loss = 0.1291\n",
            "Step 1806: Test Loss = 0.0939\n",
            "Step 1807: Training Loss = 0.0250\n",
            "Step 1807: Test Loss = 0.0177\n",
            "Step 1808: Training Loss = 0.0617\n",
            "Step 1808: Test Loss = 0.0335\n",
            "Step 1809: Training Loss = 0.0704\n",
            "Step 1809: Test Loss = 0.0277\n",
            "Step 1810: Training Loss = 0.0921\n",
            "Step 1810: Test Loss = 0.0304\n",
            "Step 1811: Training Loss = 0.0255\n",
            "Step 1811: Test Loss = 0.0180\n",
            "Step 1812: Training Loss = 0.0706\n",
            "Step 1812: Test Loss = 0.0468\n",
            "Step 1813: Training Loss = 0.0534\n",
            "Step 1813: Test Loss = 0.0210\n",
            "Step 1814: Training Loss = 0.1345\n",
            "Step 1814: Test Loss = 0.0692\n",
            "Step 1815: Training Loss = 0.1388\n",
            "Step 1815: Test Loss = 0.0975\n",
            "Step 1816: Training Loss = 0.0312\n",
            "Step 1816: Test Loss = 0.0241\n",
            "Step 1817: Training Loss = 0.1167\n",
            "Step 1817: Test Loss = 0.0947\n",
            "Step 1818: Training Loss = 0.0890\n",
            "Step 1818: Test Loss = 0.0452\n",
            "Step 1819: Training Loss = 0.0401\n",
            "Step 1819: Test Loss = 0.0205\n",
            "Step 1820: Training Loss = 0.1487\n",
            "Step 1820: Test Loss = 0.0860\n",
            "Step 1821: Training Loss = 0.0267\n",
            "Step 1821: Test Loss = 0.0202\n",
            "Step 1822: Training Loss = 0.0502\n",
            "Step 1822: Test Loss = 0.0343\n",
            "Step 1823: Training Loss = 0.1079\n",
            "Step 1823: Test Loss = 0.0450\n",
            "Step 1824: Training Loss = 0.1025\n",
            "Step 1824: Test Loss = 0.0348\n",
            "Step 1825: Training Loss = 0.0255\n",
            "Step 1825: Test Loss = 0.0192\n",
            "Step 1826: Training Loss = 0.1826\n",
            "Step 1826: Test Loss = 0.1062\n",
            "Step 1827: Training Loss = 0.0604\n",
            "Step 1827: Test Loss = 0.0338\n",
            "Step 1828: Training Loss = 0.0562\n",
            "Step 1828: Test Loss = 0.0360\n",
            "Step 1829: Training Loss = 0.1120\n",
            "Step 1829: Test Loss = 0.0474\n",
            "Step 1830: Training Loss = 0.1074\n",
            "Step 1830: Test Loss = 0.0657\n",
            "Step 1831: Training Loss = 0.0386\n",
            "Step 1831: Test Loss = 0.0232\n",
            "Step 1832: Training Loss = 0.0400\n",
            "Step 1832: Test Loss = 0.0241\n",
            "Step 1833: Training Loss = 0.1237\n",
            "Step 1833: Test Loss = 0.0818\n",
            "Step 1834: Training Loss = 0.1850\n",
            "Step 1834: Test Loss = 0.0761\n",
            "Step 1835: Training Loss = 0.1066\n",
            "Step 1835: Test Loss = 0.0661\n",
            "Step 1836: Training Loss = 0.1555\n",
            "Step 1836: Test Loss = 0.0801\n",
            "Step 1837: Training Loss = 0.1726\n",
            "Step 1837: Test Loss = 0.1086\n",
            "Step 1838: Training Loss = 0.0894\n",
            "Step 1838: Test Loss = 0.0591\n",
            "Step 1839: Training Loss = 0.1460\n",
            "Step 1839: Test Loss = 0.0893\n",
            "Step 1840: Training Loss = 0.0714\n",
            "Step 1840: Test Loss = 0.0394\n",
            "Step 1841: Training Loss = 0.0873\n",
            "Step 1841: Test Loss = 0.0434\n",
            "Step 1842: Training Loss = 0.1640\n",
            "Step 1842: Test Loss = 0.1172\n",
            "Step 1843: Training Loss = 0.0493\n",
            "Step 1843: Test Loss = 0.0355\n",
            "Step 1844: Training Loss = 0.0479\n",
            "Step 1844: Test Loss = 0.0333\n",
            "Step 1845: Training Loss = 0.1009\n",
            "Step 1845: Test Loss = 0.0681\n",
            "Step 1846: Training Loss = 0.0470\n",
            "Step 1846: Test Loss = 0.0400\n",
            "Step 1847: Training Loss = 0.0328\n",
            "Step 1847: Test Loss = 0.0221\n",
            "Step 1848: Training Loss = 0.0863\n",
            "Step 1848: Test Loss = 0.0588\n",
            "Step 1849: Training Loss = 0.0990\n",
            "Step 1849: Test Loss = 0.0640\n",
            "Step 1850: Training Loss = 0.1195\n",
            "Step 1850: Test Loss = 0.0362\n",
            "Step 1851: Training Loss = 0.1508\n",
            "Step 1851: Test Loss = 0.0561\n",
            "Step 1852: Training Loss = 0.1140\n",
            "Step 1852: Test Loss = 0.0601\n",
            "Step 1853: Training Loss = 0.0766\n",
            "Step 1853: Test Loss = 0.0531\n",
            "Step 1854: Training Loss = 0.0670\n",
            "Step 1854: Test Loss = 0.0493\n",
            "Step 1855: Training Loss = 0.1211\n",
            "Step 1855: Test Loss = 0.0608\n",
            "Step 1856: Training Loss = 0.0495\n",
            "Step 1856: Test Loss = 0.0311\n",
            "Step 1857: Training Loss = 0.1081\n",
            "Step 1857: Test Loss = 0.0532\n",
            "Step 1858: Training Loss = 0.1674\n",
            "Step 1858: Test Loss = 0.0947\n",
            "Step 1859: Training Loss = 0.0894\n",
            "Step 1859: Test Loss = 0.0501\n",
            "Step 1860: Training Loss = 0.0977\n",
            "Step 1860: Test Loss = 0.0559\n",
            "Step 1861: Training Loss = 0.0439\n",
            "Step 1861: Test Loss = 0.0266\n",
            "Step 1862: Training Loss = 0.1022\n",
            "Step 1862: Test Loss = 0.0464\n",
            "Step 1863: Training Loss = 0.1044\n",
            "Step 1863: Test Loss = 0.0485\n",
            "Step 1864: Training Loss = 0.1701\n",
            "Step 1864: Test Loss = 0.0845\n",
            "Step 1865: Training Loss = 0.1901\n",
            "Step 1865: Test Loss = 0.1375\n",
            "Step 1866: Training Loss = 0.0592\n",
            "Step 1866: Test Loss = 0.0353\n",
            "Step 1867: Training Loss = 0.1048\n",
            "Step 1867: Test Loss = 0.0462\n",
            "Step 1868: Training Loss = 0.0529\n",
            "Step 1868: Test Loss = 0.0317\n",
            "Step 1869: Training Loss = 0.0623\n",
            "Step 1869: Test Loss = 0.0202\n",
            "Step 1870: Training Loss = 0.0285\n",
            "Step 1870: Test Loss = 0.0153\n",
            "Step 1871: Training Loss = 0.1014\n",
            "Step 1871: Test Loss = 0.0624\n",
            "Step 1872: Training Loss = 0.0402\n",
            "Step 1872: Test Loss = 0.0307\n",
            "Step 1873: Training Loss = 0.0804\n",
            "Step 1873: Test Loss = 0.0438\n",
            "Step 1874: Training Loss = 0.0870\n",
            "Step 1874: Test Loss = 0.0493\n",
            "Step 1875: Training Loss = 0.0513\n",
            "Step 1875: Test Loss = 0.0357\n",
            "Step 1876: Training Loss = 0.1201\n",
            "Step 1876: Test Loss = 0.0487\n",
            "Step 1877: Training Loss = 0.0566\n",
            "Step 1877: Test Loss = 0.0367\n",
            "Step 1878: Training Loss = 0.1062\n",
            "Step 1878: Test Loss = 0.0508\n",
            "Step 1879: Training Loss = 0.1070\n",
            "Step 1879: Test Loss = 0.0708\n",
            "Step 1880: Training Loss = 0.0593\n",
            "Step 1880: Test Loss = 0.0283\n",
            "Step 1881: Training Loss = 0.1309\n",
            "Step 1881: Test Loss = 0.0570\n",
            "Step 1882: Training Loss = 0.1756\n",
            "Step 1882: Test Loss = 0.1031\n",
            "Step 1883: Training Loss = 0.1186\n",
            "Step 1883: Test Loss = 0.0576\n",
            "Step 1884: Training Loss = 0.0785\n",
            "Step 1884: Test Loss = 0.0447\n",
            "Step 1885: Training Loss = 0.0659\n",
            "Step 1885: Test Loss = 0.0326\n",
            "Step 1886: Training Loss = 0.0318\n",
            "Step 1886: Test Loss = 0.0174\n",
            "Step 1887: Training Loss = 0.1197\n",
            "Step 1887: Test Loss = 0.0827\n",
            "Step 1888: Training Loss = 0.1223\n",
            "Step 1888: Test Loss = 0.0759\n",
            "Step 1889: Training Loss = 0.1371\n",
            "Step 1889: Test Loss = 0.0643\n",
            "Step 1890: Training Loss = 0.1962\n",
            "Step 1890: Test Loss = 0.0943\n",
            "Step 1891: Training Loss = 0.2040\n",
            "Step 1891: Test Loss = 0.0934\n",
            "Step 1892: Training Loss = 0.0837\n",
            "Step 1892: Test Loss = 0.0345\n",
            "Step 1893: Training Loss = 0.0658\n",
            "Step 1893: Test Loss = 0.0332\n",
            "Step 1894: Training Loss = 0.0579\n",
            "Step 1894: Test Loss = 0.0401\n",
            "Step 1895: Training Loss = 0.1654\n",
            "Step 1895: Test Loss = 0.1223\n",
            "Step 1896: Training Loss = 0.0432\n",
            "Step 1896: Test Loss = 0.0218\n",
            "Step 1897: Training Loss = 0.0183\n",
            "Step 1897: Test Loss = 0.0161\n",
            "Step 1898: Training Loss = 0.0946\n",
            "Step 1898: Test Loss = 0.0555\n",
            "Step 1899: Training Loss = 0.0987\n",
            "Step 1899: Test Loss = 0.0711\n",
            "Step 1900: Training Loss = 0.0618\n",
            "Step 1900: Test Loss = 0.0320\n",
            "1900 95% (3m 42s) Train Loss: 0.0934, Test Loss: 0.0533, Accuracy: 0.9669 - bana saygi gostersin diye kendisine bunlari verdim / turkish ✓\n",
            "Step 1901: Training Loss = 0.2014\n",
            "Step 1901: Test Loss = 0.0862\n",
            "Step 1902: Training Loss = 0.0508\n",
            "Step 1902: Test Loss = 0.0299\n",
            "Step 1903: Training Loss = 0.1062\n",
            "Step 1903: Test Loss = 0.0775\n",
            "Step 1904: Training Loss = 0.0445\n",
            "Step 1904: Test Loss = 0.0310\n",
            "Step 1905: Training Loss = 0.1202\n",
            "Step 1905: Test Loss = 0.0570\n",
            "Step 1906: Training Loss = 0.0437\n",
            "Step 1906: Test Loss = 0.0295\n",
            "Step 1907: Training Loss = 0.0478\n",
            "Step 1907: Test Loss = 0.0416\n",
            "Step 1908: Training Loss = 0.1209\n",
            "Step 1908: Test Loss = 0.0675\n",
            "Step 1909: Training Loss = 0.0585\n",
            "Step 1909: Test Loss = 0.0367\n",
            "Step 1910: Training Loss = 0.1213\n",
            "Step 1910: Test Loss = 0.0631\n",
            "Step 1911: Training Loss = 0.1175\n",
            "Step 1911: Test Loss = 0.0742\n",
            "Step 1912: Training Loss = 0.0502\n",
            "Step 1912: Test Loss = 0.0391\n",
            "Step 1913: Training Loss = 0.1281\n",
            "Step 1913: Test Loss = 0.0455\n",
            "Step 1914: Training Loss = 0.0302\n",
            "Step 1914: Test Loss = 0.0159\n",
            "Step 1915: Training Loss = 0.1013\n",
            "Step 1915: Test Loss = 0.0777\n",
            "Step 1916: Training Loss = 0.1068\n",
            "Step 1916: Test Loss = 0.0599\n",
            "Step 1917: Training Loss = 0.0507\n",
            "Step 1917: Test Loss = 0.0266\n",
            "Step 1918: Training Loss = 0.1359\n",
            "Step 1918: Test Loss = 0.0858\n",
            "Step 1919: Training Loss = 0.0524\n",
            "Step 1919: Test Loss = 0.0383\n",
            "Step 1920: Training Loss = 0.1624\n",
            "Step 1920: Test Loss = 0.0702\n",
            "Step 1921: Training Loss = 0.0992\n",
            "Step 1921: Test Loss = 0.0399\n",
            "Step 1922: Training Loss = 0.0480\n",
            "Step 1922: Test Loss = 0.0335\n",
            "Step 1923: Training Loss = 0.0556\n",
            "Step 1923: Test Loss = 0.0340\n",
            "Step 1924: Training Loss = 0.1384\n",
            "Step 1924: Test Loss = 0.0880\n",
            "Step 1925: Training Loss = 0.0670\n",
            "Step 1925: Test Loss = 0.0576\n",
            "Step 1926: Training Loss = 0.0415\n",
            "Step 1926: Test Loss = 0.0223\n",
            "Step 1927: Training Loss = 0.0376\n",
            "Step 1927: Test Loss = 0.0117\n",
            "Step 1928: Training Loss = 0.0521\n",
            "Step 1928: Test Loss = 0.0270\n",
            "Step 1929: Training Loss = 0.0724\n",
            "Step 1929: Test Loss = 0.0333\n",
            "Step 1930: Training Loss = 0.2178\n",
            "Step 1930: Test Loss = 0.0981\n",
            "Step 1931: Training Loss = 0.1072\n",
            "Step 1931: Test Loss = 0.0289\n",
            "Step 1932: Training Loss = 0.0858\n",
            "Step 1932: Test Loss = 0.0507\n",
            "Step 1933: Training Loss = 0.1100\n",
            "Step 1933: Test Loss = 0.0581\n",
            "Step 1934: Training Loss = 0.1446\n",
            "Step 1934: Test Loss = 0.0946\n",
            "Step 1935: Training Loss = 0.1622\n",
            "Step 1935: Test Loss = 0.1157\n",
            "Step 1936: Training Loss = 0.1769\n",
            "Step 1936: Test Loss = 0.0545\n",
            "Step 1937: Training Loss = 0.0682\n",
            "Step 1937: Test Loss = 0.0320\n",
            "Step 1938: Training Loss = 0.0999\n",
            "Step 1938: Test Loss = 0.0687\n",
            "Step 1939: Training Loss = 0.0943\n",
            "Step 1939: Test Loss = 0.0426\n",
            "Step 1940: Training Loss = 0.1520\n",
            "Step 1940: Test Loss = 0.0929\n",
            "Step 1941: Training Loss = 0.1223\n",
            "Step 1941: Test Loss = 0.0813\n",
            "Step 1942: Training Loss = 0.0941\n",
            "Step 1942: Test Loss = 0.0440\n",
            "Step 1943: Training Loss = 0.0559\n",
            "Step 1943: Test Loss = 0.0409\n",
            "Step 1944: Training Loss = 0.0649\n",
            "Step 1944: Test Loss = 0.0210\n",
            "Step 1945: Training Loss = 0.0406\n",
            "Step 1945: Test Loss = 0.0185\n",
            "Step 1946: Training Loss = 0.0200\n",
            "Step 1946: Test Loss = 0.0135\n",
            "Step 1947: Training Loss = 0.0725\n",
            "Step 1947: Test Loss = 0.0463\n",
            "Step 1948: Training Loss = 0.1137\n",
            "Step 1948: Test Loss = 0.0480\n",
            "Step 1949: Training Loss = 0.0551\n",
            "Step 1949: Test Loss = 0.0260\n",
            "Step 1950: Training Loss = 0.0795\n",
            "Step 1950: Test Loss = 0.0304\n",
            "Step 1951: Training Loss = 0.0732\n",
            "Step 1951: Test Loss = 0.0407\n",
            "Step 1952: Training Loss = 0.1684\n",
            "Step 1952: Test Loss = 0.0964\n",
            "Step 1953: Training Loss = 0.1968\n",
            "Step 1953: Test Loss = 0.1239\n",
            "Step 1954: Training Loss = 0.0766\n",
            "Step 1954: Test Loss = 0.0383\n",
            "Step 1955: Training Loss = 0.0777\n",
            "Step 1955: Test Loss = 0.0391\n",
            "Step 1956: Training Loss = 0.0803\n",
            "Step 1956: Test Loss = 0.0553\n",
            "Step 1957: Training Loss = 0.2031\n",
            "Step 1957: Test Loss = 0.1351\n",
            "Step 1958: Training Loss = 0.1602\n",
            "Step 1958: Test Loss = 0.0973\n",
            "Step 1959: Training Loss = 0.0763\n",
            "Step 1959: Test Loss = 0.0394\n",
            "Step 1960: Training Loss = 0.1132\n",
            "Step 1960: Test Loss = 0.0728\n",
            "Step 1961: Training Loss = 0.1020\n",
            "Step 1961: Test Loss = 0.0356\n",
            "Step 1962: Training Loss = 0.0531\n",
            "Step 1962: Test Loss = 0.0466\n",
            "Step 1963: Training Loss = 0.0846\n",
            "Step 1963: Test Loss = 0.0536\n",
            "Step 1964: Training Loss = 0.1024\n",
            "Step 1964: Test Loss = 0.0781\n",
            "Step 1965: Training Loss = 0.1488\n",
            "Step 1965: Test Loss = 0.0983\n",
            "Step 1966: Training Loss = 0.0739\n",
            "Step 1966: Test Loss = 0.0479\n",
            "Step 1967: Training Loss = 0.1413\n",
            "Step 1967: Test Loss = 0.1083\n",
            "Step 1968: Training Loss = 0.1365\n",
            "Step 1968: Test Loss = 0.0492\n",
            "Step 1969: Training Loss = 0.0407\n",
            "Step 1969: Test Loss = 0.0234\n",
            "Step 1970: Training Loss = 0.1143\n",
            "Step 1970: Test Loss = 0.0683\n",
            "Step 1971: Training Loss = 0.0827\n",
            "Step 1971: Test Loss = 0.0478\n",
            "Step 1972: Training Loss = 0.0736\n",
            "Step 1972: Test Loss = 0.0449\n",
            "Step 1973: Training Loss = 0.0461\n",
            "Step 1973: Test Loss = 0.0178\n",
            "Step 1974: Training Loss = 0.0743\n",
            "Step 1974: Test Loss = 0.0473\n",
            "Step 1975: Training Loss = 0.1182\n",
            "Step 1975: Test Loss = 0.0690\n",
            "Step 1976: Training Loss = 0.0659\n",
            "Step 1976: Test Loss = 0.0259\n",
            "Step 1977: Training Loss = 0.1026\n",
            "Step 1977: Test Loss = 0.0473\n",
            "Step 1978: Training Loss = 0.1129\n",
            "Step 1978: Test Loss = 0.0610\n",
            "Step 1979: Training Loss = 0.0665\n",
            "Step 1979: Test Loss = 0.0603\n",
            "Step 1980: Training Loss = 0.0902\n",
            "Step 1980: Test Loss = 0.0557\n",
            "Step 1981: Training Loss = 0.1457\n",
            "Step 1981: Test Loss = 0.1024\n",
            "Step 1982: Training Loss = 0.1513\n",
            "Step 1982: Test Loss = 0.0868\n",
            "Step 1983: Training Loss = 0.0722\n",
            "Step 1983: Test Loss = 0.0364\n",
            "Step 1984: Training Loss = 0.1484\n",
            "Step 1984: Test Loss = 0.0930\n",
            "Step 1985: Training Loss = 0.0256\n",
            "Step 1985: Test Loss = 0.0089\n",
            "Step 1986: Training Loss = 0.1042\n",
            "Step 1986: Test Loss = 0.0630\n",
            "Step 1987: Training Loss = 0.1675\n",
            "Step 1987: Test Loss = 0.0747\n",
            "Step 1988: Training Loss = 0.0984\n",
            "Step 1988: Test Loss = 0.0594\n",
            "Step 1989: Training Loss = 0.0883\n",
            "Step 1989: Test Loss = 0.0339\n",
            "Step 1990: Training Loss = 0.0485\n",
            "Step 1990: Test Loss = 0.0347\n",
            "Step 1991: Training Loss = 0.0781\n",
            "Step 1991: Test Loss = 0.0277\n",
            "Step 1992: Training Loss = 0.0659\n",
            "Step 1992: Test Loss = 0.0391\n",
            "Step 1993: Training Loss = 0.0878\n",
            "Step 1993: Test Loss = 0.0498\n",
            "Step 1994: Training Loss = 0.0869\n",
            "Step 1994: Test Loss = 0.0453\n",
            "Step 1995: Training Loss = 0.2223\n",
            "Step 1995: Test Loss = 0.1031\n",
            "Step 1996: Training Loss = 0.0213\n",
            "Step 1996: Test Loss = 0.0149\n",
            "Step 1997: Training Loss = 0.0536\n",
            "Step 1997: Test Loss = 0.0358\n",
            "Step 1998: Training Loss = 0.0133\n",
            "Step 1998: Test Loss = 0.0104\n",
            "Step 1999: Training Loss = 0.1267\n",
            "Step 1999: Test Loss = 0.1036\n",
            "Step 2000: Training Loss = 0.0919\n",
            "Step 2000: Test Loss = 0.0526\n",
            "2000 100% (3m 53s) Train Loss: 0.0955, Test Loss: 0.0541, Accuracy: 0.9671 - e, cintosi i fianchi, corse innanzi ad Achab fino  / italian ✓\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss functions\n",
        "--------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "HMFd4VFZASxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the recorded loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label=\"Training Loss\", color='blue')\n",
        "plt.plot(test_loss_history, label=\"Testing Loss\", color='red', linestyle='--')\n",
        "plt.xlabel(\"Iterations (x100)\")\n",
        "plt.ylabel(\"Loss Value\")\n",
        "plt.title(\"Loss Curve: Training vs. Testing\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3hxhB9FG3Img",
        "outputId": "5c23e621-59aa-46f8-b7a5-6f323e1d5250"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate results\n",
        "-------------------\n",
        "\n",
        "We now vizualize the performance of our model by creating a confusion matrix. The ground truth languages of samples are represented by rows in the matrix while the predicted languages are represented by columns.\n",
        "\n",
        "In this evaluation we consider sequences of variable sizes rather than the fixed length sequences we used for training."
      ],
      "metadata": {
        "id": "0piNy_atASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "eval_batch_size = 1  # For evaluating different sequence lengths\n",
        "confusion = torch.zeros(n_languages, n_languages)\n",
        "n_confusion = 1000\n",
        "num_correct = 0\n",
        "total = 0\n",
        "\n",
        "for i in range(n_confusion):\n",
        "    eval_chunk_len = random.randint(10, 50)\n",
        "    input_data, target_category, text_data = load_random_batch(test_category_data, chunk_len=eval_chunk_len, batch_size=eval_batch_size, device=device)\n",
        "    output = evaluate(rnn, input_data, seq_len=eval_chunk_len, batch_size=eval_batch_size)\n",
        "\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    category_i = [int(target_category[idx]) for idx in range(len(target_category))]\n",
        "    for j in range(eval_batch_size):\n",
        "        category = all_categories[category_i[j]]\n",
        "        confusion[category_i[j]][guess_i[j]] += 1\n",
        "        num_correct += int(guess_i[j] == category_i[j])\n",
        "        total += 1\n",
        "\n",
        "print('Test accuracy: ', float(num_correct) / float(n_confusion * eval_batch_size))\n",
        "\n",
        "# Normalize confusion matrix\n",
        "for i in range(n_languages):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "# Plot confusion matrix\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Set up plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Set up axes with fixed ticks\n",
        "ax.set_xticks(range(n_languages))\n",
        "ax.set_yticks(range(n_languages))\n",
        "ax.set_xticklabels(all_categories, rotation=90)\n",
        "ax.set_yticklabels(all_categories)\n",
        "\n",
        "# Force label at every tick\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.848\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "80847HI_ASxW",
        "outputId": "345e69d4-4c2b-4ecd-b701-270710daa25a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can pick out bright spots off the main axis that show which\n",
        "languages it guesses incorrectly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2fzo8hRsASxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run on User Input\n",
        "---------------------\n",
        "\n",
        "Now you can test your model on your own input.\n"
      ],
      "metadata": {
        "id": "Q5LFhMlKASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "def predict(input_line, n_predictions=5, seq_len=chunk_len):\n",
        "    print('\\n> %s' % input_line)\n",
        "\n",
        "    # Normalize the input text\n",
        "    input_line = unicodeToAscii(input_line.lower().strip())\n",
        "\n",
        "    # Pad or truncate the input to match `seq_len`\n",
        "    if len(input_line) < seq_len:\n",
        "        input_line += \" \" * (seq_len - len(input_line))\n",
        "    else:\n",
        "        input_line = input_line[:seq_len]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Convert input string to tensor\n",
        "        input_data = stringToTensor(input_line).long().unsqueeze(0).to(device)\n",
        "\n",
        "        # Evaluate the input data using the model\n",
        "        output = evaluate(rnn, input_data, seq_len=seq_len, batch_size=1)\n",
        "\n",
        "    # Get the top N predictions\n",
        "    topv, topi = output.topk(n_predictions, dim=1)\n",
        "    predictions = []\n",
        "\n",
        "    print(\"Predictions:\")\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "        language = all_categories[category_index]\n",
        "        print(f\"({value:.2f}) {language}\")\n",
        "        predictions.append([value, language])\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example test cases\n",
        "predict(\"This is a test sentence for language prediction\", seq_len=30)\n",
        "predict(\"Bonjour, comment allez-vous aujourd'hui?\", seq_len=30)\n",
        "predict(\"Hola, ¿cómo estás?\", seq_len=30)\n",
        "predict(\"Ciao, come stai?\", seq_len=30)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> This is a test sentence for language prediction\n",
            "Predictions:\n",
            "(9.62) english\n",
            "(4.10) french\n",
            "(1.86) spanish\n",
            "(1.43) vietnamese\n",
            "(1.01) albanian\n",
            "\n",
            "> Bonjour, comment allez-vous aujourd'hui?\n",
            "Predictions:\n",
            "(10.95) french\n",
            "(3.20) portuguese\n",
            "(2.66) german\n",
            "(1.88) english\n",
            "(1.66) romanian\n",
            "\n",
            "> Hola, ¿cómo estás?\n",
            "Predictions:\n",
            "(5.00) esperanto\n",
            "(3.38) spanish\n",
            "(2.57) swedish\n",
            "(2.33) vietnamese\n",
            "(2.16) norwegian\n",
            "\n",
            "> Ciao, come stai?\n",
            "Predictions:\n",
            "(4.90) romanian\n",
            "(4.78) vietnamese\n",
            "(3.25) esperanto\n",
            "(1.40) portuguese\n",
            "(1.21) czech\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4.899930000305176, 'romanian'],\n",
              " [4.78359842300415, 'vietnamese'],\n",
              " [3.2505075931549072, 'esperanto'],\n",
              " [1.3968174457550049, 'portuguese'],\n",
              " [1.2076321840286255, 'czech']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjv_yCpEASxW",
        "outputId": "4559c448-0810-4397-970b-3c77de2b9ae5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Kaggle submission file\n",
        "\n",
        "Once you have found a good set of hyperparameters submit the output of your model on the Kaggle test file."
      ],
      "metadata": {
        "id": "GdlKZeW7ASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "### DO NOT CHANGE KAGGLE SUBMISSION CODE ####\n",
        "import csv\n",
        "\n",
        "kaggle_test_file_path = 'language_data/kaggle_rnn_language_classification_test.txt'\n",
        "with open(kaggle_test_file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "output_rows = []\n",
        "for i, line in enumerate(lines):\n",
        "    sample = line.rstrip()\n",
        "    sample_chunk_len = len(sample)\n",
        "    input_data = stringToTensor(sample).unsqueeze(0)\n",
        "    output = evaluate(rnn, input_data, seq_len=sample_chunk_len, batch_size=1)\n",
        "    guess_i = categoryFromOutput(output)\n",
        "    output_rows.append((str(i+1), all_categories[guess_i]))\n",
        "\n",
        "submission_file_path = 'kaggle_rnn_submission.csv'\n",
        "with open(submission_file_path, 'w') as f:\n",
        "    output_rows = [('id', 'category')] + output_rows\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(output_rows)\n"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "R5DCKLjxASxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "id": "ZHbP4iigASxX"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}